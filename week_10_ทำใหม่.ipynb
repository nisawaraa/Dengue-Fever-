{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PQuD-U-Bvs_U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô 1: ‡πÇ‡∏´‡∏•‡∏î‡πÅ‡∏•‡∏∞‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"
      ],
      "metadata": {
        "id": "QGNPU9QdvvpS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏†‡∏≤‡∏û‡∏≠‡∏≤‡∏Å‡∏≤‡∏®‡∏à‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢‡∏ä‡∏µ‡∏ó‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå rain.xlsx\n",
        "file_path = 'rain.xlsx'\n",
        "xls = pd.ExcelFile(file_path)\n",
        "\n",
        "df_list = []\n",
        "for sheet in xls.sheet_names:\n",
        "    df = pd.read_excel(xls, sheet_name=sheet)\n",
        "    df = df.rename(columns={'‡∏õ‡∏µ': 'year', '‡πÄ‡∏î‡∏∑‡∏≠‡∏ô': 'month', '‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà': 'day'})\n",
        "\n",
        "    # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç\n",
        "    df['year'] = pd.to_numeric(df['year'], errors='coerce')\n",
        "    df['month'] = pd.to_numeric(df['month'], errors='coerce')\n",
        "    df['day'] = pd.to_numeric(df['day'], errors='coerce')\n",
        "    df = df.dropna(subset=['year', 'month', 'day'])\n",
        "\n",
        "    # ‡∏™‡∏£‡πâ‡∏≤‡∏á datetime column\n",
        "    df['‡∏ß‡∏±‡∏ô'] = pd.to_datetime(df[['year', 'month', 'day']], errors='coerce')\n",
        "    df = df.dropna(subset=['‡∏ß‡∏±‡∏ô'])\n",
        "\n",
        "    # ‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏†‡∏≤‡∏û‡∏≠‡∏≤‡∏Å‡∏≤‡∏®‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç\n",
        "    for col in ['‡∏≠‡∏∏‡∏ì‡∏´‡∏†‡∏π‡∏°‡∏¥', '‡∏ù‡∏ô', '‡∏ä‡∏∑‡πâ‡∏ô']:\n",
        "        if col in df.columns:\n",
        "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "    # ‡∏Å‡∏£‡∏≠‡∏á‡πÄ‡∏≠‡∏≤‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÅ‡∏ñ‡∏ß‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏£‡∏ö\n",
        "    df = df[df[['‡∏≠‡∏∏‡∏ì‡∏´‡∏†‡∏π‡∏°‡∏¥', '‡∏ù‡∏ô', '‡∏ä‡∏∑‡πâ‡∏ô']].notna().all(axis=1)]\n",
        "    df_list.append(df)\n",
        "\n",
        "# ‡∏£‡∏ß‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏†‡∏≤‡∏û‡∏≠‡∏≤‡∏Å‡∏≤‡∏®‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î\n",
        "weather = pd.concat(df_list, ignore_index=True).drop_duplicates().sort_values('‡∏ß‡∏±‡∏ô').reset_index(drop=True)\n",
        "\n",
        "# ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏†‡∏≤‡∏û‡∏≠‡∏≤‡∏Å‡∏≤‡∏®‡∏ó‡∏µ‡πà clean ‡πÅ‡∏•‡πâ‡∏ß\n",
        "weather.to_excel('rain_all_years_sorted3.xlsx', index=False)\n",
        "print(\"‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å rain_all_years_sorted3.xlsx ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡πÅ‡∏•‡πâ‡∏ß\")\n"
      ],
      "metadata": {
        "id": "X-BOXRdcvwn4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô 2: ‡πÇ‡∏´‡∏•‡∏î‡πÅ‡∏•‡∏∞‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ú‡∏π‡πâ‡∏õ‡πà‡∏ß‡∏¢"
      ],
      "metadata": {
        "id": "guGfkSH3vziC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ú‡∏π‡πâ‡∏õ‡πà‡∏ß‡∏¢‡∏à‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢‡∏ä‡∏µ‡∏ó‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå DHFcc12.xlsx\n",
        "xls = pd.ExcelFile('DHFcc12.xlsx')\n",
        "df_list = []\n",
        "\n",
        "for sheet in xls.sheet_names:\n",
        "    if sheet == \"Table1\":  # ‡∏Ç‡πâ‡∏≤‡∏°‡∏ä‡∏µ‡∏ó Table1\n",
        "        continue\n",
        "\n",
        "    df = pd.read_excel(xls, sheet_name=sheet)\n",
        "    df.columns = df.columns.str.strip()\n",
        "\n",
        "    if '‡∏ß‡∏±‡∏ô‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏õ‡πà‡∏ß‡∏¢' in df.columns:\n",
        "        df['‡∏ß‡∏±‡∏ô‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏õ‡πà‡∏ß‡∏¢'] = pd.to_datetime(df['‡∏ß‡∏±‡∏ô‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏õ‡πà‡∏ß‡∏¢'], errors='coerce')\n",
        "\n",
        "    for col in ['‡∏≠‡∏≤‡∏¢‡∏∏(‡∏õ‡∏µ)', '‡∏≠‡∏≤‡∏¢‡∏∏(‡πÄ‡∏î‡∏∑‡∏≠‡∏ô)']:\n",
        "        if col in df.columns:\n",
        "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "    df = df.dropna(subset=['‡∏ß‡∏±‡∏ô‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏õ‡πà‡∏ß‡∏¢'])\n",
        "    df = df.dropna(how='all')\n",
        "\n",
        "    df_list.append(df)\n",
        "\n",
        "patients = pd.concat(df_list, ignore_index=True).drop_duplicates()\n",
        "print(f\"‚úÖ ‡∏£‡∏ß‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ú‡∏π‡πâ‡∏õ‡πà‡∏ß‡∏¢‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {patients.shape[0]} ‡πÅ‡∏ñ‡∏ß, {patients.shape[1]} ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå\")\n"
      ],
      "metadata": {
        "id": "Q3idV_YBv0gv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô 3: ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì rolling average ‡∏Ç‡∏≠‡∏á‡∏™‡∏†‡∏≤‡∏û‡∏≠‡∏≤‡∏Å‡∏≤‡∏®‡∏¢‡πâ‡∏≠‡∏ô‡∏´‡∏•‡∏±‡∏á 15 ‡∏ß‡∏±‡∏ô ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏ß‡∏±‡∏ô‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏õ‡πà‡∏ß‡∏¢"
      ],
      "metadata": {
        "id": "I8F_5ONJv3ST"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏†‡∏≤‡∏û‡∏≠‡∏≤‡∏Å‡∏≤‡∏®‡∏ó‡∏µ‡πà‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡πÅ‡∏•‡πâ‡∏ß (‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏ô‡πà‡∏ô‡∏≠‡∏ô)\n",
        "weather = pd.read_excel(\"rain_all_years_sorted3.xlsx\")\n",
        "weather['‡∏ß‡∏±‡∏ô'] = pd.to_datetime(weather['‡∏ß‡∏±‡∏ô'])\n",
        "\n",
        "# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì rolling average ‡∏¢‡πâ‡∏≠‡∏ô‡∏´‡∏•‡∏±‡∏á 15 ‡∏ß‡∏±‡∏ô\n",
        "def get_rolling_avg(date, n_days=15):\n",
        "    start_date = date - pd.Timedelta(days=n_days)\n",
        "    mask = (weather['‡∏ß‡∏±‡∏ô'] >= start_date) & (weather['‡∏ß‡∏±‡∏ô'] < date)\n",
        "    subset = weather.loc[mask]\n",
        "    if subset.empty:\n",
        "        return pd.Series([None, None, None])\n",
        "    return pd.Series([\n",
        "        subset['‡∏≠‡∏∏‡∏ì‡∏´‡∏†‡∏π‡∏°‡∏¥'].mean(),\n",
        "        subset['‡∏ù‡∏ô'].mean(),\n",
        "        subset['‡∏ä‡∏∑‡πâ‡∏ô'].mean()\n",
        "    ])\n",
        "\n",
        "# ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì rolling average ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ú‡∏π‡πâ‡∏õ‡πà‡∏ß‡∏¢‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏£‡∏≤‡∏¢\n",
        "patients[['temp_15d_avg', 'rain_15d_avg', 'humid_15d_avg']] = patients['‡∏ß‡∏±‡∏ô‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏õ‡πà‡∏ß‡∏¢'].apply(get_rolling_avg)\n",
        "print(\"‚úÖ ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì rolling average ‡πÄ‡∏™‡∏£‡πá‡∏à\")\n"
      ],
      "metadata": {
        "id": "VijSe9Uov3mW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô 4: ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà ‡πÄ‡∏ä‡πà‡∏ô ‡∏õ‡∏µ, ‡πÄ‡∏î‡∏∑‡∏≠‡∏ô, ‡πÑ‡∏ï‡∏£‡∏°‡∏≤‡∏™, ‡∏§‡∏î‡∏π‡∏Å‡∏≤‡∏•"
      ],
      "metadata": {
        "id": "7cfpszmov7-F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "patients['‡∏õ‡∏µ'] = patients['‡∏ß‡∏±‡∏ô‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏õ‡πà‡∏ß‡∏¢'].dt.year\n",
        "patients['‡πÄ‡∏î‡∏∑‡∏≠‡∏ô'] = patients['‡∏ß‡∏±‡∏ô‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏õ‡πà‡∏ß‡∏¢'].dt.month\n",
        "patients['‡πÑ‡∏ï‡∏£‡∏°‡∏≤‡∏™'] = patients['‡∏ß‡∏±‡∏ô‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏õ‡πà‡∏ß‡∏¢'].dt.quarter\n",
        "\n",
        "def assign_season(row):\n",
        "    month = row['‡πÄ‡∏î‡∏∑‡∏≠‡∏ô']\n",
        "    day = row['‡∏ß‡∏±‡∏ô‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏õ‡πà‡∏ß‡∏¢'].day\n",
        "    if (month == 2 and day >= 15) or month in [3,4] or (month == 5 and day < 15):\n",
        "        return 'Summer'\n",
        "    elif (month == 5 and day >= 15) or month in [6,7,8,9] or (month == 10 and day < 15):\n",
        "        return 'Rainy'\n",
        "    else:\n",
        "        return 'Winter'\n",
        "\n",
        "patients['‡∏§‡∏î‡∏π‡∏Å‡∏≤‡∏•'] = patients.apply(assign_season, axis=1)\n"
      ],
      "metadata": {
        "id": "ZxILeNCYv9Tp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô 5: ‡∏£‡∏ß‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏£‡∏≤‡∏¢‡∏ß‡∏±‡∏ô‡πÅ‡∏•‡∏∞‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ú‡∏π‡πâ‡∏õ‡πà‡∏ß‡∏¢‡∏£‡∏≤‡∏¢‡∏ß‡∏±‡∏ô"
      ],
      "metadata": {
        "id": "4f3zx3P0wAgB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ‡∏™‡∏£‡πâ‡∏≤‡∏á column ‡∏ß‡∏±‡∏ô‡πÅ‡∏ö‡∏ö date (‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÄ‡∏ß‡∏•‡∏≤)\n",
        "patients['date'] = patients['‡∏ß‡∏±‡∏ô‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏õ‡πà‡∏ß‡∏¢'].dt.date\n",
        "\n",
        "# ‡∏ô‡∏±‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ú‡∏π‡πâ‡∏õ‡πà‡∏ß‡∏¢‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏ß‡∏±‡∏ô (cases)\n",
        "daily_counts = patients.groupby('date').size().reset_index(name='cases')\n",
        "\n",
        "# ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡πÅ‡∏•‡∏∞‡πÇ‡∏´‡∏°‡∏î‡∏Ç‡∏≠‡∏á‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡∏≠‡∏∑‡πà‡∏ô ‡πÜ ‡∏ï‡πà‡∏≠‡∏ß‡∏±‡∏ô\n",
        "daily_weather = patients.groupby('date').agg({\n",
        "    'temp_15d_avg': 'mean',\n",
        "    'rain_15d_avg': 'mean',\n",
        "    'humid_15d_avg': 'mean',\n",
        "    '‡∏≠‡∏≤‡∏¢‡∏∏(‡∏õ‡∏µ)': 'mean',\n",
        "    '‡πÄ‡∏û‡∏®': lambda x: x.mode()[0] if not x.mode().empty else None,\n",
        "    '‡∏≠‡∏≤‡∏ä‡∏µ‡∏û': lambda x: x.mode()[0] if not x.mode().empty else None,\n",
        "    '‡∏ï‡∏≥‡∏ö‡∏•': lambda x: x.mode()[0] if not x.mode().empty else None,\n",
        "    '‡∏≠‡∏≥‡πÄ‡∏†‡∏≠': lambda x: x.mode()[0] if not x.mode().empty else None,\n",
        "    '‡πÄ‡∏î‡∏∑‡∏≠‡∏ô': lambda x: x.mode()[0] if not x.mode().empty else None,\n",
        "    '‡∏õ‡∏µ': lambda x: x.mode()[0] if not x.mode().empty else None,\n",
        "    '‡πÑ‡∏ï‡∏£‡∏°‡∏≤‡∏™': lambda x: x.mode()[0] if not x.mode().empty else None,\n",
        "    '‡∏§‡∏î‡∏π‡∏Å‡∏≤‡∏•': lambda x: x.mode()[0] if not x.mode().empty else None\n",
        "}).reset_index()\n",
        "\n",
        "# ‡∏£‡∏ß‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ú‡∏π‡πâ‡∏õ‡πà‡∏ß‡∏¢‡∏£‡∏≤‡∏¢‡∏ß‡∏±‡∏ô‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏†‡∏≤‡∏û‡∏≠‡∏≤‡∏Å‡∏≤‡∏®\n",
        "df_final = pd.merge(daily_counts, daily_weather, on='date', how='left')\n",
        "print(\"‚úÖ ‡∏£‡∏ß‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• df_final ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à:\", df_final.shape)\n"
      ],
      "metadata": {
        "id": "d8ELTpp6wBce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô 6: ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ missing values ‡πÅ‡∏•‡∏∞‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"
      ],
      "metadata": {
        "id": "XKRfmM20wEcL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "missing_before = df_final.isnull().sum().sum()\n",
        "print(f\"‚ö†Ô∏è ‡∏û‡∏ö missing values: {missing_before} ‡∏ä‡πà‡∏≠‡∏á\")\n",
        "\n",
        "df_final_clean = df_final.dropna()\n",
        "print(\"‚úÖ ‡∏•‡∏ö missing rows ‡πÅ‡∏•‡πâ‡∏ß ‚Üí ‡∏Ç‡∏ô‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•:\", df_final_clean.shape)\n",
        "\n",
        "# ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ü‡∏•‡πå clean data\n",
        "df_final_clean.to_csv(\"df_final_clean.csv\", index=False)\n",
        "df_final_clean.to_excel(\"df_final_clean.xlsx\", index=False)\n",
        "print(\"üìÅ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ü‡∏•‡πå df_final_clean.csv ‡πÅ‡∏•‡∏∞ df_final_clean.xlsx ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢\")\n"
      ],
      "metadata": {
        "id": "0c4k-ckFwFNz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô 7: ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏© ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÉ‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•"
      ],
      "metadata": {
        "id": "Cmcu7JMiwJXm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_final_clean = pd.read_excel(\"/content/df_final_clean.xlsx\")"
      ],
      "metadata": {
        "id": "IouK0CFx2H9G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_final_clean.isnull().sum())\n"
      ],
      "metadata": {
        "id": "eSW25gCTOcEg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_final_clean = df_final_clean.drop_duplicates() #‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ã‡πâ‡∏≥ (Duplicate Records)"
      ],
      "metadata": {
        "id": "i0Xp1RnOOfPW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_final_clean.dtypes) #‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (Data Types)\n"
      ],
      "metadata": {
        "id": "aypEpMzAOzxI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_clean = df_final_clean.rename(columns={\n",
        "    '‡πÄ‡∏û‡∏®': 'gender',\n",
        "    '‡∏≠‡∏≤‡∏ä‡∏µ‡∏û': 'occupation',\n",
        "    '‡∏ï‡∏≥‡∏ö‡∏•': 'subdistrict',\n",
        "    '‡∏≠‡∏≥‡πÄ‡∏†‡∏≠': 'district',\n",
        "    '‡πÄ‡∏î‡∏∑‡∏≠‡∏ô': 'month',\n",
        "    '‡πÑ‡∏ï‡∏£‡∏°‡∏≤‡∏™': 'quarter',\n",
        "    '‡∏≠‡∏≤‡∏¢‡∏∏(‡∏õ‡∏µ)': 'age',\n",
        "    '‡∏§‡∏î‡∏π‡∏Å‡∏≤‡∏•': 'season',\n",
        "})\n"
      ],
      "metadata": {
        "id": "duEZRDLYwKNP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_clean.head())"
      ],
      "metadata": {
        "id": "Wetw53VbI6Lu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå\n",
        "df_final_clean = pd.read_excel(\"/content/df_final_clean.xlsx\")\n",
        "\n",
        "# ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Å‡∏£‡∏≤‡∏ü‡πÅ‡∏ó‡πà‡∏á (Bar Chart) ‡πÅ‡∏™‡∏î‡∏á‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏∞‡∏à‡∏≤‡∏¢‡∏Ç‡∏≠‡∏á 'cases' ‡∏ï‡∏≤‡∏° 'season'\n",
        "plt.figure(figsize=(10, 6))\n",
        "df_final_clean.groupby('‡∏§‡∏î‡∏π‡∏Å‡∏≤‡∏•')['cases'].sum().plot(kind='bar', color='skyblue')\n",
        "plt.title('Total Cases by Season')\n",
        "plt.xlabel('Season')\n",
        "plt.ylabel('Total Cases')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()\n",
        "\n",
        "# ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Å‡∏£‡∏≤‡∏ü‡∏Å‡∏£‡∏∞‡∏à‡∏≤‡∏¢ (Scatter Plot) ‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á 'age' ‡πÅ‡∏•‡∏∞ 'cases'\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(df_final_clean['‡∏≠‡∏≤‡∏¢‡∏∏(‡∏õ‡∏µ)'], df_final_clean['cases'], color='orange')\n",
        "plt.title('Scatter Plot of Age vs Cases')\n",
        "plt.xlabel('Age')\n",
        "plt.ylabel('Cases')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "3sFktvdklJkm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ‡πÅ‡∏õ‡∏•‡∏á‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå 'date' ‡πÄ‡∏õ‡πá‡∏ô datetime\n",
        "df_clean['date'] = pd.to_datetime(df_clean['date'], errors='coerce')\n",
        "\n",
        "# ‡∏Å‡∏£‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á‡∏õ‡∏µ 2017-2024\n",
        "df_clean = df_clean[df_clean['date'].dt.year.between(2017, 2024)]\n",
        "\n",
        "# ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå 'month' ‡πÅ‡∏•‡∏∞ 'year' ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÅ‡∏¢‡∏Å‡∏Å‡∏£‡∏≤‡∏ü‡∏ï‡∏≤‡∏°‡πÄ‡∏î‡∏∑‡∏≠‡∏ô\n",
        "df_clean['month'] = df_clean['date'].dt.month\n",
        "df_clean['year'] = df_clean['date'].dt.year\n",
        "\n",
        "# ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡∏ï‡∏≤‡∏°‡∏õ‡∏µ‡πÅ‡∏•‡∏∞‡πÄ‡∏î‡∏∑‡∏≠‡∏ô\n",
        "avg_data = df_clean.groupby(['year', 'month']).agg({\n",
        "    'temp_15d_avg': 'mean',\n",
        "    'rain_15d_avg': 'mean',\n",
        "    'humid_15d_avg': 'mean'\n",
        "}).reset_index()\n",
        "\n",
        "# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏Å‡∏≤‡∏£‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏• 3 ‡∏Å‡∏£‡∏≤‡∏ü (temp_15d_avg, rain_15d_avg, humid_15d_avg) ‡πÅ‡∏¢‡∏Å‡∏ï‡∏≤‡∏°‡πÄ‡∏î‡∏∑‡∏≠‡∏ô\n",
        "fig, axs = plt.subplots(3, 1, figsize=(12, 18), sharex=True)\n",
        "\n",
        "# ‡πÅ‡∏™‡∏î‡∏á‡∏Å‡∏£‡∏≤‡∏ü‡πÅ‡∏Ñ‡πà‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô (‡∏ó‡∏∏‡∏Å‡πÜ 6 ‡πÄ‡∏î‡∏∑‡∏≠‡∏ô)\n",
        "months_to_display = [1, 6, 12]\n",
        "avg_data_filtered = avg_data[avg_data['month'].isin(months_to_display)]\n",
        "\n",
        "# ‡∏Å‡∏£‡∏≤‡∏ü‡πÅ‡∏™‡∏î‡∏á‡∏≠‡∏∏‡∏ì‡∏´‡∏†‡∏π‡∏°‡∏¥ (Temperature)\n",
        "axs[0].plot(avg_data_filtered['year'].astype(str) + '-' + avg_data_filtered['month'].astype(str), avg_data_filtered['temp_15d_avg'], color='red', label='Temperature')\n",
        "axs[0].set_title('Average Temperature (¬∞C) from 2017 to 2024')\n",
        "axs[0].set_ylabel('Temperature (¬∞C)')\n",
        "axs[0].legend()\n",
        "\n",
        "# ‡∏Å‡∏£‡∏≤‡∏ü‡πÅ‡∏™‡∏î‡∏á‡∏ù‡∏ô (Rainfall)\n",
        "axs[1].plot(avg_data_filtered['year'].astype(str) + '-' + avg_data_filtered['month'].astype(str), avg_data_filtered['rain_15d_avg'], color='green', label='Rainfall')\n",
        "axs[1].set_title('Average Rainfall (mm) from 2017 to 2024')\n",
        "axs[1].set_ylabel('Rainfall (mm)')\n",
        "axs[1].legend()\n",
        "\n",
        "# ‡∏Å‡∏£‡∏≤‡∏ü‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ä‡∏∑‡πâ‡∏ô (Humidity)\n",
        "axs[2].plot(avg_data_filtered['year'].astype(str) + '-' + avg_data_filtered['month'].astype(str), avg_data_filtered['humid_15d_avg'], color='blue', label='Humidity')\n",
        "axs[2].set_title('Average Humidity (%) from 2017 to 2024')\n",
        "axs[2].set_ylabel('Humidity (%)')\n",
        "axs[2].legend()\n",
        "\n",
        "# ‡∏ï‡∏±‡πâ‡∏á‡∏ä‡∏∑‡πà‡∏≠‡∏Å‡∏£‡∏≤‡∏ü\n",
        "plt.xlabel('Date (Year-Month)')\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "tqN2205pKI_n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ‡∏≠‡πà‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•\n",
        "df = pd.read_csv('df_final_clean.csv')  # ‡πÉ‡∏™‡πà path ‡∏Ç‡∏≠‡∏á‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡πÉ‡∏ä‡πâ\n",
        "\n",
        "# ‡πÅ‡∏õ‡∏•‡∏á‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå 'date' ‡πÄ‡∏õ‡πá‡∏ô datetime\n",
        "df['date'] = pd.to_datetime(df['date'])\n",
        "\n",
        "# ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå 'year' ‡πÅ‡∏•‡∏∞ 'season' ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏£‡∏≤‡∏ü‡∏£‡∏≤‡∏¢‡∏õ‡∏µ‡πÅ‡∏•‡∏∞‡∏§‡∏î‡∏π‡∏Å‡∏≤‡∏•\n",
        "df['year'] = df['date'].dt.year  # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå 'year' ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏∏‡πä‡∏õ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏£‡∏≤‡∏¢‡∏õ‡∏µ\n",
        "df['season'] = df['date'].dt.month % 12 // 3 + 1  # ‡∏§‡∏î‡∏π‡∏Å‡∏≤‡∏•: 1=‡∏§‡∏î‡∏π‡∏£‡πâ‡∏≠‡∏ô, 2=‡∏§‡∏î‡∏π‡∏ù‡∏ô, 3=‡∏§‡∏î‡∏π‡∏´‡∏ô‡∏≤‡∏ß\n",
        "\n",
        "# ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡∏õ‡∏£‡∏∞‡∏à‡∏≥‡∏õ‡∏µ\n",
        "df_yearly = df.groupby('year').agg({\n",
        "    'humid_15d_avg': 'mean',\n",
        "    'rain_15d_avg': 'mean',\n",
        "    'temp_15d_avg': 'mean'\n",
        "}).reset_index()\n",
        "\n",
        "# ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Å‡∏£‡∏≤‡∏ü\n",
        "fig, ax = plt.subplots(3, 1, figsize=(10, 12))\n",
        "\n",
        "# ‡∏Å‡∏£‡∏≤‡∏ü‡πÅ‡∏™‡∏î‡∏á‡∏≠‡∏∏‡∏ì‡∏´‡∏†‡∏π‡∏°‡∏¥\n",
        "ax[0].plot(df_yearly['year'], df_yearly['temp_15d_avg'], label='Temperature', color='red')\n",
        "ax[0].set_title('Average Temperature from 2017 to 2024')\n",
        "ax[0].set_xlabel('Year')\n",
        "ax[0].set_ylabel('Temperature (¬∞C)')\n",
        "\n",
        "# ‡∏Å‡∏£‡∏≤‡∏ü‡πÅ‡∏™‡∏î‡∏á‡∏ù‡∏ô\n",
        "ax[1].plot(df_yearly['year'], df_yearly['rain_15d_avg'], label='Rain', color='blue')\n",
        "ax[1].set_title('Average Rainfall from 2017 to 2024')\n",
        "ax[1].set_xlabel('Year')\n",
        "ax[1].set_ylabel('Rainfall (mm)')\n",
        "\n",
        "# ‡∏Å‡∏£‡∏≤‡∏ü‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ä‡∏∑‡πâ‡∏ô\n",
        "ax[2].plot(df_yearly['year'], df_yearly['humid_15d_avg'], label='Humidity', color='green')\n",
        "ax[2].set_title('Average Humidity from 2017 to 2024')\n",
        "ax[2].set_xlabel('Year')\n",
        "ax[2].set_ylabel('Humidity (%)')\n",
        "\n",
        "# ‡πÅ‡∏™‡∏î‡∏á‡∏Å‡∏£‡∏≤‡∏ü\n",
        "plt.tight_layout()\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "bysb4fgVLAbB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.columns)\n"
      ],
      "metadata": {
        "id": "qab8woG2LRC9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import font_manager\n",
        "\n",
        "# ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏ü‡∏≠‡∏ô‡∏ï‡πå‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ\n",
        "font_path = \"/content/THSarabunNew.ttf\"  # ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏ü‡∏≠‡∏ô‡∏ï‡πå‡∏ó‡∏µ‡πà‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á\n",
        "font_prop = font_manager.FontProperties(fname=font_path)\n",
        "\n",
        "# ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ú‡∏π‡πâ‡∏õ‡πà‡∏ß‡∏¢‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏ï‡∏≥‡∏ö‡∏•\n",
        "top_subdistricts = df_clean.groupby('subdistrict')['cases'].sum().sort_values(ascending=False).head(20)\n",
        "\n",
        "# ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Å‡∏£‡∏≤‡∏ü\n",
        "plt.figure(figsize=(12, 8))\n",
        "top_subdistricts.plot(kind='barh', color='lightblue')\n",
        "\n",
        "# ‡∏ï‡∏±‡πâ‡∏á‡∏ä‡∏∑‡πà‡∏≠‡∏Å‡∏£‡∏≤‡∏ü‡πÅ‡∏•‡∏∞‡πÅ‡∏Å‡∏ô\n",
        "plt.xlabel('Total Cases', fontproperties=font_prop)\n",
        "plt.ylabel('Subdistrict', fontproperties=font_prop)\n",
        "plt.title('Top 20 Subdistricts by Total Cases', fontproperties=font_prop)\n",
        "\n",
        "# ‡∏´‡∏°‡∏∏‡∏ô‡∏ä‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏î‡πâ‡∏á‡πà‡∏≤‡∏¢‡∏Ç‡∏∂‡πâ‡∏ô\n",
        "plt.xticks(rotation=45, fontproperties=font_prop)\n",
        "plt.yticks(fontproperties=font_prop)\n",
        "\n",
        "# ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏™‡∏î‡∏á‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ú‡∏π‡πâ‡∏õ‡πà‡∏ß‡∏¢\n",
        "for index, value in enumerate(top_subdistricts):\n",
        "    plt.text(value, index, str(value), fontproperties=font_prop)  # ‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡πà‡∏≤‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏Ç‡∏≠‡∏á‡∏ö‡∏≤‡∏£‡πå\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "3y43STz2le0U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import font_manager\n",
        "\n",
        "# ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏ü‡∏≠‡∏ô‡∏ï‡πå‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ\n",
        "font_path = \"/content/THSarabunNew.ttf\"  # ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏ü‡∏≠‡∏ô‡∏ï‡πå‡∏ó‡∏µ‡πà‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á\n",
        "font_prop = font_manager.FontProperties(fname=font_path)\n",
        "\n",
        "# ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ú‡∏π‡πâ‡∏õ‡πà‡∏ß‡∏¢‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏ï‡∏≥‡∏ö‡∏•\n",
        "top_subdistricts = df_clean.groupby('subdistrict')['cases'].sum().sort_values(ascending=True).head(20)  # ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å 20 ‡∏ï‡∏≥‡∏ö‡∏•‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ú‡∏π‡πâ‡∏õ‡πà‡∏ß‡∏¢‡∏ô‡πâ‡∏≠‡∏¢‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î\n",
        "\n",
        "# ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Å‡∏£‡∏≤‡∏ü\n",
        "plt.figure(figsize=(12, 8))\n",
        "top_subdistricts.plot(kind='barh', color='lightblue')\n",
        "\n",
        "# ‡∏ï‡∏±‡πâ‡∏á‡∏ä‡∏∑‡πà‡∏≠‡∏Å‡∏£‡∏≤‡∏ü‡πÅ‡∏•‡∏∞‡πÅ‡∏Å‡∏ô\n",
        "plt.xlabel('Total Cases', fontproperties=font_prop)\n",
        "plt.ylabel('Subdistrict', fontproperties=font_prop)\n",
        "plt.title('Top 20 Subdistricts by Total Cases (Lowest)', fontproperties=font_prop)\n",
        "\n",
        "# ‡∏´‡∏°‡∏∏‡∏ô‡∏ä‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏î‡πâ‡∏á‡πà‡∏≤‡∏¢‡∏Ç‡∏∂‡πâ‡∏ô\n",
        "plt.xticks(rotation=45, fontproperties=font_prop)\n",
        "plt.yticks(fontproperties=font_prop)\n",
        "\n",
        "# ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏™‡∏î‡∏á‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ú‡∏π‡πâ‡∏õ‡πà‡∏ß‡∏¢\n",
        "for index, value in enumerate(top_subdistricts):\n",
        "    plt.text(value, index, str(value), fontproperties=font_prop)  # ‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡πà‡∏≤‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏Ç‡∏≠‡∏á‡∏ö‡∏≤‡∏£‡πå\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "9ZRjXSqsCi__"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import font_manager\n",
        "\n",
        "# ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏ü‡∏≠‡∏ô‡∏ï‡πå‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ\n",
        "font_path = \"/content/THSarabunNew.ttf\"  # ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏ü‡∏≠‡∏ô‡∏ï‡πå‡∏ó‡∏µ‡πà‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á\n",
        "font_prop = font_manager.FontProperties(fname=font_path)\n",
        "\n",
        "# ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ú‡∏π‡πâ‡∏õ‡πà‡∏ß‡∏¢‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏≠‡∏≤‡∏ä‡∏µ‡∏û\n",
        "top_occupation = df_clean.groupby('occupation')['cases'].sum().sort_values(ascending=False).head(20)\n",
        "\n",
        "# ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Å‡∏£‡∏≤‡∏ü\n",
        "plt.figure(figsize=(12, 10))  # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡∏ô‡∏≤‡∏î‡∏Å‡∏£‡∏≤‡∏ü\n",
        "top_occupation.plot(kind='barh', color='lightcoral')  # ‡πÉ‡∏ä‡πâ top_occupation ‡πÅ‡∏ó‡∏ô top_subdistricts\n",
        "\n",
        "# ‡∏ï‡∏±‡πâ‡∏á‡∏ä‡∏∑‡πà‡∏≠‡∏Å‡∏£‡∏≤‡∏ü‡πÅ‡∏•‡∏∞‡πÅ‡∏Å‡∏ô\n",
        "plt.xlabel('Total Cases', fontproperties=font_prop)\n",
        "plt.ylabel('Occupation', fontproperties=font_prop)  # ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏ä‡∏∑‡πà‡∏≠‡πÅ‡∏Å‡∏ô y\n",
        "plt.title('Top 20 Occupation by Total Cases', fontproperties=font_prop)  # ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏ä‡∏∑‡πà‡∏≠‡∏Å‡∏£‡∏≤‡∏ü\n",
        "\n",
        "# ‡∏´‡∏°‡∏∏‡∏ô‡∏ä‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏î‡πâ‡∏á‡πà‡∏≤‡∏¢‡∏Ç‡∏∂‡πâ‡∏ô\n",
        "plt.xticks(rotation=45, fontproperties=font_prop)\n",
        "plt.yticks(fontproperties=font_prop)\n",
        "\n",
        "# ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏™‡∏î‡∏á‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ú‡∏π‡πâ‡∏õ‡πà‡∏ß‡∏¢\n",
        "for index, value in enumerate(top_occupation):  # ‡πÉ‡∏ä‡πâ top_occupation ‡πÅ‡∏ó‡∏ô top_subdistricts\n",
        "    plt.text(value, index, str(value), fontproperties=font_prop)  # ‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡πà‡∏≤‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏Ç‡∏≠‡∏á‡∏ö‡∏≤‡∏£‡πå\n",
        "\n",
        "plt.tight_layout()  # ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Å‡∏±‡∏ö‡∏Ç‡∏ô‡∏≤‡∏î‡∏Ç‡∏≠‡∏á‡∏Å‡∏£‡∏≤‡∏ü‡πÉ‡∏´‡πâ‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "UFMh7gRryMww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô 8: ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÄ‡∏ä‡∏¥‡∏á‡πÄ‡∏î‡∏µ‡πà‡∏¢‡∏ß (Univariate Analysis)"
      ],
      "metadata": {
        "id": "REbDjrN3wNOG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á\n",
        "print(df_final_clean.columns)\n"
      ],
      "metadata": {
        "id": "72man_fQQ5hr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import scipy.stats as stats\n",
        "from scipy.stats import spearmanr, pointbiserialr, kruskal\n",
        "\n",
        "# ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ\n",
        "target = 'cases'\n",
        "numeric_vars = ['temp_15d_avg', 'rain_15d_avg', 'humid_15d_avg', '‡∏≠‡∏≤‡∏¢‡∏∏(‡∏õ‡∏µ)']  # ‡∏£‡∏ß‡∏° '‡∏≠‡∏≤‡∏¢‡∏∏(‡∏õ‡∏µ)'\n",
        "binary_cats = ['‡πÄ‡∏û‡∏®']\n",
        "multi_cats = ['‡∏≠‡∏≤‡∏ä‡∏µ‡∏û', '‡∏ï‡∏≥‡∏ö‡∏•', '‡∏≠‡∏≥‡πÄ‡∏†‡∏≠', '‡πÄ‡∏î‡∏∑‡∏≠‡∏ô', '‡∏õ‡∏µ', '‡πÑ‡∏ï‡∏£‡∏°‡∏≤‡∏™', '‡∏§‡∏î‡∏π‡∏Å‡∏≤‡∏•']  # ‡∏£‡∏ß‡∏°‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£ '‡πÄ‡∏î‡∏∑‡∏≠‡∏ô', '‡∏õ‡∏µ', '‡πÑ‡∏ï‡∏£‡∏°‡∏≤‡∏™', '‡∏§‡∏î‡∏π‡∏Å‡∏≤‡∏•'\n",
        "\n",
        "# ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏û‡∏®‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç (‡∏ä‡∏≤‡∏¢=0, ‡∏´‡∏ç‡∏¥‡∏á=1)\n",
        "if '‡πÄ‡∏û‡∏®' in df_final_clean.columns:\n",
        "    df_final_clean['gender_code'] = df_final_clean['‡πÄ‡∏û‡∏®'].map({'‡∏ä‡∏≤‡∏¢': 0, '‡∏´‡∏ç‡∏¥‡∏á': 1})\n",
        "\n",
        "# ‡∏•‡∏ö missing values ‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì\n",
        "df_final_clean = df_final_clean.dropna(subset=['temp_15d_avg', 'rain_15d_avg', 'humid_15d_avg', 'gender_code', target])\n",
        "\n",
        "# ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡πà‡∏≤ p-value\n",
        "results = []\n",
        "\n",
        "# 1) Spearman correlation ‡∏Å‡∏±‡∏ö‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡πÄ‡∏ä‡∏¥‡∏á‡∏õ‡∏£‡∏¥‡∏°‡∏≤‡∏ì\n",
        "for var in numeric_vars:\n",
        "    corr, p = spearmanr(df_final_clean[var], df_final_clean[target])\n",
        "    results.append({\n",
        "        'Variable': var,\n",
        "        'Test': 'Spearman Correlation',\n",
        "        'Stat': round(corr, 3),\n",
        "        'P-Value': round(p, 4)\n",
        "    })\n",
        "\n",
        "# 2) Point-Biserial correlation ‡∏Å‡∏±‡∏ö‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡πÑ‡∏ö‡∏ô‡∏≤‡∏£‡∏µ\n",
        "for var in binary_cats:\n",
        "    encoded_var = var + '_code'  # ‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡πÅ‡∏õ‡∏•‡∏á‡∏à‡∏≤‡∏Å‡πÄ‡∏û‡∏®\n",
        "    if encoded_var in df_final_clean.columns and df_final_clean[encoded_var].nunique() == 2:\n",
        "        corr, p = pointbiserialr(df_final_clean[encoded_var], df_final_clean[target])\n",
        "        results.append({\n",
        "            'Variable': var,\n",
        "            'Test': 'Point-Biserial',\n",
        "            'Stat': round(corr, 3),\n",
        "            'P-Value': round(p, 4)\n",
        "        })\n",
        "\n",
        "# 3) Kruskal-Wallis test ‡∏Å‡∏±‡∏ö‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡∏´‡∏•‡∏≤‡∏¢‡∏Å‡∏•‡∏∏‡πà‡∏°\n",
        "for var in multi_cats:\n",
        "    df_non_null = df_final_clean.dropna(subset=[var])\n",
        "    groups = [group[target].dropna() for name, group in df_non_null.groupby(var)]\n",
        "    if len(groups) > 1:\n",
        "        h_stat, p = kruskal(*groups)\n",
        "        results.append({\n",
        "            'Variable': var,\n",
        "            'Test': 'Kruskal-Wallis',\n",
        "            'Stat': round(h_stat, 3),\n",
        "            'P-Value': round(p, 4)\n",
        "        })\n",
        "\n",
        "# ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•\n",
        "results_df = pd.DataFrame(results).sort_values('P-Value')\n",
        "print(\"\\nüìä ‡∏ú‡∏•‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÄ‡∏ä‡∏¥‡∏á‡πÄ‡∏î‡∏µ‡πà‡∏¢‡∏ß (‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏ï‡∏≤‡∏° p-value):\")\n",
        "print(results_df)\n"
      ],
      "metadata": {
        "id": "BticRF0EwOKf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import scipy.stats as stats\n",
        "from scipy.stats import spearmanr, pointbiserialr, kruskal\n",
        "\n",
        "# ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ\n",
        "target = 'cases'\n",
        "numeric_vars = ['temp_15d_avg', 'rain_15d_avg', 'humid_15d_avg', '‡∏≠‡∏≤‡∏¢‡∏∏(‡∏õ‡∏µ)']  # ‡∏£‡∏ß‡∏° '‡∏≠‡∏≤‡∏¢‡∏∏(‡∏õ‡∏µ)'\n",
        "binary_cats = ['‡πÄ‡∏û‡∏®']\n",
        "multi_cats = ['‡∏≠‡∏≤‡∏ä‡∏µ‡∏û', '‡∏ï‡∏≥‡∏ö‡∏•', '‡∏≠‡∏≥‡πÄ‡∏†‡∏≠', '‡πÄ‡∏î‡∏∑‡∏≠‡∏ô', '‡∏õ‡∏µ', '‡πÑ‡∏ï‡∏£‡∏°‡∏≤‡∏™', '‡∏§‡∏î‡∏π‡∏Å‡∏≤‡∏•']  # ‡∏£‡∏ß‡∏°‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£ '‡πÄ‡∏î‡∏∑‡∏≠‡∏ô', '‡∏õ‡∏µ', '‡πÑ‡∏ï‡∏£‡∏°‡∏≤‡∏™', '‡∏§‡∏î‡∏π‡∏Å‡∏≤‡∏•'\n",
        "\n",
        "# ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏û‡∏®‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç (‡∏ä‡∏≤‡∏¢=0, ‡∏´‡∏ç‡∏¥‡∏á=1)\n",
        "if '‡πÄ‡∏û‡∏®' in df_final_clean.columns:\n",
        "    df_final_clean['gender_code'] = df_final_clean['‡πÄ‡∏û‡∏®'].map({'‡∏ä‡∏≤‡∏¢': 0, '‡∏´‡∏ç‡∏¥‡∏á': 1})\n",
        "\n",
        "# ‡∏•‡∏ö missing values ‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì\n",
        "df_final_clean = df_final_clean.dropna(subset=['temp_15d_avg', 'rain_15d_avg', 'humid_15d_avg', 'gender_code', target])\n",
        "\n",
        "# ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡πà‡∏≤ p-value\n",
        "results = []\n",
        "\n",
        "# 1) Spearman correlation ‡∏Å‡∏±‡∏ö‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡πÄ‡∏ä‡∏¥‡∏á‡∏õ‡∏£‡∏¥‡∏°‡∏≤‡∏ì\n",
        "for var in numeric_vars:\n",
        "    corr, p = spearmanr(df_final_clean[var], df_final_clean[target])\n",
        "    results.append({\n",
        "        'Variable': var,\n",
        "        'Test': 'Spearman Correlation',\n",
        "        'Stat': round(corr, 3),\n",
        "        'P-Value': round(p, 4)\n",
        "    })\n",
        "\n",
        "# 2) Point-Biserial correlation ‡∏Å‡∏±‡∏ö‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡πÑ‡∏ö‡∏ô‡∏≤‡∏£‡∏µ\n",
        "for var in binary_cats:\n",
        "    encoded_var = var + '_code'  # ‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡πÅ‡∏õ‡∏•‡∏á‡∏à‡∏≤‡∏Å‡πÄ‡∏û‡∏®\n",
        "    if encoded_var in df_final_clean.columns and df_final_clean[encoded_var].nunique() == 2:\n",
        "        corr, p = pointbiserialr(df_final_clean[encoded_var], df_final_clean[target])\n",
        "        results.append({\n",
        "            'Variable': var,\n",
        "            'Test': 'Point-Biserial',\n",
        "            'Stat': round(corr, 3),\n",
        "            'P-Value': round(p, 4)\n",
        "        })\n",
        "\n",
        "# 3) Kruskal-Wallis test ‡∏Å‡∏±‡∏ö‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡∏´‡∏•‡∏≤‡∏¢‡∏Å‡∏•‡∏∏‡πà‡∏°\n",
        "for var in multi_cats:\n",
        "    df_non_null = df_final_clean.dropna(subset=[var])\n",
        "    groups = [group[target].dropna() for name, group in df_non_null.groupby(var)]\n",
        "    if len(groups) > 1:\n",
        "        h_stat, p = kruskal(*groups)\n",
        "        results.append({\n",
        "            'Variable': var,\n",
        "            'Test': 'Kruskal-Wallis',\n",
        "            'Stat': round(h_stat, 3),\n",
        "            'P-Value': round(p, 4)\n",
        "        })\n",
        "\n",
        "# ‡πÅ‡∏õ‡∏•‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÄ‡∏õ‡πá‡∏ô DataFrame\n",
        "results_df = pd.DataFrame(results).sort_values('P-Value')\n",
        "\n",
        "# ‡∏Å‡∏£‡∏≠‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡∏ó‡∏µ‡πà‡∏°‡∏µ p-value < 0.05\n",
        "significant_results_df = results_df[results_df['P-Value'] < 0.05]\n",
        "\n",
        "# ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•\n",
        "print(\"\\nüìä ‡∏ú‡∏•‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÄ‡∏ä‡∏¥‡∏á‡πÄ‡∏î‡∏µ‡πà‡∏¢‡∏ß (‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡∏ó‡∏µ‡πà‡∏°‡∏µ p-value < 0.05):\")\n",
        "print(significant_results_df)\n"
      ],
      "metadata": {
        "id": "Tjas_15qMqdd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô 9: ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÄ‡∏ä‡∏¥‡∏á‡∏û‡∏´‡∏∏‡∏î‡πâ‡∏ß‡∏¢ Negative Binomial Regression"
      ],
      "metadata": {
        "id": "snd6z7VFwSNs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_final_clean.columns)  # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÉ‡∏ô DataFrame\n"
      ],
      "metadata": {
        "id": "LgP1JD5oa6oY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_final_clean.rename(columns={\n",
        "    'date': 'date',\n",
        "    'cases': 'cases',\n",
        "    'temp_15d_avg': 'temp_15d_avg',\n",
        "    'rain_15d_avg': 'rain_15d_avg',\n",
        "    'humid_15d_avg': 'humid_15d_avg',\n",
        "    '‡∏≠‡∏≤‡∏¢‡∏∏(‡∏õ‡∏µ)': 'age',\n",
        "    '‡πÄ‡∏û‡∏®': 'gender',\n",
        "    '‡∏≠‡∏≤‡∏ä‡∏µ‡∏û': 'occupation',\n",
        "    '‡∏ï‡∏≥‡∏ö‡∏•': 'subdistrict',\n",
        "    '‡∏≠‡∏≥‡πÄ‡∏†‡∏≠': 'district',\n",
        "    '‡πÄ‡∏î‡∏∑‡∏≠‡∏ô': 'month',\n",
        "    '‡∏õ‡∏µ': 'year',\n",
        "    '‡πÑ‡∏ï‡∏£‡∏°‡∏≤‡∏™': 'quarter',\n",
        "    '‡∏§‡∏î‡∏π‡∏Å‡∏≤‡∏•': 'season',\n",
        "    'gender_code': 'gender_code'\n",
        "}, inplace=True)\n"
      ],
      "metadata": {
        "id": "vnZa-ue9Vbrp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm  # ‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤ statsmodels\n"
      ],
      "metadata": {
        "id": "7m6FfUuR2qR6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ‡πÅ‡∏õ‡∏•‡∏á‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô categorical ‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô dtype 'category' (‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà)\n",
        "df_final_clean['occupation'] = df_final_clean['occupation'].astype('category')\n",
        "df_final_clean['subdistrict'] = df_final_clean['subdistrict'].astype('category')\n",
        "df_final_clean['district'] = df_final_clean['district'].astype('category')\n",
        "df_final_clean['season'] = df_final_clean['season'].astype('category')\n",
        "df_final_clean['quarter'] = df_final_clean['quarter'].astype('category')\n",
        "\n",
        "# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡∏°‡πà\n",
        "print(df_final_clean.dtypes)\n"
      ],
      "metadata": {
        "id": "W0IjCB5OwTBZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ‡∏•‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå season ‡∏ó‡∏µ‡πà‡∏ã‡πâ‡∏≥\n",
        "df_final_clean = df_final_clean.loc[:, ~df_final_clean.columns.duplicated()]\n",
        "\n",
        "# ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏• Negative Binomial\n",
        "nb_model = smf.glm(\n",
        "    formula=formula,\n",
        "    data=df_final_clean,\n",
        "    family=sm.families.NegativeBinomial()  # ‡πÉ‡∏ä‡πâ sm.families.NegativeBinomial()\n",
        ").fit()\n",
        "\n",
        "# ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•\n",
        "print(nb_model.summary())\n"
      ],
      "metadata": {
        "id": "qWCfTn4MXV0c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ‡∏™‡∏£‡∏∏‡∏õ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏ô‡∏±‡∏¢‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç p-value < 0.05\n",
        "summary_df = nb_model.summary2().tables[1]\n",
        "significant_vars = summary_df[summary_df['P>|z|'] < 0.05]\n",
        "\n",
        "print(\"\\nüìå ‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏ô‡∏±‡∏¢‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç (p-value < 0.05):\")\n",
        "print(significant_vars[['Coef.', 'Std.Err.', 'z', 'P>|z|']])\n"
      ],
      "metadata": {
        "id": "3W3DbpleXepd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö overdispersion\n",
        "mean_cases = df_final_clean['cases'].mean()\n",
        "var_cases = df_final_clean['cases'].var()\n",
        "\n",
        "print(f\"\\nMean of cases: {mean_cases:.4f}\")\n",
        "print(f\"Variance of cases: {var_cases:.4f}\")\n",
        "\n",
        "# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÄ‡∏Å‡∏¥‡∏î overdispersion ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà\n",
        "if var_cases > mean_cases:\n",
        "    print(\"üìà ‡∏°‡∏µ overdispersion ‚Üí ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö Negative Binomial\")\n",
        "else:\n",
        "    print(\"üìâ ‡πÑ‡∏°‡πà‡∏°‡∏µ overdispersion ‚Üí ‡∏≠‡∏≤‡∏à‡πÑ‡∏°‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö Negative Binomial\")\n"
      ],
      "metadata": {
        "id": "FeM2HKy2XiST"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô (Standardization)\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# ‡∏ó‡∏≥‡∏Å‡∏≤‡∏£ normalize ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ì‡πå\n",
        "df_final_clean[['temp_15d_avg', 'rain_15d_avg', 'humid_15d_avg']] = scaler.fit_transform(\n",
        "    df_final_clean[['temp_15d_avg', 'rain_15d_avg', 'humid_15d_avg']])\n",
        "\n",
        "# ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏• Negative Binomial ‡πÉ‡∏´‡∏°‡πà\n",
        "nb_model = smf.glm(\n",
        "    formula=formula,\n",
        "    data=df_final_clean,\n",
        "    family=sm.families.NegativeBinomial()\n",
        ").fit()\n",
        "\n",
        "# ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÉ‡∏´‡∏°‡πà\n",
        "predictions = nb_model.predict(df_final_clean)\n"
      ],
      "metadata": {
        "id": "F008IJYuXkET"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use rolling average for smoothing\n",
        "predictions_smooth = predictions.rolling(window=10).mean()\n",
        "actual_cases_smooth = df_final_clean['cases'].rolling(window=10).mean()\n",
        "\n",
        "# ‡∏Å‡∏£‡∏≤‡∏ü‡πÉ‡∏´‡∏°‡πà\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(predictions_smooth, label='Predicted Cases', color='blue')\n",
        "plt.plot(actual_cases_smooth, label='Actual Cases', color='red', alpha=0.6)\n",
        "plt.title(\"Smoothed Predicted vs Actual Cases\")\n",
        "plt.xlabel(\"Index\")\n",
        "plt.ylabel(\"Number of Cases\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Y79Yi9NEXnjz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏ô‡∏±‡∏¢‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç\n",
        "significant_columns = ['month', 'rain_15d_avg', 'humid_15d_avg', 'subdistrict']\n",
        "\n",
        "# ‡πÅ‡∏õ‡∏•‡∏á categorical variables ‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç\n",
        "df_final_clean_encoded = df_final_clean[significant_columns].copy()\n",
        "\n",
        "# ‡πÉ‡∏ä‡πâ LabelEncoder ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏õ‡∏•‡∏á‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡πÄ‡∏ä‡∏¥‡∏á‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç\n",
        "label_encoder = LabelEncoder()\n",
        "df_final_clean_encoded['subdistrict'] = label_encoder.fit_transform(df_final_clean_encoded['subdistrict'])\n",
        "\n",
        "# ‡∏™‡∏£‡πâ‡∏≤‡∏á X ‡πÅ‡∏•‡∏∞ y\n",
        "X = df_final_clean_encoded\n",
        "y = df_final_clean['cases']\n",
        "\n",
        "# ‡πÅ‡∏ö‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏õ‡πá‡∏ô‡∏ä‡∏∏‡∏î‡∏ù‡∏∂‡∏Å‡πÅ‡∏•‡∏∞‡∏ó‡∏î‡∏™‡∏≠‡∏ö\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏• XGBoost ‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏±‡∏ö‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå\n",
        "model = xgb.XGBRegressor(\n",
        "    objective='reg:squarederror',\n",
        "    eval_metric='rmse',\n",
        "    max_depth=5,        # ‡∏•‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡∏•‡∏∂‡∏Å‡∏Ç‡∏≠‡∏á‡∏ï‡πâ‡∏ô‡πÑ‡∏°‡πâ\n",
        "    learning_rate=0.05,  # ‡∏•‡∏î‡∏Ñ‡πà‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ\n",
        "    n_estimators=500,   # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ï‡πâ‡∏ô‡πÑ‡∏°‡πâ\n",
        "    colsample_bytree=0.8,  # ‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏ö‡πà‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏ï‡πâ‡∏ô‡πÑ‡∏°‡πâ\n",
        "    subsample=0.7,         # ‡∏Ç‡∏ô‡∏≤‡∏î‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏ä‡∏∏‡∏î‡∏¢‡πà‡∏≠‡∏¢‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å\n",
        "    gamma=0.1           # ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏±‡∏ö‡πÉ‡∏´‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÑ‡∏°‡πà‡∏ü‡∏¥‡∏ï‡∏°‡∏≤‡∏Å‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ\n",
        ")\n",
        "\n",
        "# ‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏Ñ‡πà‡∏≤‡∏ö‡∏ô‡∏ä‡∏∏‡∏î‡∏ó‡∏î‡∏™‡∏≠‡∏ö\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡πà‡∏≤ MSE (Mean Squared Error)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)  # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡πà‡∏≤‡∏£‡∏≤‡∏Å‡∏ó‡∏µ‡πà‡∏™‡∏≠‡∏á‡∏Ç‡∏≠‡∏á MSE\n",
        "print(f\"RMSE: {rmse}\")\n",
        "\n",
        "# ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡πà‡∏≤ R¬≤ (Coefficient of Determination)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print(f\"R¬≤: {r2}\")\n",
        "\n",
        "# ‡∏Å‡∏£‡∏≤‡∏ü‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏ú‡∏•‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡πÅ‡∏•‡∏∞‡∏Ñ‡πà‡∏≤‡∏à‡∏£‡∏¥‡∏á\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(y_test.values, label='Actual Cases', color='red')\n",
        "plt.plot(y_pred, label='Predicted Cases', color='blue')\n",
        "plt.title('Predicted vs Actual Cases')\n",
        "plt.xlabel('Index')\n",
        "plt.ylabel('Number of Cases')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Feature Importance\n",
        "xgb.plot_importance(model, importance_type='weight', max_num_features=10, title=\"Feature Importance\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "2cA5jlADcEHP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# XGBoost"
      ],
      "metadata": {
        "id": "mpljdokceuSn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏ô‡∏±‡∏¢‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç\n",
        "significant_columns = ['rain_15d_avg', 'humid_15d_avg', 'month', 'subdistrict']\n",
        "\n",
        "# ‡πÅ‡∏õ‡∏•‡∏á categorical variables ‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç\n",
        "df_final_clean_encoded = df_final_clean[significant_columns].copy()\n",
        "\n",
        "# ‡πÉ‡∏ä‡πâ One-Hot Encoding ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏õ‡∏•‡∏á‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£ subdistrict ‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡πà‡∏≤‡∏î‡∏¥‡∏à‡∏¥‡∏ï‡∏≠‡∏•\n",
        "df_final_clean_encoded = pd.get_dummies(df_final_clean_encoded, columns=['subdistrict'], drop_first=True)\n",
        "\n",
        "# ‡πÉ‡∏ä‡πâ LabelEncoder ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏õ‡∏•‡∏á‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡πÄ‡∏î‡∏∑‡∏≠‡∏ô\n",
        "label_encoder = LabelEncoder()\n",
        "df_final_clean_encoded['month'] = label_encoder.fit_transform(df_final_clean_encoded['month'])\n",
        "\n",
        "# ‡∏™‡∏£‡πâ‡∏≤‡∏á X ‡πÅ‡∏•‡∏∞ y\n",
        "X = df_final_clean_encoded\n",
        "y = df_final_clean['cases']\n",
        "\n",
        "# ‡πÅ‡∏ö‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏õ‡πá‡∏ô‡∏ä‡∏∏‡∏î‡∏ù‡∏∂‡∏Å‡πÅ‡∏•‡∏∞‡∏ó‡∏î‡∏™‡∏≠‡∏ö\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏• XGBoost ‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏±‡∏ö‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå\n",
        "model = xgb.XGBRegressor(\n",
        "    objective='reg:squarederror',\n",
        "    eval_metric='rmse',\n",
        "    max_depth=5,        # ‡∏•‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡∏•‡∏∂‡∏Å‡∏Ç‡∏≠‡∏á‡∏ï‡πâ‡∏ô‡πÑ‡∏°‡πâ\n",
        "    learning_rate=0.05,  # ‡∏•‡∏î‡∏Ñ‡πà‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ\n",
        "    n_estimators=500,   # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ï‡πâ‡∏ô‡πÑ‡∏°‡πâ\n",
        "    colsample_bytree=0.8,  # ‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏ö‡πà‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏ï‡πâ‡∏ô‡πÑ‡∏°‡πâ\n",
        "    subsample=0.7,         # ‡∏Ç‡∏ô‡∏≤‡∏î‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏ä‡∏∏‡∏î‡∏¢‡πà‡∏≠‡∏¢‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å\n",
        "    gamma=0.1           # ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏±‡∏ö‡πÉ‡∏´‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÑ‡∏°‡πà‡∏ü‡∏¥‡∏ï‡∏°‡∏≤‡∏Å‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ\n",
        ")\n",
        "\n",
        "# ‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏Ñ‡πà‡∏≤‡∏ö‡∏ô‡∏ä‡∏∏‡∏î‡∏ó‡∏î‡∏™‡∏≠‡∏ö\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡πà‡∏≤ MSE (Mean Squared Error)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)  # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡πà‡∏≤‡∏£‡∏≤‡∏Å‡∏ó‡∏µ‡πà‡∏™‡∏≠‡∏á‡∏Ç‡∏≠‡∏á MSE\n",
        "print(f\"RMSE: {rmse}\")\n",
        "\n",
        "# ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡πà‡∏≤ R¬≤ (Coefficient of Determination)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print(f\"R¬≤: {r2}\")\n",
        "\n",
        "# ‡∏Å‡∏£‡∏≤‡∏ü‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏ú‡∏•‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡πÅ‡∏•‡∏∞‡∏Ñ‡πà‡∏≤‡∏à‡∏£‡∏¥‡∏á\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(y_test.values, label='Actual Cases', color='red')\n",
        "plt.plot(y_pred, label='Predicted Cases', color='blue')\n",
        "plt.title('Predicted vs Actual Cases')\n",
        "plt.xlabel('Index')\n",
        "plt.ylabel('Number of Cases')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Feature Importance\n",
        "xgb.plot_importance(model, importance_type='weight', max_num_features=10, title=\"Feature Importance\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "EhDvcq3mvIg_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gradient Boosting"
      ],
      "metadata": {
        "id": "B5j9pzbeeo3n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏ô‡∏±‡∏¢‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç\n",
        "significant_columns = ['rain_15d_avg', 'month', 'subdistrict', 'humid_15d_avg']\n",
        "\n",
        "# ‡πÅ‡∏õ‡∏•‡∏á categorical variables ‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç\n",
        "df_final_clean_encoded = df_final_clean[significant_columns].copy()\n",
        "\n",
        "# ‡πÉ‡∏ä‡πâ LabelEncoder ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏õ‡∏•‡∏á‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡πÄ‡∏ä‡∏¥‡∏á‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç\n",
        "label_encoder = LabelEncoder()\n",
        "df_final_clean_encoded['subdistrict'] = label_encoder.fit_transform(df_final_clean_encoded['subdistrict'])\n",
        "\n",
        "# ‡∏™‡∏£‡πâ‡∏≤‡∏á X ‡πÅ‡∏•‡∏∞ y\n",
        "X = df_final_clean_encoded\n",
        "y = df_final_clean['cases']\n",
        "\n",
        "# ‡πÅ‡∏ö‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏õ‡πá‡∏ô‡∏ä‡∏∏‡∏î‡∏ù‡∏∂‡∏Å‡πÅ‡∏•‡∏∞‡∏ó‡∏î‡∏™‡∏≠‡∏ö\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏• Gradient Boosting\n",
        "gb_model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=5)\n",
        "\n",
        "# ‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•\n",
        "gb_model.fit(X_train, y_train)\n",
        "\n",
        "# ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏Ñ‡πà‡∏≤‡∏ö‡∏ô‡∏ä‡∏∏‡∏î‡∏ó‡∏î‡∏™‡∏≠‡∏ö\n",
        "y_pred = gb_model.predict(X_test)\n",
        "\n",
        "# ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡πà‡∏≤ MSE (Mean Squared Error)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)  # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡πà‡∏≤‡∏£‡∏≤‡∏Å‡∏ó‡∏µ‡πà‡∏™‡∏≠‡∏á‡∏Ç‡∏≠‡∏á MSE\n",
        "print(f\"RMSE: {rmse}\")\n",
        "\n",
        "# ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡πà‡∏≤ R¬≤ (Coefficient of Determination)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print(f\"R¬≤: {r2}\")\n",
        "\n",
        "# ‡∏Å‡∏£‡∏≤‡∏ü‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏ú‡∏•‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡πÅ‡∏•‡∏∞‡∏Ñ‡πà‡∏≤‡∏à‡∏£‡∏¥‡∏á\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(y_test.values, label='Actual Cases', color='red')\n",
        "plt.plot(y_pred, label='Predicted Cases', color='blue')\n",
        "plt.title('Predicted vs Actual Cases')\n",
        "plt.xlabel('Index')\n",
        "plt.ylabel('Number of Cases')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "uyL1lRAL0LrT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}