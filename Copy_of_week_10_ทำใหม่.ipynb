{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# โหลดและคลีนข้อมูลสภาพอากาศ\n",
        "file_path = 'rain.xlsx'\n",
        "xls = pd.ExcelFile(file_path)\n",
        "\n",
        "df_list = []\n",
        "for sheet in xls.sheet_names:\n",
        "    df = pd.read_excel(xls, sheet_name=sheet)\n",
        "    df = df.rename(columns={'ปี': 'year', 'เดือน': 'month', 'วันที่': 'day'})\n",
        "    df['year'] = pd.to_numeric(df['year'], errors='coerce')\n",
        "    df['month'] = pd.to_numeric(df['month'], errors='coerce')\n",
        "    df['day'] = pd.to_numeric(df['day'], errors='coerce')\n",
        "    df = df.dropna(subset=['year', 'month', 'day'])\n",
        "    df['วัน'] = pd.to_datetime(df[['year', 'month', 'day']], errors='coerce')\n",
        "    df = df.dropna(subset=['วัน'])\n",
        "    for col in ['อุณหภูมิ', 'ฝน', 'ชื้น']:\n",
        "        if col in df.columns:\n",
        "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "    df = df[df[['อุณหภูมิ', 'ฝน', 'ชื้น']].notna().all(axis=1)]\n",
        "    df_list.append(df)\n",
        "\n",
        "weather = pd.concat(df_list, ignore_index=True)\n",
        "weather = weather.drop_duplicates()\n",
        "weather = weather.sort_values('วัน').reset_index(drop=True)\n",
        "\n",
        "# โหลดและคลีนข้อมูลผู้ป่วย\n",
        "xls = pd.ExcelFile('DHFcc12.xlsx')\n",
        "df_list = []\n",
        "for sheet in xls.sheet_names:\n",
        "    df = pd.read_excel(xls, sheet_name=sheet)\n",
        "    df.columns = df.columns.str.strip()\n",
        "    if 'วันเริ่มป่วย' in df.columns:\n",
        "        df['วันเริ่มป่วย'] = pd.to_datetime(df['วันเริ่มป่วย'], errors='coerce')\n",
        "    for col in ['อายุ(ปี)', 'อายุ(เดือน)']:\n",
        "        if col in df.columns:\n",
        "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "    df_list.append(df)\n",
        "\n",
        "patients = pd.concat(df_list, ignore_index=True)\n",
        "patients = patients.drop_duplicates()\n",
        "patients = patients.dropna(subset=['วันเริ่มป่วย'])\n",
        "\n",
        "# สร้างคอลัมน์ ปี เดือน ไตรมาส ฤดูกาล จากวันเริ่มป่วย\n",
        "patients['ปี'] = patients['วันเริ่มป่วย'].dt.year\n",
        "patients['เดือน'] = patients['วันเริ่มป่วย'].dt.month\n",
        "patients['ไตรมาส'] = patients['วันเริ่มป่วย'].dt.quarter\n",
        "\n",
        "def assign_season(row):\n",
        "    month = row['เดือน']\n",
        "    day = row['วันเริ่มป่วย'].day\n",
        "    if (month == 2 and day >= 15) or month in [3, 4] or (month == 5 and day < 15):\n",
        "        return 'Summer'\n",
        "    elif (month == 5 and day >= 15) or month in [6, 7, 8, 9] or (month == 10 and day < 15):\n",
        "        return 'Rainy'\n",
        "    else:\n",
        "        return 'Winter'\n",
        "\n",
        "patients['ฤดูกาล'] = patients.apply(assign_season, axis=1)\n",
        "\n",
        "# เลือกคอลัมน์ที่ต้องการใช้วิเคราะห์\n",
        "selected_cols = ['วันเริ่มป่วย', 'เพศ', 'อายุ(ปี)', 'อายุ(เดือน)', 'ตำบล', 'อำเภอ',\n",
        "                 'เดือน', 'ปี', 'ไตรมาส', 'ฤดูกาล', 'อาชีพ']\n",
        "\n",
        "df_selected = patients[selected_cols]\n",
        "\n",
        "# นับจำนวนผู้ป่วยรายวัน\n",
        "daily_counts = df_selected.groupby('วันเริ่มป่วย').size().reset_index(name='จำนวนผู้ป่วย')\n",
        "\n",
        "# หา mode หรือ mean ของแต่ละตัวแปร (รายวัน)\n",
        "daily_modes = df_selected.groupby('วันเริ่มป่วย').agg({\n",
        "    'เพศ': lambda x: x.mode().iloc[0] if not x.mode().empty else None,\n",
        "    'อายุ(ปี)': 'mean',\n",
        "    'อายุ(เดือน)': 'mean',\n",
        "    'ตำบล': lambda x: x.mode().iloc[0] if not x.mode().empty else None,\n",
        "    'อำเภอ': lambda x: x.mode().iloc[0] if not x.mode().empty else None,\n",
        "    'เดือน': lambda x: x.mode().iloc[0] if not x.mode().empty else None,\n",
        "    'ปี': lambda x: x.mode().iloc[0] if not x.mode().empty else None,\n",
        "    'ไตรมาส': lambda x: x.mode().iloc[0] if not x.mode().empty else None,\n",
        "    'ฤดูกาล': lambda x: x.mode().iloc[0] if not x.mode().empty else None,\n",
        "    'อาชีพ': lambda x: x.mode().iloc[0] if not x.mode().empty else None\n",
        "}).reset_index()\n",
        "\n",
        "# รวมจำนวนผู้ป่วยกับข้อมูลตัวแปรรายวัน\n",
        "df_analysis = pd.merge(daily_counts, daily_modes, on='วันเริ่มป่วย', how='left')\n",
        "\n",
        "# รวมกับข้อมูลสภาพอากาศ (merge โดยใช้วันเริ่มป่วย = วัน)\n",
        "df_analysis = pd.merge(\n",
        "    df_analysis,\n",
        "    weather[['วัน', 'อุณหภูมิ', 'ฝน', 'ชื้น']],\n",
        "    left_on='วันเริ่มป่วย',\n",
        "    right_on='วัน',\n",
        "    how='left'\n",
        ").drop(columns=['วัน'])\n",
        "# เรียงข้อมูลตามวันก่อน เพื่อ rolling ให้ถูกต้อง\n",
        "df_analysis = df_analysis.sort_values('วันเริ่มป่วย')\n",
        "\n",
        "# สร้างค่าเฉลี่ยย้อนหลัง 15 วัน\n",
        "df_analysis['temp_avg15'] = df_analysis['อุณหภูมิ'].rolling(window=15).mean()\n",
        "df_analysis['rain_avg15'] = df_analysis['ฝน'].rolling(window=15).mean()\n",
        "df_analysis['humidity_avg15'] = df_analysis['ชื้น'].rolling(window=15).mean()\n",
        "\n",
        "# ลบข้อมูลแถวที่ยังไม่ครบ 15 วันแรก (NaN)\n",
        "df_analysis = df_analysis.dropna(subset=['temp_avg15', 'rain_avg15', 'humidity_avg15'])\n",
        "\n",
        "\n",
        "# แสดงข้อมูลตัวอย่าง\n",
        "print(df_analysis.head())\n"
      ],
      "metadata": {
        "id": "7SNQF7fw1_Mz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_analysis.columns)\n"
      ],
      "metadata": {
        "id": "BWTqk_UHJ74T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_analysis = df_analysis.rename(columns={\n",
        "    'วันเริ่มป่วย': 'date',\n",
        "    'จำนวนผู้ป่วย': 'cases',\n",
        "    'เพศ': 'gender',\n",
        "    'อายุ(ปี)': 'age_year',\n",
        "    'อายุ(เดือน)': 'age_month',\n",
        "    'ตำบล': 'subdistrict',\n",
        "    'อำเภอ': 'district',\n",
        "    'เดือน': 'month',\n",
        "    'ปี': 'year',\n",
        "    'ไตรมาส': 'quarter',\n",
        "    'ฤดูกาล': 'season',\n",
        "    'อาชีพ': 'occupation',\n",
        "    'อุณหภูมิ': 'temperature',\n",
        "    'ฝน': 'rainfall',\n",
        "    'ชื้น': 'humidity'\n",
        "})\n"
      ],
      "metadata": {
        "id": "k_-P4UA8Kq2p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "numeric_cols = ['cases', 'temperature', 'rainfall', 'humidity',\n",
        "                'temp_avg15', 'rain_avg15', 'humidity_avg15',\n",
        "                'age_year', 'age_month', 'month', 'year', 'quarter']\n",
        "\n",
        "df_corr = df_analysis[numeric_cols].copy()\n",
        "\n",
        "# คำนวณค่า Correlation matrix\n",
        "correlation_matrix = df_corr.corr()\n",
        "\n",
        "# วาด heatmap\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", square=True)\n",
        "plt.title('Correlation Matrix with Dengue Cases')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# แสดงคอลัมน์ที่สัมพันธ์กับจำนวนผู้ป่วย เรียงจากมากไปน้อย\n",
        "print(correlation_matrix['cases'].sort_values(ascending=False))\n"
      ],
      "metadata": {
        "id": "eEMkPSmzKIu0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "import statsmodels.formula.api as smf\n",
        "\n",
        "# สมมติ df_analysis มีข้อมูลครบและมีคอลัมน์:\n",
        "# 'จำนวนผู้ป่วย' (cases), 'year', 'rain_avg15', 'temp_avg15', 'เพศ', 'อำเภอ', 'ฤดูกาล'\n",
        "\n",
        "# เปลี่ยนชื่อคอลัมน์ภาษาไทยเป็นอังกฤษให้สะดวก\n",
        "df_analysis = df_analysis.rename(columns={\n",
        "    'จำนวนผู้ป่วย': 'cases',\n",
        "    'เพศ': 'gender',\n",
        "    'อำเภอ': 'district',\n",
        "    'ฤดูกาล': 'season'\n",
        "})\n",
        "\n",
        "# สร้าง dummy variables สำหรับ categorical ตัวแปร gender, district, season\n",
        "df_analysis = pd.get_dummies(df_analysis, columns=['gender', 'district', 'season'], drop_first=True)\n",
        "\n",
        "# ดู columns ที่ใช้\n",
        "print(df_analysis.columns)\n"
      ],
      "metadata": {
        "id": "a3ZZU0XrK_sC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_analysis.columns)\n"
      ],
      "metadata": {
        "id": "23m4Q60hL17i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# เปลี่ยนชื่อคอลัมน์เป็นอังกฤษง่ายๆ\n",
        "df_analysis = df_analysis.rename(columns={\n",
        "    'วันเริ่มป่วย': 'date',\n",
        "    'จำนวนผู้ป่วย': 'cases',\n",
        "    'เพศ': 'gender',\n",
        "    'อายุ(ปี)': 'age_year',\n",
        "    'อายุ(เดือน)': 'age_month',\n",
        "    'ตำบล': 'district',\n",
        "    'อำเภอ': 'subdistrict',\n",
        "    'เดือน': 'month',\n",
        "    'ปี': 'year',\n",
        "    'ไตรมาส': 'quarter',\n",
        "    'ฤดูกาล': 'season',\n",
        "    'อาชีพ': 'occupation',\n",
        "    'อุณหภูมิ': 'temperature',\n",
        "    'ฝน': 'rainfall',\n",
        "    'ชื้น': 'humidity',\n",
        "    'temp_avg15': 'temp_avg15',\n",
        "    'rain_avg15': 'rain_avg15',\n",
        "    'humidity_avg15': 'humidity_avg15'\n",
        "})\n",
        "\n",
        "# สร้าง dummy variables สำหรับ categorical variables\n",
        "df_analysis = pd.get_dummies(df_analysis, columns=['gender', 'district', 'season'], drop_first=True)\n",
        "\n",
        "# ตรวจสอบคอลัมน์หลังสร้าง dummy\n",
        "print(df_analysis.columns)\n",
        "\n",
        "# สร้างสูตรโมเดล (ใช้ตัวแปรที่ต้องการ)\n",
        "numeric_vars = ['year', 'rain_avg15', 'temp_avg15', 'humidity_avg15', 'age_year', 'age_month', 'month', 'quarter']\n",
        "dummy_vars = [col for col in df_analysis.columns if col.startswith('gender_') or col.startswith('district_') or col.startswith('season_')]\n",
        "all_vars = numeric_vars + dummy_vars\n",
        "\n",
        "formula = 'cases ~ ' + ' + '.join(all_vars)\n",
        "print(formula)\n",
        "\n",
        "# Fit โมเดล Negative Binomial\n",
        "nb_model = smf.glm(formula=formula, data=df_analysis, family=sm.families.NegativeBinomial()).fit()\n",
        "\n",
        "# ดูสรุปผลโมเดล\n",
        "print(nb_model.summary())\n"
      ],
      "metadata": {
        "id": "8rnLTUgqLBYW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dcAxCUqoLDmV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_analysis.to_excel('summary.xlsx', index=False)\n",
        "print(\"บันทึกไฟล์ summary.xlsx เรียบร้อยแล้ว\")\n"
      ],
      "metadata": {
        "id": "obElMix02-Uz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"จำนวนวันที่ผู้ป่วยเริ่มป่วยที่ไม่ซ้ำ:\", patients['วันเริ่มป่วย'].nunique())\n",
        "print(\"จำนวนแถวรวมข้อมูลผู้ป่วย:\", len(patients))\n"
      ],
      "metadata": {
        "id": "r3lil884_aJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# เลือกเฉพาะตัวเลข\n",
        "num_cols = ['จำนวนผู้ป่วย', 'อายุ(ปี)', 'อายุ(เดือน)', 'เดือน', 'ปี', 'อุณหภูมิ', 'ฝน', 'ชื้น']\n",
        "print(df_analysis[num_cols].corr()['จำนวนผู้ป่วย'])\n"
      ],
      "metadata": {
        "id": "ErBSbOyGAB0r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# สมมติ df_analysis โหลดมาแล้ว พร้อมข้อมูลครบถ้วน\n",
        "\n",
        "# 1. ดู correlation ของตัวแปรเชิงตัวเลขกับจำนวนผู้ป่วย\n",
        "num_cols = ['จำนวนผู้ป่วย', 'อายุ(ปี)', 'อายุ(เดือน)', 'เดือน', 'ปี', 'อุณหภูมิ', 'ฝน', 'ชื้น']\n",
        "print(\"Correlation matrix กับ จำนวนผู้ป่วย:\")\n",
        "print(df_analysis[num_cols].corr()['จำนวนผู้ป่วย'].sort_values(ascending=False))\n",
        "print(\"\\n\")\n",
        "\n",
        "# 2. ดูค่าเฉลี่ยจำนวนผู้ป่วยตามกลุ่มของตัวแปรเชิงหมวดหมู่\n",
        "categorical_cols = ['เพศ', 'ตำบล', 'อำเภอ', 'ไตรมาส', 'ฤดูกาล', 'อาชีพ']\n",
        "\n",
        "for col in categorical_cols:\n",
        "    print(f\"ค่าเฉลี่ยจำนวนผู้ป่วยตาม {col}:\")\n",
        "    mean_cases = df_analysis.groupby(col)['จำนวนผู้ป่วย'].mean().sort_values(ascending=False)\n",
        "    print(mean_cases)\n",
        "    print(\"\\n\")\n",
        "\n",
        "# 3. (ถ้าต้องการ) สรุปข้อมูลใน DataFrame เพื่อง่ายต่อการวิเคราะห์\n",
        "summary = {}\n",
        "\n",
        "# correlation\n",
        "summary['correlation'] = df_analysis[num_cols].corr()['จำนวนผู้ป่วย']\n",
        "\n",
        "# ค่าเฉลี่ยจำนวนผู้ป่วยตามกลุ่ม categorical\n",
        "for col in categorical_cols:\n",
        "    summary[col] = df_analysis.groupby(col)['จำนวนผู้ป่วย'].mean()\n",
        "\n",
        "# แสดงสรุปแบบง่าย\n",
        "print(\"สรุปความสัมพันธ์:\")\n",
        "for key, value in summary.items():\n",
        "    print(f\"--- {key} ---\")\n",
        "    print(value)\n",
        "    print()\n"
      ],
      "metadata": {
        "id": "Sx-oc3LrAUTZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.heatmap(df_analysis[num_cols].corr(), annot=True, cmap='coolwarm')\n",
        "plt.title('Correlation Matrix of Numeric Variables')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "8ZW2TbAmBMA2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# จำนวนวันที่มีผู้ป่วย = 0\n",
        "num_zero_days = (df_analysis['จำนวนผู้ป่วย'] == 0).sum()\n",
        "\n",
        "# จำนวนวันทั้งหมด\n",
        "total_days = df_analysis.shape[0]\n",
        "\n",
        "# เปอร์เซ็นต์วันที่มีผู้ป่วย = 0\n",
        "percent_zero = num_zero_days / total_days * 100\n",
        "\n",
        "print(f\"จำนวนวันที่มีผู้ป่วย = 0: {num_zero_days} วัน\")\n",
        "print(f\"จำนวนวันทั้งหมด: {total_days} วัน\")\n",
        "print(f\"เปอร์เซ็นต์วันที่มีผู้ป่วย = 0: {percent_zero:.2f}%\")\n"
      ],
      "metadata": {
        "id": "Jgz4HZ5OFXbQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# เปลี่ยนชื่อคอลัมน์ใน df_analysis เป็นอังกฤษเพื่อความง่ายในการใช้สูตรโมเดล\n",
        "df_analysis = df_analysis.rename(columns={\n",
        "    'วันเริ่มป่วย': 'date',\n",
        "    'จำนวนผู้ป่วย': 'cases',\n",
        "    'เพศ': 'gender',\n",
        "    'อายุ(ปี)': 'age_year',\n",
        "    'อายุ(เดือน)': 'age_month',\n",
        "    'ตำบล': 'subdistrict',\n",
        "    'อำเภอ': 'district',\n",
        "    'เดือน': 'month',\n",
        "    'ปี': 'year',\n",
        "    'ไตรมาส': 'quarter',\n",
        "    'ฤดูกาล': 'season',\n",
        "    'อาชีพ': 'occupation',\n",
        "    'อุณหภูมิ': 'temperature',\n",
        "    'ฝน': 'rainfall',\n",
        "    'ชื้น': 'humidity'\n",
        "})\n",
        "\n",
        "# ดูตัวอย่างข้อมูลที่แปลงแล้ว\n",
        "print(df_analysis.head())\n"
      ],
      "metadata": {
        "id": "Vwj5YD38FzG1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "sns.histplot(df_analysis['cases'], bins=30)\n",
        "plt.title('Distribution of Daily Dengue Cases')\n",
        "plt.show()\n",
        "print(df_analysis['cases'].describe())\n"
      ],
      "metadata": {
        "id": "BDQLo__7GShn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean_cases = df_analysis['cases'].mean()\n",
        "var_cases = df_analysis['cases'].var()\n",
        "print(f\"Mean: {mean_cases}, Variance: {var_cases}\")\n",
        "\n",
        "if var_cases > mean_cases:\n",
        "    print(\"พบ Overdispersion แนะนำใช้ Negative Binomial Regression\")\n",
        "else:\n",
        "    print(\"Poisson Regression น่าจะเหมาะสม\")\n"
      ],
      "metadata": {
        "id": "wr7pBo_eGmt3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.formula.api as smf\n",
        "\n",
        "# สูตรโมเดล รวมตัวแปร numeric กับ categorical (ใช้ C() ครอบ categorical variables)\n",
        "formula = (\n",
        "    'cases ~ temperature + rainfall + humidity + month + year + age_year + age_month + '\n",
        "    'C(gender) + C(subdistrict) + C(district) + C(quarter) + C(season) + C(occupation)'\n",
        ")\n",
        "\n",
        "# Fit Negative Binomial Regression\n",
        "nb_model = smf.glm(formula=formula, data=df_analysis, family=sm.families.NegativeBinomial()).fit()\n",
        "\n",
        "# แสดงสรุปผลโมเดล\n",
        "print(nb_model.summary())\n"
      ],
      "metadata": {
        "id": "gjLXaLfwHFvT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ดึงผลสรุปตารางแบบ DataFrame\n",
        "summary_df = nb_model.summary2().tables[1]\n",
        "\n",
        "# กรองเฉพาะตัวแปรที่ p-value < 0.05 (นัยสำคัญ)\n",
        "significant_vars = summary_df[summary_df['P>|z|'] < 0.05]\n",
        "\n",
        "print(\"ตัวแปรที่มีนัยสำคัญ (p < 0.05):\")\n",
        "print(significant_vars)\n"
      ],
      "metadata": {
        "id": "o66eM9R2H5Lt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sig_var_names = significant_vars.index.tolist()\n",
        "print(\"ชื่อตัวแปรที่มีนัยสำคัญ:\", sig_var_names)\n"
      ],
      "metadata": {
        "id": "HlT1Gju7H8Q-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ดึงตัวแปรที่มีนัยสำคัญ (p < 0.05)\n",
        "summary_df = nb_model.summary2().tables[1]\n",
        "significant_vars = summary_df[summary_df['P>|z|'] < 0.05]\n",
        "sig_var_names = significant_vars.index.tolist()\n",
        "\n",
        "# ลบ intercept ออก เพราะไม่ต้องใส่ในสูตร\n",
        "if 'Intercept' in sig_var_names:\n",
        "    sig_var_names.remove('Intercept')\n",
        "\n",
        "print(\"ตัวแปรนัยสำคัญ:\", sig_var_names)\n",
        "\n",
        "# สร้างสูตรใหม่\n",
        "# ต้องแปลงชื่อ categorical variables ให้เหมาะสม เช่น 'C(gender)[T.male]' ให้เป็น 'C(gender)'\n",
        "# เอาแค่ชื่อหลักมาใช้ โดยกรองชื่อที่ขึ้นต้นด้วย 'C(' หรือไม่มี 'C(' ก็เอา\n",
        "\n",
        "def clean_var_name(var):\n",
        "    # ถ้าเป็น dummy variable เช่น 'C(gender)[T.male]' ให้ return 'C(gender)'\n",
        "    if var.startswith('C('):\n",
        "        return var.split('[')[0]\n",
        "    else:\n",
        "        return var\n",
        "\n",
        "clean_vars = list(set([clean_var_name(v) for v in sig_var_names]))\n",
        "\n",
        "# สร้างสูตรใหม่ (รวมตัวแปร categorical ด้วย C())\n",
        "formula_new = 'cases ~ ' + ' + '.join(clean_vars)\n",
        "\n",
        "print(\"สูตรใหม่:\", formula_new)\n",
        "\n",
        "# Fit โมเดลใหม่\n",
        "nb_model2 = smf.glm(formula=formula_new, data=df_analysis, family=sm.families.NegativeBinomial()).fit()\n",
        "\n",
        "# แสดงสรุปโมเดลใหม่\n",
        "print(nb_model2.summary())\n"
      ],
      "metadata": {
        "id": "qBPloiioIFWd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.formula.api as smf\n",
        "\n",
        "# ดึงตารางสรุป coefficients\n",
        "summary_df = nb_model.summary2().tables[1]\n",
        "\n",
        "# เลือกตัวแปรที่ p-value < 0.05 (นัยสำคัญ)\n",
        "significant_vars = summary_df[summary_df['P>|z|'] < 0.05]\n",
        "sig_var_names = significant_vars.index.tolist()\n",
        "\n",
        "# ลบ intercept ออก\n",
        "if 'Intercept' in sig_var_names:\n",
        "    sig_var_names.remove('Intercept')\n",
        "\n",
        "print(\"ตัวแปรนัยสำคัญ:\", sig_var_names)\n",
        "\n",
        "# ฟังก์ชันแปลงชื่อตัวแปร dummy ให้เหลือเฉพาะชื่อหลัก\n",
        "def clean_var_name(var):\n",
        "    if var.startswith('C('):\n",
        "        return var.split('[')[0]  # เอาแค่ 'C(variable)'\n",
        "    else:\n",
        "        return var\n",
        "\n",
        "clean_vars = list(set([clean_var_name(v) for v in sig_var_names]))\n",
        "\n",
        "# สร้างสูตรโมเดลใหม่จากตัวแปรนัยสำคัญ\n",
        "formula_new = 'cases ~ ' + ' + '.join(clean_vars)\n",
        "print(\"สูตรโมเดลใหม่:\", formula_new)\n",
        "\n",
        "# Fit โมเดล Negative Binomial ใหม่ด้วยสูตรนี้\n",
        "nb_model2 = smf.glm(formula=formula_new, data=df_analysis, family=sm.families.NegativeBinomial()).fit()\n",
        "\n",
        "# แสดงผลสรุปโมเดลใหม่\n",
        "print(nb_model2.summary())\n"
      ],
      "metadata": {
        "id": "Y38XscxiIONL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "57z2-9LFImEv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import pandas as pd\n",
        "\n",
        "# 1. เลือก features และ target\n",
        "target = 'cases'\n",
        "features = df_analysis.drop(columns=['date', 'cases'])  # เอา 'date' กับ target ออก\n",
        "\n",
        "# แยกตัวแปรตามประเภท\n",
        "categorical_cols = features.select_dtypes(include='object').columns.tolist()\n",
        "numeric_cols = features.select_dtypes(exclude='object').columns.tolist()\n",
        "\n",
        "# 2. One-hot encoding ตัวแปรหมวดหมู่\n",
        "df_encoded = pd.get_dummies(df_analysis, columns=categorical_cols, drop_first=True)\n",
        "\n",
        "# 3. แยก X, y\n",
        "X = df_encoded.drop(columns=['date', 'cases'])\n",
        "y = df_encoded['cases']\n",
        "\n",
        "# 4. Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 5. Train Random Forest\n",
        "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "# 6. Evaluate\n",
        "y_pred = rf.predict(X_test)\n",
        "\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f'MSE: {mse:.4f}')\n",
        "print(f'R²: {r2:.4f}')\n"
      ],
      "metadata": {
        "id": "E9UzG4CqIp0W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBRegressor\n",
        "\n",
        "xgb = XGBRegressor(n_estimators=100, learning_rate=0.1, random_state=42)\n",
        "xgb.fit(X_train, y_train)\n",
        "y_pred_xgb = xgb.predict(X_test)\n",
        "\n",
        "mse_xgb = mean_squared_error(y_test, y_pred_xgb)\n",
        "r2_xgb = r2_score(y_test, y_pred_xgb)\n",
        "\n",
        "print(f\"[XGBoost] MSE: {mse_xgb:.4f}, R²: {r2_xgb:.4f}\")\n"
      ],
      "metadata": {
        "id": "RTu52010Itcx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yScpXyNyMSw_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OzHIwh04MSzp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "blG9xu5TMS2M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# --- โหลดและคลีนข้อมูลสภาพอากาศ ---\n",
        "file_path = 'rain.xlsx'\n",
        "xls = pd.ExcelFile(file_path)\n",
        "\n",
        "df_list = []\n",
        "for sheet in xls.sheet_names:\n",
        "    df = pd.read_excel(xls, sheet_name=sheet)\n",
        "    df = df.rename(columns={'ปี': 'year', 'เดือน': 'month', 'วันที่': 'day'})\n",
        "    df['year'] = pd.to_numeric(df['year'], errors='coerce')\n",
        "    df['month'] = pd.to_numeric(df['month'], errors='coerce')\n",
        "    df['day'] = pd.to_numeric(df['day'], errors='coerce')\n",
        "    df = df.dropna(subset=['year', 'month', 'day'])\n",
        "    df['วัน'] = pd.to_datetime(df[['year', 'month', 'day']], errors='coerce')\n",
        "    df = df.dropna(subset=['วัน'])\n",
        "    for col in ['อุณหภูมิ', 'ฝน', 'ชื้น']:\n",
        "        if col in df.columns:\n",
        "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "    df = df[df[['อุณหภูมิ', 'ฝน', 'ชื้น']].notna().all(axis=1)]\n",
        "    df_list.append(df)\n",
        "\n",
        "weather = pd.concat(df_list, ignore_index=True)\n",
        "weather = weather.drop_duplicates()\n",
        "weather = weather.sort_values('วัน').reset_index(drop=True)\n",
        "\n",
        "# --- โหลดและคลีนข้อมูลผู้ป่วย ---\n",
        "xls = pd.ExcelFile('DHFcc12.xlsx')\n",
        "df_list = []\n",
        "for sheet in xls.sheet_names:\n",
        "    df = pd.read_excel(xls, sheet_name=sheet)\n",
        "    df.columns = df.columns.str.strip()\n",
        "    if 'วันเริ่มป่วย' in df.columns:\n",
        "        df['วันเริ่มป่วย'] = pd.to_datetime(df['วันเริ่มป่วย'], errors='coerce')\n",
        "    for col in ['อายุ(ปี)', 'อายุ(เดือน)']:\n",
        "        if col in df.columns:\n",
        "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "    df_list.append(df)\n",
        "\n",
        "patients = pd.concat(df_list, ignore_index=True)\n",
        "patients = patients.drop_duplicates()\n",
        "patients = patients.dropna(subset=['วันเริ่มป่วย'])\n",
        "\n",
        "# สร้างคอลัมน์ ปี เดือน ไตรมาส ฤดูกาล จากวันเริ่มป่วย\n",
        "patients['ปี'] = patients['วันเริ่มป่วย'].dt.year\n",
        "patients['เดือน'] = patients['วันเริ่มป่วย'].dt.month\n",
        "patients['ไตรมาส'] = patients['วันเริ่มป่วย'].dt.quarter\n",
        "\n",
        "def assign_season(row):\n",
        "    month = row['เดือน']\n",
        "    day = row['วันเริ่มป่วย'].day\n",
        "    if (month == 2 and day >= 15) or month in [3, 4] or (month == 5 and day < 15):\n",
        "        return 'Summer'\n",
        "    elif (month == 5 and day >= 15) or month in [6, 7, 8, 9] or (month == 10 and day < 15):\n",
        "        return 'Rainy'\n",
        "    else:\n",
        "        return 'Winter'\n",
        "\n",
        "patients['ฤดูกาล'] = patients.apply(assign_season, axis=1)\n",
        "\n",
        "# เลือกคอลัมน์ที่ใช้วิเคราะห์ (ตัดอายุ(เดือน)ออกตามคำขอ)\n",
        "selected_cols = ['วันเริ่มป่วย', 'เพศ', 'อายุ(ปี)', 'ตำบล', 'อำเภอ',\n",
        "                 'เดือน', 'ปี', 'ไตรมาส', 'ฤดูกาล', 'อาชีพ']\n",
        "\n",
        "df_selected = patients[selected_cols]\n",
        "\n",
        "# นับจำนวนผู้ป่วยรายวัน\n",
        "daily_counts = df_selected.groupby('วันเริ่มป่วย').size().reset_index(name='จำนวนผู้ป่วย')\n",
        "\n",
        "# หา mode หรือ mean ของแต่ละตัวแปร (รายวัน)\n",
        "daily_modes = df_selected.groupby('วันเริ่มป่วย').agg({\n",
        "    'เพศ': lambda x: x.mode().iloc[0] if not x.mode().empty else None,\n",
        "    'อายุ(ปี)': 'mean',\n",
        "    'ตำบล': lambda x: x.mode().iloc[0] if not x.mode().empty else None,\n",
        "    'อำเภอ': lambda x: x.mode().iloc[0] if not x.mode().empty else None,\n",
        "    'เดือน': lambda x: x.mode().iloc[0] if not x.mode().empty else None,\n",
        "    'ปี': lambda x: x.mode().iloc[0] if not x.mode().empty else None,\n",
        "    'ไตรมาส': lambda x: x.mode().iloc[0] if not x.mode().empty else None,\n",
        "    'ฤดูกาล': lambda x: x.mode().iloc[0] if not x.mode().empty else None,\n",
        "    'อาชีพ': lambda x: x.mode().iloc[0] if not x.mode().empty else None\n",
        "}).reset_index()\n",
        "\n",
        "# รวมจำนวนผู้ป่วยกับข้อมูลตัวแปรรายวัน\n",
        "df_analysis = pd.merge(daily_counts, daily_modes, on='วันเริ่มป่วย', how='left')\n",
        "\n",
        "# รวมกับข้อมูลสภาพอากาศ\n",
        "df_analysis = pd.merge(\n",
        "    df_analysis,\n",
        "    weather[['วัน', 'อุณหภูมิ', 'ฝน', 'ชื้น']],\n",
        "    left_on='วันเริ่มป่วย',\n",
        "    right_on='วัน',\n",
        "    how='left'\n",
        ").drop(columns=['วัน'])\n",
        "\n",
        "# เปลี่ยนชื่อคอลัมน์เป็นอังกฤษ\n",
        "df_analysis = df_analysis.rename(columns={\n",
        "    'วันเริ่มป่วย': 'date',\n",
        "    'จำนวนผู้ป่วย': 'cases',\n",
        "    'เพศ': 'gender',\n",
        "    'อายุ(ปี)': 'age_year',\n",
        "    'ตำบล': 'district',\n",
        "    'อำเภอ': 'subdistrict',\n",
        "    'เดือน': 'month',\n",
        "    'ปี': 'year',\n",
        "    'ไตรมาส': 'quarter',\n",
        "    'ฤดูกาล': 'season',\n",
        "    'อาชีพ': 'occupation',\n",
        "    'อุณหภูมิ': 'temperature',\n",
        "    'ฝน': 'rainfall',\n",
        "    'ชื้น': 'humidity'\n",
        "})\n",
        "\n",
        "# เรียงตามวันที่\n",
        "df_analysis = df_analysis.sort_values('date').reset_index(drop=True)\n",
        "\n",
        "# สร้างฟีเจอร์ rolling mean 15 วัน (ค่าเฉลี่ยย้อนหลัง)\n",
        "window_size = 15\n",
        "for col in ['cases', 'temperature', 'rainfall', 'humidity']:\n",
        "    df_analysis[f'{col}_rolling_mean_{window_size}d'] = df_analysis[col].rolling(window=window_size, min_periods=1).mean()\n",
        "\n",
        "# ดูข้อมูลตัวอย่าง\n",
        "print(df_analysis.head(20))\n"
      ],
      "metadata": {
        "id": "jY_zIMfNMS5h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# 1. เตรียมข้อมูล\n",
        "# เลือกฟีเจอร์ที่ใช้\n",
        "features = [\n",
        "    'age_year', 'month', 'year', 'quarter', 'temperature', 'rainfall', 'humidity',\n",
        "    'cases_rolling_mean_15d', 'temperature_rolling_mean_15d', 'rainfall_rolling_mean_15d', 'humidity_rolling_mean_15d'\n",
        "]\n",
        "\n",
        "# แปลง categorical เป็น dummy variables\n",
        "df_model = df_analysis.copy()\n",
        "df_model = pd.get_dummies(df_model, columns=['gender', 'district', 'subdistrict', 'season', 'occupation'], drop_first=True)\n",
        "\n",
        "# Update features list เพิ่ม dummy columns ที่สร้างใหม่\n",
        "dummy_cols = [col for col in df_model.columns if col.startswith(('gender_', 'district_', 'subdistrict_', 'season_', 'occupation_'))]\n",
        "features += dummy_cols\n",
        "\n",
        "# กรองข้อมูลที่ไม่มีค่า missing\n",
        "df_model = df_model.dropna(subset=['cases'] + features)\n",
        "\n",
        "X = df_model[features]\n",
        "y = df_model['cases']\n",
        "\n",
        "# 2. แบ่งข้อมูล train-test (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 3. สร้างโมเดล Random Forest Regression\n",
        "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# 4. ทำนายและประเมินผล\n",
        "y_pred = model.predict(X_test)\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f'RMSE: {rmse:.2f}')\n",
        "print(f'R^2: {r2:.2f}')\n",
        "\n",
        "# 5. ดูความสำคัญของตัวแปร (feature importance)\n",
        "importances = model.feature_importances_\n",
        "feature_importance = pd.Series(importances, index=features).sort_values(ascending=False)\n",
        "\n",
        "print(\"Feature Importances:\")\n",
        "print(feature_importance.head(10))\n"
      ],
      "metadata": {
        "id": "SZVH9F9oNQpE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# กำหนด model เบื้องต้น\n",
        "xgb = XGBRegressor(objective='reg:squarederror', random_state=42)\n",
        "\n",
        "# กำหนดพารามิเตอร์ที่ต้องการลอง\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'learning_rate': [0.01, 0.05, 0.1],\n",
        "    'subsample': [0.7, 1],\n",
        "    'colsample_bytree': [0.7, 1]\n",
        "}\n",
        "\n",
        "# สร้าง GridSearchCV\n",
        "grid_search = GridSearchCV(estimator=xgb, param_grid=param_grid,\n",
        "                           cv=3, scoring='neg_mean_squared_error', verbose=1)\n",
        "\n",
        "# Fit model\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# best params\n",
        "print(\"Best parameters:\", grid_search.best_params_)\n",
        "\n",
        "# ทำนายด้วย model ที่ดีที่สุด\n",
        "best_xgb = grid_search.best_estimator_\n",
        "y_pred = best_xgb.predict(X_test)\n",
        "\n",
        "# ประเมินผล\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = mse ** 0.5\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"RMSE: {rmse:.2f}\")\n",
        "print(f\"R^2: {r2:.2f}\")\n"
      ],
      "metadata": {
        "id": "_QnSCSqhNaMd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# สมมติ X_train, X_test, y_train, y_test เตรียมไว้แล้ว (Feature เป็น numeric เท่านั้น)\n",
        "\n",
        "# สเกลข้อมูล (StandardScaler)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# สร้างโมเดลง่าย ๆ ANN\n",
        "model = Sequential([\n",
        "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    Dropout(0.3),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    Dense(1)  # output layer สำหรับ regression (ไม่มี activation)\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# ฝึกโมเดล\n",
        "history = model.fit(X_train_scaled, y_train, epochs=100, batch_size=32,\n",
        "                    validation_split=0.2, verbose=1)\n",
        "\n",
        "# ทำนายและประเมินผล\n",
        "y_pred = model.predict(X_test_scaled).flatten()\n",
        "\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Deep Learning RMSE: {rmse:.2f}\")\n",
        "print(f\"Deep Learning R^2: {r2:.2f}\")\n",
        "\n",
        "# วาดกราฟ loss train กับ validation\n",
        "plt.plot(history.history['loss'], label='train loss')\n",
        "plt.plot(history.history['val_loss'], label='val loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('MSE Loss')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "nxid9vBoOOcs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# สมมติ X_train, X_test, y_train, y_test เตรียมไว้แล้ว\n",
        "\n",
        "# สเกลข้อมูล\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# สร้างโมเดล Deep Learning ใหม่\n",
        "model = Sequential([\n",
        "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.4),  # เพิ่ม Dropout\n",
        "    Dense(32, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.3),  # เพิ่ม Dropout\n",
        "    Dense(1)  # output layer สำหรับ regression\n",
        "])\n",
        "\n",
        "# ปรับ optimizer และ learning rate\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "\n",
        "model.compile(optimizer=optimizer, loss='mse')\n",
        "\n",
        "# Early stopping เพื่อตัดการเทรนเมื่อ val_loss ไม่ลดลง 10 epochs\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "# ฝึกโมเดล\n",
        "history = model.fit(\n",
        "    X_train_scaled, y_train,\n",
        "    epochs=100,\n",
        "    batch_size=32,\n",
        "    validation_split=0.2,\n",
        "    verbose=1,\n",
        "    callbacks=[early_stop]\n",
        ")\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "y_pred = model.predict(X_test_scaled).flatten()\n",
        "\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)  # แปลง MSE เป็น RMSE\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Deep Learning RMSE: {rmse:.2f}\")\n",
        "print(f\"Deep Learning R^2: {r2:.2f}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "g9fNwV-OQ2jl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RYASYZT84KrZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "y7nKJsb54Kv9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2aLzwzbr4Ky5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Pajkr4WC4K1N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MR8KPa1u4K4G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wgvpgcTp4K7C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TZ2B6jeA4K9q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J9EfbyEk4LAr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# อันที่สอง"
      ],
      "metadata": {
        "id": "OZ6aAvLpOMQA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "#  โหลดและคลีนข้อมูลสภาพอากาศจากทุกชีท\n",
        "file_path = 'rain.xlsx'\n",
        "xls = pd.ExcelFile(file_path)\n",
        "\n",
        "df_list = []\n",
        "for sheet in xls.sheet_names:\n",
        "    df = pd.read_excel(xls, sheet_name=sheet)\n",
        "    df = df.rename(columns={'ปี': 'year', 'เดือน': 'month', 'วันที่': 'day'})  # เปลี่ยนชื่อเป็นอังกฤษ\n",
        "\n",
        "    #  แปลงวันที่เป็นตัวเลข และกรองค่าที่ว่าง\n",
        "    df['year'] = pd.to_numeric(df['year'], errors='coerce')\n",
        "    df['month'] = pd.to_numeric(df['month'], errors='coerce')\n",
        "    df['day'] = pd.to_numeric(df['day'], errors='coerce')\n",
        "    df = df.dropna(subset=['year', 'month', 'day'])\n",
        "\n",
        "    # แปลงเป็น datetime และกรองค่าที่แปลงไม่ได้\n",
        "    df['วัน'] = pd.to_datetime(df[['year', 'month', 'day']], errors='coerce')\n",
        "    df = df.dropna(subset=['วัน'])\n",
        "\n",
        "    #  แปลงคอลัมน์อุณหภูมิ/ฝน/ชื้น เป็นตัวเลข (0 ไม่ถูกลบ)\n",
        "    for col in ['อุณหภูมิ', 'ฝน', 'ชื้น']:\n",
        "        if col in df.columns:\n",
        "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "    #  กรองเฉพาะแถวที่ไม่มี NaN ในคอลัมน์หลัก (แต่ 0 ยังอยู่)\n",
        "    df = df[df[['อุณหภูมิ', 'ฝน', 'ชื้น']].notna().all(axis=1)]\n",
        "\n",
        "    df_list.append(df)\n",
        "\n",
        "#  รวมทุกชีทเข้าด้วยกัน\n",
        "weather = pd.concat(df_list, ignore_index=True)\n",
        "weather = weather.drop_duplicates()\n",
        "weather = weather.sort_values('วัน').reset_index(drop=True)\n",
        "\n",
        "#  บันทึกไฟล์ที่คลีนแล้ว\n",
        "weather.to_excel('rain_all_years_sorted3.xlsx', index=False)\n",
        "print(\" บันทึกไฟล์ rain_all_years_sorted3.xlsx เรียบร้อยแล้ว\")\n",
        "\n",
        "#  โหลดและคลีนข้อมูลผู้ป่วย\n",
        "xls = pd.ExcelFile('DHFcc12.xlsx')\n",
        "df_list = []\n",
        "\n",
        "for sheet in xls.sheet_names:\n",
        "    df = pd.read_excel(xls, sheet_name=sheet)\n",
        "    df.columns = df.columns.str.strip()  # ลบช่องว่างจากชื่อคอลัมน์\n",
        "\n",
        "    #  แปลงวันเริ่มป่วยเป็น datetime\n",
        "    if 'วันเริ่มป่วย' in df.columns:\n",
        "        df['วันเริ่มป่วย'] = pd.to_datetime(df['วันเริ่มป่วย'], errors='coerce')\n",
        "\n",
        "    #  แปลงอายุเป็นตัวเลข (0 ได้)\n",
        "    for col in ['อายุ(ปี)', 'อายุ(เดือน)']:\n",
        "        if col in df.columns:\n",
        "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "    df_list.append(df)\n",
        "\n",
        "#  รวมข้อมูลผู้ป่วย\n",
        "patients = pd.concat(df_list, ignore_index=True)\n",
        "patients = patients.drop_duplicates()\n",
        "patients = patients.dropna(subset=['วันเริ่มป่วย'])\n",
        "\n",
        "print(f\" จำนวนผู้ป่วยที่มีวันเริ่มป่วย: {len(patients)}\")\n",
        "\n",
        "#  ฟังก์ชันคำนวณ rolling average\n",
        "def get_rolling_avg(date, n_days=15):\n",
        "    start_date = date - pd.Timedelta(days=n_days)\n",
        "    mask = (weather['วัน'] >= start_date) & (weather['วัน'] < date)\n",
        "    subset = weather.loc[mask]\n",
        "    if subset.empty:\n",
        "        return pd.Series([None, None, None])\n",
        "    return pd.Series([\n",
        "        subset['อุณหภูมิ'].mean(),\n",
        "        subset['ฝน'].mean(),\n",
        "        subset['ชื้น'].mean()  #ฟังก์ชันนี้รับวันที่ date แล้วคืนค่าเฉลี่ยอุณหภูมิ ฝน และความชื้น ย้อนหลัง n_days วัน\n",
        "    ])\n",
        "\n",
        "#  เพิ่มค่าเฉลี่ยย้อนหลัง 15 วัน\n",
        "patients[['temp_15d_avg', 'rain_15d_avg', 'humid_15d_avg']] = patients['วันเริ่มป่วย'].apply(get_rolling_avg)\n",
        "\n",
        "print(\" คำนวณค่าเฉลี่ย temp, rain และ humid ย้อนหลัง 15 วันเสร็จสิ้น\")\n",
        "\n",
        "# สร้างคอลัมน์ ปี เดือน ไตรมาส ฤดูกาล\n",
        "patients['ปี'] = patients['วันเริ่มป่วย'].dt.year\n",
        "patients['เดือน'] = patients['วันเริ่มป่วย'].dt.month\n",
        "patients['ไตรมาส'] = patients['วันเริ่มป่วย'].dt.quarter\n",
        "\n",
        "#  ฟังก์ชันแบ่งฤดูแบบไทย\n",
        "def assign_season(row):\n",
        "    month = row['เดือน']\n",
        "    day = row['วันเริ่มป่วย'].day\n",
        "\n",
        "    if (month == 2 and day >= 15) or month in [3, 4] or (month == 5 and day < 15):\n",
        "        return 'Summer'\n",
        "    elif (month == 5 and day >= 15) or month in [6, 7, 8, 9] or (month == 10 and day < 15):\n",
        "        return 'Rainy'\n",
        "    else:\n",
        "        return 'Winter'\n",
        "\n",
        "patients['ฤดูกาล'] = patients.apply(assign_season, axis=1)\n",
        "\n",
        "#  สรุปรายวัน\n",
        "if 'วันพบผป' in patients.columns:\n",
        "    daily_counts = patients.groupby('วันพบผป').size().reset_index(name='จำนวนผู้ป่วย')\n",
        "\n",
        "    daily_weather = patients.groupby('วันพบผป').agg({\n",
        "        'temp_15d_avg': 'mean',\n",
        "        'rain_15d_avg': 'mean',\n",
        "        'humid_15d_avg': 'mean'\n",
        "    }).reset_index()\n",
        "\n",
        "    df_analysis = pd.merge(daily_counts, daily_weather, on='วันพบผป', how='left')\n",
        "\n",
        "    daily_vars = patients.groupby('วันพบผป').agg({\n",
        "        'อายุ(ปี)': 'mean',\n",
        "        'เพศ': lambda x: x.mode()[0] if not x.mode().empty else None,\n",
        "        'อาชีพ': lambda x: x.mode()[0] if not x.mode().empty else None,\n",
        "        'ตำบล': lambda x: x.mode()[0] if not x.mode().empty else None,\n",
        "        'อำเภอ': lambda x: x.mode()[0] if not x.mode().empty else None,\n",
        "        'เดือน': lambda x: x.mode()[0] if not x.mode().empty else None,\n",
        "        'ปี': lambda x: x.mode()[0] if not x.mode().empty else None,\n",
        "        'ไตรมาส': lambda x: x.mode()[0] if not x.mode().empty else None,\n",
        "        'ฤดูกาล': lambda x: x.mode()[0] if not x.mode().empty else None\n",
        "    }).reset_index()\n",
        "\n",
        "    df_analysis = pd.merge(df_analysis, daily_vars, on='วันพบผป', how='left')\n",
        "    print(\"✅ รวมข้อมูลผู้ป่วยกับสภาพอากาศรายวันเสร็จแล้ว\")\n",
        "else:\n",
        "    print(\"⚠️ ไม่พบคอลัมน์ 'วันพบผป' ในข้อมูลผู้ป่วย\")\n"
      ],
      "metadata": {
        "id": "mZxkp1Ms4LLT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# โหลดไฟล์\n",
        "xls = pd.ExcelFile('DHFcc12.xlsx')\n",
        "\n",
        "df_list = []\n",
        "\n",
        "for sheet in xls.sheet_names:\n",
        "    if sheet == \"Table1\":\n",
        "        continue  # ข้ามชีทที่ไม่ใช่ข้อมูลผู้ป่วย\n",
        "\n",
        "    df = pd.read_excel(xls, sheet_name=sheet)\n",
        "    df.columns = df.columns.str.strip()  # ลบช่องว่างจากชื่อคอลัมน์\n",
        "\n",
        "    # แปลงวันเริ่มป่วยเป็น datetime\n",
        "    if 'วันเริ่มป่วย' in df.columns:\n",
        "        df['วันเริ่มป่วย'] = pd.to_datetime(df['วันเริ่มป่วย'], errors='coerce')\n",
        "\n",
        "    # แปลงอายุให้เป็นตัวเลข (0 ได้)\n",
        "    for col in ['อายุ(ปี)', 'อายุ(เดือน)']:\n",
        "        if col in df.columns:\n",
        "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "    # ลบแถวที่ไม่มีวันเริ่มป่วย\n",
        "    df = df.dropna(subset=['วันเริ่มป่วย'])\n",
        "\n",
        "    # ลบแถวว่างทั้งหมด\n",
        "    df = df.dropna(how='all')\n",
        "\n",
        "    df_list.append(df)\n",
        "\n",
        "# รวมทุกชีทเข้าด้วยกัน\n",
        "patients = pd.concat(df_list, ignore_index=True)\n",
        "\n",
        "# ลบข้อมูลซ้ำ\n",
        "patients = patients.drop_duplicates()\n",
        "\n",
        "# ตรวจสอบขนาดข้อมูลสุดท้าย\n",
        "print(f\"✅ รวมข้อมูลผู้ป่วยสำเร็จ: {patients.shape[0]} แถว, {patients.shape[1]} คอลัมน์\")\n",
        "\n",
        "# แสดงตัวอย่างข้อมูล\n",
        "\n",
        "print(patients.head())\n"
      ],
      "metadata": {
        "id": "NwTK1aja8rIa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weather = pd.read_excel(\"rain_all_years_sorted3.xlsx\")\n",
        "weather['วัน'] = pd.to_datetime(weather['วัน'])\n"
      ],
      "metadata": {
        "id": "f47fzsjj49zh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_rolling_avg(date, n_days=15):\n",
        "    start_date = date - pd.Timedelta(days=n_days)\n",
        "    mask = (weather['วัน'] >= start_date) & (weather['วัน'] < date)\n",
        "    subset = weather.loc[mask]\n",
        "    if subset.empty:\n",
        "        return pd.Series([None, None, None])\n",
        "    return pd.Series([\n",
        "        subset['อุณหภูมิ'].mean(),\n",
        "        subset['ฝน'].mean(),\n",
        "        subset['ชื้น'].mean()\n",
        "    ])\n",
        "\n",
        "# เพิ่มคอลัมน์ค่าเฉลี่ยย้อนหลัง 15 วัน\n",
        "patients[['temp_15d_avg', 'rain_15d_avg', 'humid_15d_avg']] = patients['วันเริ่มป่วย'].apply(get_rolling_avg)\n"
      ],
      "metadata": {
        "id": "xytgr802-RPC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# สร้างฟีเจอร์วันที่เป็นรายวัน\n",
        "patients['date'] = patients['วันเริ่มป่วย'].dt.date\n",
        "\n",
        "# จำนวนผู้ป่วยต่อวัน\n",
        "daily_counts = patients.groupby('date').size().reset_index(name='cases')\n",
        "\n",
        "# ค่ากลางของตัวแปรรายวัน (รวม weather)\n",
        "daily_weather = patients.groupby('date').agg({\n",
        "    'temp_15d_avg': 'mean',\n",
        "    'rain_15d_avg': 'mean',\n",
        "    'humid_15d_avg': 'mean',\n",
        "    'อายุ(ปี)': 'mean',\n",
        "    'เพศ': lambda x: x.mode()[0] if not x.mode().empty else None,\n",
        "    'อาชีพ': lambda x: x.mode()[0] if not x.mode().empty else None,\n",
        "    'ตำบล': lambda x: x.mode()[0] if not x.mode().empty else None,\n",
        "    'อำเภอ': lambda x: x.mode()[0] if not x.mode().empty else None,\n",
        "    'เดือน': lambda x: x.mode()[0] if not x.mode().empty else None,\n",
        "    'ปี': lambda x: x.mode()[0] if not x.mode().empty else None,\n",
        "    'ไตรมาส': lambda x: x.mode()[0] if not x.mode().empty else None,\n",
        "    'ฤดูกาล': lambda x: x.mode()[0] if not x.mode().empty else None\n",
        "}).reset_index()\n",
        "\n",
        "# รวมข้อมูลทั้งหมด\n",
        "df_final = pd.merge(daily_counts, daily_weather, on='date', how='left')\n",
        "print(\"✅ ได้ข้อมูลรวมพร้อมใช้งานสำหรับโมเดล:\", df_final.shape)\n"
      ],
      "metadata": {
        "id": "AdqAo7sz-Tln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"ข้อมูลสุดท้าย df_final shape:\", df_final.shape)\n",
        "print(\"ตัวอย่างข้อมูล:\")\n",
        "print(df_final.head())\n",
        "print(\"ข้อมูล missing:\")\n",
        "print(df_final.isnull().sum())\n"
      ],
      "metadata": {
        "id": "3_WaThGECXvn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# โหลดข้อมูลสภาพอากาศจากทุกชีท\n",
        "file_path = 'rain.xlsx'\n",
        "xls = pd.ExcelFile(file_path)\n",
        "\n",
        "df_list = []\n",
        "for sheet in xls.sheet_names:\n",
        "    df = pd.read_excel(xls, sheet_name=sheet)\n",
        "    df = df.rename(columns={'ปี': 'year', 'เดือน': 'month', 'วันที่': 'day'})\n",
        "\n",
        "    df['year'] = pd.to_numeric(df['year'], errors='coerce')\n",
        "    df['month'] = pd.to_numeric(df['month'], errors='coerce')\n",
        "    df['day'] = pd.to_numeric(df['day'], errors='coerce')\n",
        "    df = df.dropna(subset=['year', 'month', 'day'])\n",
        "\n",
        "    df['วัน'] = pd.to_datetime(df[['year', 'month', 'day']], errors='coerce')\n",
        "    df = df.dropna(subset=['วัน'])\n",
        "\n",
        "    for col in ['อุณหภูมิ', 'ฝน', 'ชื้น']:\n",
        "        if col in df.columns:\n",
        "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "    df = df[df[['อุณหภูมิ', 'ฝน', 'ชื้น']].notna().all(axis=1)]\n",
        "    df_list.append(df)\n",
        "\n",
        "weather = pd.concat(df_list, ignore_index=True)\n",
        "weather = weather.drop_duplicates()\n",
        "weather = weather.sort_values('วัน').reset_index(drop=True)\n",
        "\n",
        "# บันทึกข้อมูลสภาพอากาศที่ clean แล้ว\n",
        "weather.to_excel('rain_all_years_sorted3.xlsx', index=False)\n",
        "print(\"✅ บันทึก rain_all_years_sorted3.xlsx เรียบร้อยแล้ว\")\n",
        "\n",
        "# โหลดข้อมูลผู้ป่วย\n",
        "xls = pd.ExcelFile('DHFcc12.xlsx')\n",
        "df_list = []\n",
        "\n",
        "for sheet in xls.sheet_names:\n",
        "    if sheet == \"Table1\":\n",
        "        continue\n",
        "\n",
        "    df = pd.read_excel(xls, sheet_name=sheet)\n",
        "    df.columns = df.columns.str.strip()\n",
        "\n",
        "    if 'วันเริ่มป่วย' in df.columns:\n",
        "        df['วันเริ่มป่วย'] = pd.to_datetime(df['วันเริ่มป่วย'], errors='coerce')\n",
        "\n",
        "    for col in ['อายุ(ปี)', 'อายุ(เดือน)']:\n",
        "        if col in df.columns:\n",
        "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "    df = df.dropna(subset=['วันเริ่มป่วย'])\n",
        "    df = df.dropna(how='all')\n",
        "\n",
        "    df_list.append(df)\n",
        "\n",
        "patients = pd.concat(df_list, ignore_index=True)\n",
        "patients = patients.drop_duplicates()\n",
        "print(f\"✅ รวมข้อมูลผู้ป่วยสำเร็จ: {patients.shape[0]} แถว, {patients.shape[1]} คอลัมน์\")\n",
        "\n",
        "# โหลด weather อีกครั้งเพื่อความชัวร์\n",
        "weather = pd.read_excel(\"rain_all_years_sorted3.xlsx\")\n",
        "weather['วัน'] = pd.to_datetime(weather['วัน'])\n",
        "\n",
        "# ฟังก์ชัน rolling average\n",
        "def get_rolling_avg(date, n_days=15):\n",
        "    start_date = date - pd.Timedelta(days=n_days)\n",
        "    mask = (weather['วัน'] >= start_date) & (weather['วัน'] < date)\n",
        "    subset = weather.loc[mask]\n",
        "    if subset.empty:\n",
        "        return pd.Series([None, None, None])\n",
        "    return pd.Series([\n",
        "        subset['อุณหภูมิ'].mean(),\n",
        "        subset['ฝน'].mean(),\n",
        "        subset['ชื้น'].mean()\n",
        "    ])\n",
        "\n",
        "# คำนวณ rolling average ย้อนหลัง 15 วัน\n",
        "patients[['temp_15d_avg', 'rain_15d_avg', 'humid_15d_avg']] = patients['วันเริ่มป่วย'].apply(get_rolling_avg)\n",
        "print(\"✅ คำนวณ rolling average เสร็จ\")\n",
        "\n",
        "# สร้างฟีเจอร์วัน/เดือน/ไตรมาส/ฤดูกาล\n",
        "patients['ปี'] = patients['วันเริ่มป่วย'].dt.year\n",
        "patients['เดือน'] = patients['วันเริ่มป่วย'].dt.month\n",
        "patients['ไตรมาส'] = patients['วันเริ่มป่วย'].dt.quarter\n",
        "\n",
        "def assign_season(row):\n",
        "    month = row['เดือน']\n",
        "    day = row['วันเริ่มป่วย'].day\n",
        "    if (month == 2 and day >= 15) or month in [3, 4] or (month == 5 and day < 15):\n",
        "        return 'Summer'\n",
        "    elif (month == 5 and day >= 15) or month in [6, 7, 8, 9] or (month == 10 and day < 15):\n",
        "        return 'Rainy'\n",
        "    else:\n",
        "        return 'Winter'\n",
        "\n",
        "patients['ฤดูกาล'] = patients.apply(assign_season, axis=1)\n",
        "\n",
        "# รวมข้อมูลรายวัน\n",
        "patients['date'] = patients['วันเริ่มป่วย'].dt.date\n",
        "daily_counts = patients.groupby('date').size().reset_index(name='cases')\n",
        "\n",
        "daily_weather = patients.groupby('date').agg({\n",
        "    'temp_15d_avg': 'mean',\n",
        "    'rain_15d_avg': 'mean',\n",
        "    'humid_15d_avg': 'mean',\n",
        "    'อายุ(ปี)': 'mean',\n",
        "    'เพศ': lambda x: x.mode()[0] if not x.mode().empty else None,\n",
        "    'อาชีพ': lambda x: x.mode()[0] if not x.mode().empty else None,\n",
        "    'ตำบล': lambda x: x.mode()[0] if not x.mode().empty else None,\n",
        "    'อำเภอ': lambda x: x.mode()[0] if not x.mode().empty else None,\n",
        "    'เดือน': lambda x: x.mode()[0] if not x.mode().empty else None,\n",
        "    'ปี': lambda x: x.mode()[0] if not x.mode().empty else None,\n",
        "    'ไตรมาส': lambda x: x.mode()[0] if not x.mode().empty else None,\n",
        "    'ฤดูกาล': lambda x: x.mode()[0] if not x.mode().empty else None\n",
        "}).reset_index()\n",
        "\n",
        "# รวมข้อมูลทั้งหมด\n",
        "df_final = pd.merge(daily_counts, daily_weather, on='date', how='left')\n",
        "print(\"✅ รวมข้อมูล df_final สำเร็จ:\", df_final.shape)\n",
        "\n",
        "# จัดการ missing\n",
        "missing_before = df_final.isnull().sum().sum()\n",
        "print(f\"⚠️ พบ missing values: {missing_before} ช่อง\")\n",
        "\n",
        "df_final_clean = df_final.dropna()\n",
        "print(\"✅ ลบ missing rows แล้ว → ขนาดข้อมูล:\", df_final_clean.shape)\n",
        "\n",
        "# บันทึกข้อมูลที่สะอาดแล้ว\n",
        "df_final_clean.to_csv(\"df_final_clean.csv\", index=False)\n",
        "df_final_clean.to_excel(\"df_final_clean.xlsx\", index=False)\n",
        "print(\"📁 บันทึกไฟล์ df_final_clean.csv และ .xlsx เรียบร้อย\")\n"
      ],
      "metadata": {
        "id": "3hpQUkEtEGGI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# บันทึกข้อมูลที่สะอาดแล้ว\n",
        "df_final_clean.to_csv(\"df_final_clean.csv\", index=False)\n",
        "df_final_clean.to_excel(\"df_final_clean.xlsx\", index=False)\n",
        "print(\"📁 บันทึกไฟล์ df_final_clean.csv และ .xlsx เรียบร้อย\")"
      ],
      "metadata": {
        "id": "CUMpSqhlLyOm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.columns)\n"
      ],
      "metadata": {
        "id": "jDrpXkWfrUem"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# แก้ชื่อคอลัมน์ให้เป็น ASCII-friendly (หรือใช้ชื่ออังกฤษทั้งหมด)\n",
        "df_clean = df_clean.rename(columns={\n",
        "    'เพศ': 'gender',\n",
        "    'อาชีพ': 'occupation',\n",
        "    'ตำบล': 'subdistrict',\n",
        "    'อำเภอ': 'district',\n",
        "    'เดือน': 'month',\n",
        "    'ไตรมาส': 'quarter'\n",
        "})\n"
      ],
      "metadata": {
        "id": "xyPGWGI1Nkm6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import scipy.stats as stats\n",
        "from scipy.stats import spearmanr, pointbiserialr, kruskal\n",
        "import statsmodels.api as sm\n",
        "import statsmodels.formula.api as smf\n",
        "\n",
        "# -----------------------------\n",
        "# ✅ 0. Load and Rename Columns\n",
        "# -----------------------------\n",
        "df = pd.read_csv(\"df_final_clean.csv\")  # ใส่ path ตามจริง\n",
        "df_clean = df.copy()\n",
        "\n",
        "# เปลี่ยนชื่อคอลัมน์ให้เป็นภาษาอังกฤษเพื่อใช้ในสูตร model\n",
        "df_clean = df_clean.rename(columns={\n",
        "    'เพศ': 'gender',\n",
        "    'อาชีพ': 'occupation',\n",
        "    'ตำบล': 'subdistrict',\n",
        "    'อำเภอ': 'district',\n",
        "    'เดือน': 'month',\n",
        "    'ไตรมาส': 'quarter',\n",
        "    'อายุ(ปี)': 'age',\n",
        "    'ฤดูกาล': 'season',\n",
        "\n",
        "})\n",
        "\n",
        "# -----------------------------\n",
        "# ✅ 1. วิเคราะห์เชิงเดี่ยว\n",
        "# -----------------------------\n",
        "target = 'cases'\n",
        "numeric_vars = ['temp_15d_avg', 'rain_15d_avg', 'humid_15d_avg']  # ตัด month_name ออก เพราะไม่มีคอลัมน์นี้\n",
        "binary_cats = ['gender']\n",
        "multi_cats = ['occupation', 'subdistrict', 'district', 'month', 'season']\n",
        "  # ใช้ month แทน month_name\n",
        "\n",
        "# แปลง gender เป็นตัวเลข (0/1)\n",
        "if 'gender' in df_clean.columns:\n",
        "    df_clean['gender_code'] = df_clean['gender'].map({'ชาย': 0, 'หญิง': 1})\n",
        "\n",
        "results = []\n",
        "\n",
        "# 1.1 Spearman correlation (numeric)\n",
        "for var in numeric_vars:\n",
        "    corr, p = spearmanr(df_clean[var], df_clean[target])\n",
        "    results.append({\n",
        "        'Variable': var,\n",
        "        'Test': 'Spearman Correlation',\n",
        "        'Stat': round(corr, 3),\n",
        "        'P-Value': round(p, 4)\n",
        "    })\n",
        "\n",
        "# 1.2 Point-Biserial (binary)\n",
        "for var in binary_cats:\n",
        "    encoded_var = var + '_code'\n",
        "    if encoded_var in df_clean.columns and df_clean[encoded_var].nunique() == 2:\n",
        "        corr, p = pointbiserialr(df_clean[encoded_var], df_clean[target])\n",
        "        results.append({\n",
        "            'Variable': var,\n",
        "            'Test': 'Point-Biserial',\n",
        "            'Stat': round(corr, 3),\n",
        "            'P-Value': round(p, 4)\n",
        "        })\n",
        "\n",
        "# 1.3 Kruskal-Wallis (multi-category)\n",
        "for var in multi_cats:\n",
        "    df_non_null = df_clean.dropna(subset=[var])\n",
        "    groups = [group[target].dropna() for name, group in df_non_null.groupby(var)]\n",
        "    if len(groups) > 1:\n",
        "        h_stat, p = kruskal(*groups)\n",
        "        results.append({\n",
        "            'Variable': var,\n",
        "            'Test': 'Kruskal-Wallis',\n",
        "            'Stat': round(h_stat, 3),\n",
        "            'P-Value': round(p, 4)\n",
        "        })\n",
        "\n",
        "# แสดงผล\n",
        "results_df = pd.DataFrame(results).sort_values('P-Value')\n",
        "print(\"\\n📊 ผลวิเคราะห์เชิงเดี่ยว (เรียงตาม p-value):\")\n",
        "print(results_df)\n",
        "\n",
        "# -----------------------------\n",
        "# ✅ 2. Negative Binomial Regression\n",
        "# -----------------------------\n",
        "print(\"\\n📈 ผลการวิเคราะห์ Negative Binomial Regression:\")\n",
        "\n",
        "formula = \"\"\"\n",
        "cases ~ temp_15d_avg + rain_15d_avg + humid_15d_avg\n",
        "+ C(gender) + C(occupation) + C(subdistrict) + C(month) + C(season)\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "nb_model = smf.glm(\n",
        "    formula=formula,\n",
        "    data=df_clean,\n",
        "    family=sm.families.NegativeBinomial()\n",
        ").fit()\n",
        "\n",
        "print(nb_model.summary())\n"
      ],
      "metadata": {
        "id": "pGPH0hnKL9Iw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# รันโมเดล Negative Binomial และเก็บผลลัพธ์\n",
        "nb_model = smf.glm(\n",
        "    formula=formula,\n",
        "    data=df_clean,\n",
        "    family=sm.families.NegativeBinomial()\n",
        ").fit()\n",
        "\n",
        "# แสดงผลสรุปโมเดล\n",
        "print(nb_model.summary())\n",
        "\n",
        "# ดึงตารางผลลัพธ์ coefficients\n",
        "summary_df = nb_model.summary2().tables[1]\n",
        "\n",
        "# กรองเฉพาะตัวแปรที่มีนัยสำคัญ p-value < 0.05\n",
        "significant_vars = summary_df[summary_df['P>|z|'] < 0.05]\n",
        "\n",
        "print(\"\\n📌 ตัวแปรที่มีนัยสำคัญ (p-value < 0.05):\")\n",
        "print(significant_vars[['Coef.', 'Std.Err.', 'z', 'P>|z|']])\n",
        "\n",
        "# ตรวจสอบ overdispersion ของข้อมูล\n",
        "mean_cases = df_clean['cases'].mean()\n",
        "var_cases = df_clean['cases'].var()\n",
        "\n",
        "print(f\"\\nMean of cases: {mean_cases:.4f}\")\n",
        "print(f\"Variance of cases: {var_cases:.4f}\")\n",
        "\n",
        "if var_cases > mean_cases:\n",
        "    print(\"📈 มี overdispersion → เหมาะกับ Negative Binomial\")\n",
        "else:\n",
        "    print(\"📉 ไม่มี overdispersion → อาจไม่เหมาะกับ Negative Binomial\")\n"
      ],
      "metadata": {
        "id": "QV7wdSRiSb3x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "import statsmodels.formula.api as smf\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "\n",
        "# โหลดข้อมูล\n",
        "df = pd.read_csv(\"df_final_clean.csv\")\n",
        "df_clean = df.copy()\n",
        "\n",
        "# เปลี่ยนชื่อคอลัมน์\n",
        "df_clean = df_clean.rename(columns={\n",
        "    'เพศ': 'gender',\n",
        "    'อาชีพ': 'occupation',\n",
        "    'ตำบล': 'subdistrict',\n",
        "    'อำเภอ': 'district',\n",
        "    'เดือน': 'month',\n",
        "    'ไตรมาส': 'quarter',\n",
        "    'อายุ(ปี)': 'age',\n",
        "    'ฤดูกาล': 'season',\n",
        "})\n",
        "\n",
        "# กำหนดสูตรโมเดล Negative Binomial\n",
        "formula = \"\"\"\n",
        "cases ~ temp_15d_avg + rain_15d_avg + humid_15d_avg\n",
        "+ C(gender) + C(occupation) + C(subdistrict) + C(month) + C(season)\n",
        "\"\"\"\n",
        "\n",
        "# รันโมเดล Negative Binomial\n",
        "nb_model = smf.glm(\n",
        "    formula=formula,\n",
        "    data=df_clean,\n",
        "    family=sm.families.NegativeBinomial()\n",
        ").fit()\n",
        "\n",
        "# แสดงผล summary\n",
        "print(nb_model.summary())\n",
        "\n",
        "# ดึงตาราง coefficients\n",
        "summary_df = nb_model.summary2().tables[1]\n",
        "\n",
        "# กรองตัวแปรที่ p-value < 0.05\n",
        "significant_vars = summary_df[summary_df['P>|z|'] < 0.05]\n",
        "\n",
        "print(\"\\n📌 ตัวแปรที่มีนัยสำคัญ (p-value < 0.05):\")\n",
        "print(significant_vars[['Coef.', 'Std.Err.', 'z', 'P>|z|']])\n",
        "\n",
        "# ตรวจสอบ overdispersion\n",
        "mean_cases = df_clean['cases'].mean()\n",
        "var_cases = df_clean['cases'].var()\n",
        "print(f\"\\nMean of cases: {mean_cases}\")\n",
        "print(f\"Variance of cases: {var_cases}\")\n",
        "\n",
        "if var_cases > mean_cases:\n",
        "    print(\"📈 มี overdispersion → เหมาะกับ Negative Binomial\")\n",
        "else:\n",
        "    print(\"📉 ไม่มี overdispersion → อาจไม่เหมาะกับ Negative Binomial\")\n",
        "\n",
        "# เตรียมข้อมูลสำหรับคำนวณ VIF (แปลง categorical เป็น dummy)\n",
        "X = pd.get_dummies(df_clean[['temp_15d_avg', 'rain_15d_avg', 'humid_15d_avg',\n",
        "                             'gender', 'occupation', 'subdistrict', 'month', 'season']], drop_first=True)\n",
        "# เติมค่า missing ถ้ามี (โดยใช้ mean)\n",
        "X = X.fillna(X.mean())\n",
        "\n",
        "# เพิ่ม constant term\n",
        "X = sm.add_constant(X)\n",
        "\n",
        "# แปลงข้อมูลเป็น float ทั้งหมดก่อนคำนวณ VIF\n",
        "X = X.astype(float)\n",
        "\n",
        "# คำนวณ VIF\n",
        "vif_data = pd.DataFrame()\n",
        "vif_data['feature'] = X.columns\n",
        "vif_data['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
        "\n",
        "print(\"\\n📊 Variance Inflation Factor (VIF):\")\n",
        "print(vif_data.sort_values(by='VIF', ascending=False))\n",
        "\n"
      ],
      "metadata": {
        "id": "vNgww1ywam5j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "import statsmodels.formula.api as smf\n",
        "\n",
        "# 1. โหลดข้อมูลและเปลี่ยนชื่อคอลัมน์\n",
        "df = pd.read_csv(\"df_final_clean.csv\")\n",
        "df_clean = df.copy()\n",
        "df_clean = df_clean.rename(columns={\n",
        "    'เพศ': 'gender',\n",
        "    'อาชีพ': 'occupation',\n",
        "    'ตำบล': 'subdistrict',\n",
        "    'อำเภอ': 'district',\n",
        "    'เดือน': 'month',\n",
        "    'ไตรมาส': 'quarter',\n",
        "    'อายุ(ปี)': 'age',\n",
        "    'ฤดูกาล': 'season',\n",
        "})\n",
        "\n",
        "# 2. แปลง categorical เป็น category dtype\n",
        "for col in ['gender', 'occupation', 'subdistrict', 'district', 'month', 'season']:\n",
        "    df_clean[col] = df_clean[col].astype('category')\n",
        "\n",
        "# 3. สร้างสูตรโมเดลใหม่ ลด occupation ออกเพื่อลด multicollinearity\n",
        "formula_reduced = \"\"\"\n",
        "cases ~ rain_15d_avg + humid_15d_avg\n",
        "+ C(subdistrict) + C(season)\n",
        "\"\"\"\n",
        "\n",
        "# 4. Fit Negative Binomial model ด้วยสูตรใหม่\n",
        "nb_model_reduced = smf.glm(\n",
        "    formula=formula_reduced,\n",
        "    data=df_clean,\n",
        "    family=sm.families.NegativeBinomial()\n",
        ").fit()\n",
        "\n",
        "# 5. แสดงผลสรุปโมเดล\n",
        "print(nb_model_reduced.summary())\n",
        "\n",
        "# 6. ดึงตารางผลลัพธ์ coefficients\n",
        "summary_df = nb_model_reduced.summary2().tables[1]\n",
        "\n",
        "# 7. กรองเฉพาะตัวแปรที่ p-value < 0.05\n",
        "significant_vars = summary_df[summary_df['P>|z|'] < 0.05]\n",
        "\n",
        "print(\"\\n📌 ตัวแปรที่มีนัยสำคัญ (p-value < 0.05):\")\n",
        "print(significant_vars[['Coef.', 'Std.Err.', 'z', 'P>|z|']])\n",
        "\n",
        "# 8. ตรวจสอบ overdispersion\n",
        "mean_cases = df_clean['cases'].mean()\n",
        "var_cases = df_clean['cases'].var()\n",
        "print(f\"\\nMean of cases: {mean_cases}\")\n",
        "print(f\"Variance of cases: {var_cases}\")\n",
        "\n",
        "if var_cases > mean_cases:\n",
        "    print(\"📈 มี overdispersion → เหมาะกับ Negative Binomial\")\n",
        "else:\n",
        "    print(\"📉 ไม่มี overdispersion → อาจไม่เหมาะกับ Negative Binomial\")\n"
      ],
      "metadata": {
        "id": "qVnv8o0ncff8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ดึงชื่อของตัวแปรที่มีนัยสำคัญ ยกเว้น Intercept\n",
        "selected_features = [var for var in significant_vars.index if var != 'Intercept']\n",
        "\n",
        "# สร้างชุดข้อมูลใหม่เฉพาะตัวแปรที่สำคัญ\n",
        "# ต้องแปลง C(...) เป็นชื่อคอลัมน์จริง\n",
        "X = pd.get_dummies(df_clean, drop_first=True)\n",
        "\n",
        "# กรองเฉพาะคอลัมน์ที่ตรงกับ selected_features\n",
        "X_selected = X[[col for col in X.columns if any(f in col for f in selected_features)]]\n",
        "\n",
        "# เป้าหมาย (Target)\n",
        "y = df_clean['cases']\n"
      ],
      "metadata": {
        "id": "1iMPGlfCnA4L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "# เลือกเฉพาะ features ที่เกี่ยวข้อง\n",
        "features = ['rain_15d_avg', 'humid_15d_avg', 'subdistrict', 'season']\n",
        "df_ml = df_clean[features + ['cases']].dropna()\n",
        "\n",
        "# One-hot encode\n",
        "df_ml = pd.get_dummies(df_ml, drop_first=True)\n",
        "\n",
        "X = df_ml.drop('cases', axis=1)\n",
        "y = df_ml['cases']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = RandomForestRegressor()\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"RMSE: {rmse:.4f}\")\n",
        "print(f\"R² Score: {r2:.4f}\")\n"
      ],
      "metadata": {
        "id": "IW6IZYc1nDfz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install xgboost scikit-learn\n"
      ],
      "metadata": {
        "id": "Z4d166Nan65s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# 1. โหลดและเตรียมข้อมูล\n",
        "df = pd.read_csv(\"df_final_clean.csv\")\n",
        "\n",
        "# เปลี่ยนชื่อคอลัมน์\n",
        "df = df.rename(columns={\n",
        "    'เพศ': 'gender',\n",
        "    'อาชีพ': 'occupation',\n",
        "    'ตำบล': 'subdistrict',\n",
        "    'อำเภอ': 'district',\n",
        "    'เดือน': 'month',\n",
        "    'ไตรมาส': 'quarter',\n",
        "    'อายุ(ปี)': 'age',\n",
        "    'ฤดูกาล': 'season',\n",
        "})\n",
        "\n",
        "# เลือกเฉพาะตัวแปรที่มีนัยสำคัญ\n",
        "features = ['subdistrict', 'season', 'rain_15d_avg', 'humid_15d_avg']\n",
        "target = 'cases'\n",
        "\n",
        "df_model = df[features + [target]].copy()\n",
        "\n",
        "# One-hot encode ตัวแปร category\n",
        "cat_cols = ['subdistrict', 'season']\n",
        "df_model = pd.get_dummies(df_model, columns=cat_cols, drop_first=True)\n",
        "\n",
        "# 2. แบ่งข้อมูล\n",
        "X = df_model.drop(columns=[target])\n",
        "y = df_model[target]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 3. สร้างโมเดล\n",
        "models = {\n",
        "    \"Random Forest\": RandomForestRegressor(random_state=42),\n",
        "    \"Gradient Boosting\": GradientBoostingRegressor(random_state=42),\n",
        "    \"XGBoost\": XGBRegressor(random_state=42),\n",
        "    \"Linear Regression\": LinearRegression()\n",
        "}\n",
        "\n",
        "# 4. เทรนและประเมินผล\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    from sklearn.metrics import mean_squared_error\n",
        "\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    rmse = mse ** 0.5\n",
        "\n",
        "    print(f\"\\n📊 ผลการประเมินโมเดล {name}:\")\n",
        "    print(f\"RMSE: {rmse:.4f}\")\n",
        "    print(f\"R² Score: {r2:.4f}\")\n"
      ],
      "metadata": {
        "id": "HrAJ4Lo0n68h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_ao12nifn6_z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "GHoEPXH3WucZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import xgboost as xgb\n",
        "\n",
        "# เตรียมข้อมูล\n",
        "df_xgb = df_clean.copy()\n",
        "\n",
        "features = ['subdistrict', 'month', 'rain_15d_avg', 'humid_15d_avg']\n",
        "target = 'cases'\n",
        "\n",
        "X = df_xgb[features]\n",
        "y = df_xgb[target]\n",
        "\n",
        "# แปลง categorical เป็น dummy variables\n",
        "X_encoded = pd.get_dummies(X, columns=['subdistrict', 'month'], drop_first=True)\n",
        "\n",
        "# แบ่งข้อมูล train/test\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_encoded, y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "# สร้าง DMatrix สำหรับ XGBoost\n",
        "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
        "dtest = xgb.DMatrix(X_test, label=y_test)\n",
        "\n",
        "# กำหนดพารามิเตอร์ XGBoost\n",
        "params = {\n",
        "    'objective': 'reg:squarederror',\n",
        "    'eval_metric': 'rmse',\n",
        "    'seed': 42\n",
        "}\n",
        "\n",
        "# Train โมเดล\n",
        "num_rounds = 100\n",
        "xgb_model = xgb.train(params, dtrain, num_rounds)\n",
        "\n",
        "# ทำนาย\n",
        "y_pred = xgb_model.predict(dtest)\n",
        "\n",
        "# ประเมินผล\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print(f\"Mean Squared Error (MSE): {mse:.3f}\")\n",
        "print(f\"R-squared (R2): {r2:.3f}\")\n",
        "\n",
        "# ดูความสำคัญของตัวแปร\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "xgb.plot_importance(xgb_model, max_num_features=10)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "EhX6pLkyRw0M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "อีกอัน\n"
      ],
      "metadata": {
        "id": "T0QgJX3GWcpl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import scipy.stats as stats\n",
        "from scipy.stats import pointbiserialr\n",
        "\n",
        "# ลิสต์ตัวแปร\n",
        "numeric_vars = ['temp_15d_avg', 'rain_15d_avg', 'humid_15d_avg', 'อายุ(ปี)']\n",
        "binary_cats = ['เพศ']\n",
        "multi_cats = ['อาชีพ', 'ตำบล', 'อำเภอ', 'เดือน', 'ไตรมาส']\n",
        "\n",
        "# ตัวแปรเป้าหมาย\n",
        "target = 'cases'\n",
        "\n",
        "# สำเนา df เพื่อตัด NaN\n",
        "df_clean = df_final.copy()\n",
        "\n",
        "# แปลง 'เพศ' เป็นตัวเลข (เช่น 'ชาย' = 0, 'หญิง' = 1)\n",
        "if 'เพศ' in df_clean.columns:\n",
        "    df_clean['เพศ_รหัส'] = df_clean['เพศ'].map({'ชาย': 0, 'หญิง': 1})\n",
        "\n",
        "# เก็บผลลัพธ์\n",
        "results = []\n",
        "\n",
        "# 1. Pearson correlation สำหรับ numeric\n",
        "for var in numeric_vars:\n",
        "    corr, p = stats.pearsonr(df_clean[var], df_clean[target])\n",
        "    results.append({\n",
        "        'Variable': var,\n",
        "        'Test': 'Pearson',\n",
        "        'Stat': round(corr, 3),\n",
        "        'P-Value': round(p, 4)\n",
        "    })\n",
        "\n",
        "# 2. Point-Biserial สำหรับ binary (หลัง encode แล้ว)\n",
        "for var in binary_cats:\n",
        "    encoded_var = var + '_รหัส'\n",
        "    if encoded_var in df_clean.columns and df_clean[encoded_var].nunique() == 2:\n",
        "        corr, p = pointbiserialr(df_clean[encoded_var], df_clean[target])\n",
        "        results.append({\n",
        "            'Variable': var,\n",
        "            'Test': 'Point-Biserial',\n",
        "            'Stat': round(corr, 3),\n",
        "            'P-Value': round(p, 4)\n",
        "        })\n",
        "\n",
        "# 3. ANOVA สำหรับ multi-category\n",
        "for var in multi_cats:\n",
        "    df_non_null = df_clean.dropna(subset=[var])\n",
        "    groups = [group[target].dropna() for name, group in df_non_null.groupby(var)]\n",
        "    if len(groups) > 1:\n",
        "        f_stat, p = stats.f_oneway(*groups)\n",
        "        results.append({\n",
        "            'Variable': var,\n",
        "            'Test': 'ANOVA',\n",
        "            'Stat': round(f_stat, 3),\n",
        "            'P-Value': round(p, 4)\n",
        "        })\n",
        "\n",
        "# แสดงผลลัพธ์\n",
        "results_df = pd.DataFrame(results).sort_values('P-Value')\n",
        "print(\"\\n📊 สรุปผลการทดสอบความสัมพันธ์ (เรียงตาม p-value):\")\n",
        "print(results_df)\n"
      ],
      "metadata": {
        "id": "XYyfQdBqi6-A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# กรองเฉพาะตัวแปรที่มีนัยสำคัญ\n",
        "significant_vars = results_df[results_df['P-Value'] < 0.05]['Variable'].tolist()\n",
        "\n",
        "# แสดงผล\n",
        "print(\"✅ ตัวแปรที่ผ่านการคัดเลือก:\", significant_vars)\n"
      ],
      "metadata": {
        "id": "uGHfm8xCQ75g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_selected.head())\n"
      ],
      "metadata": {
        "id": "IY3Ro4oqN6ta"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df[significant_vars]\n",
        "y = df['cases']\n"
      ],
      "metadata": {
        "id": "aw1ipEjKkCZG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# สมมติ df_selected คือ dataframe ที่ได้จากการเลือกตัวแปรแล้ว\n",
        "# แยก features และ target\n",
        "X = df_selected.drop(columns=['cases'])\n",
        "y = df_selected['cases']\n",
        "\n",
        "# หาคอลัมน์ที่เป็น categorical\n",
        "cat_cols = X.select_dtypes(include=['object', 'category']).columns\n",
        "\n",
        "# ทำ One-Hot Encoding\n",
        "X_encoded = pd.get_dummies(X, columns=cat_cols, drop_first=True)\n",
        "\n",
        "print(X_encoded.head())\n"
      ],
      "metadata": {
        "id": "jpGLnewgN6xd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_encoded, y, test_size=0.2, random_state=42\n",
        ")\n"
      ],
      "metadata": {
        "id": "8Iyw44-Nd7QI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "import numpy as np\n",
        "\n",
        "# สร้างและฝึกโมเดล\n",
        "rf = RandomForestRegressor(random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "# ทำนายข้อมูลทดสอบ\n",
        "y_pred_rf = rf.predict(X_test)\n",
        "\n",
        "# คำนวณ metric ต่าง ๆ\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred_rf))\n",
        "r2 = r2_score(y_test, y_pred_rf)\n",
        "mae = mean_absolute_error(y_test, y_pred_rf)\n",
        "\n",
        "print(f\"RandomForest R2: {r2:.4f}\")\n",
        "print(f\"RandomForest RMSE: {rmse:.4f}\")\n",
        "print(f\"RandomForest MAE: {mae:.4f}\")\n"
      ],
      "metadata": {
        "id": "VZ36yvyYd5Vg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "import numpy as np\n",
        "\n",
        "# กำหนดพารามิเตอร์ที่ต้องการลอง\n",
        "param_dist = {\n",
        "    'n_estimators': [100, 200, 300, 500],\n",
        "    'max_depth': [None, 10, 20, 30, 50],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'max_features': ['auto', 'sqrt', 'log2']\n",
        "}\n",
        "\n",
        "rf = RandomForestRegressor(random_state=42)\n",
        "\n",
        "# ใช้ RandomizedSearchCV เพื่อหาพารามิเตอร์ที่ดีที่สุด\n",
        "search = RandomizedSearchCV(\n",
        "    estimator=rf,\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=20,  # จำนวนรอบสุ่มลองพารามิเตอร์\n",
        "    cv=5,\n",
        "    scoring='neg_mean_squared_error',\n",
        "    random_state=42,\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "search.fit(X_train, y_train)\n",
        "\n",
        "# โมเดลที่ดีที่สุด\n",
        "best_rf = search.best_estimator_\n",
        "\n",
        "# ทำนายข้อมูลทดสอบ\n",
        "y_pred_rf = best_rf.predict(X_test)\n",
        "\n",
        "# คำนวณ metric\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred_rf))\n",
        "r2 = r2_score(y_test, y_pred_rf)\n",
        "mae = mean_absolute_error(y_test, y_pred_rf)\n",
        "\n",
        "print(f\"Best Parameters: {search.best_params_}\")\n",
        "print(f\"RandomForest R2: {r2:.4f}\")\n",
        "print(f\"RandomForest RMSE: {rmse:.4f}\")\n",
        "print(f\"RandomForest MAE: {mae:.4f}\")\n"
      ],
      "metadata": {
        "id": "LB3F56OHnLkY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "import numpy as np\n",
        "\n",
        "# กำหนดพารามิเตอร์ที่ต้องการลอง\n",
        "param_dist = {\n",
        "    'n_estimators': [100, 200, 300, 500],\n",
        "    'max_depth': [None, 10, 20, 30, 50],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'max_features': ['auto', 'sqrt', 'log2']\n",
        "}\n",
        "\n",
        "rf = RandomForestRegressor(random_state=42)\n",
        "\n",
        "# ใช้ RandomizedSearchCV เพื่อหาพารามิเตอร์ที่ดีที่สุด\n",
        "search = RandomizedSearchCV(\n",
        "    estimator=rf,\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=20,  # จำนวนรอบสุ่มลองพารามิเตอร์\n",
        "    cv=5,\n",
        "    scoring='neg_mean_squared_error',\n",
        "    random_state=42,\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "search.fit(X_train, y_train)\n",
        "\n",
        "# โมเดลที่ดีที่สุด\n",
        "best_rf = search.best_estimator_\n",
        "\n",
        "# ทำนายข้อมูลทดสอบ\n",
        "y_pred_rf = best_rf.predict(X_test)\n",
        "\n",
        "# คำนวณ metric\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred_rf))\n",
        "r2 = r2_score(y_test, y_pred_rf)\n",
        "mae = mean_absolute_error(y_test, y_pred_rf)\n",
        "\n",
        "print(f\"Best Parameters: {search.best_params_}\")\n",
        "print(f\"RandomForest R2: {r2:.4f}\")\n",
        "print(f\"RandomForest RMSE: {rmse:.4f}\")\n",
        "print(f\"RandomForest MAE: {mae:.4f}\")\n"
      ],
      "metadata": {
        "id": "zYP6mMdgd5YV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# XGBOOST"
      ],
      "metadata": {
        "id": "SUqdvLZfuDRy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install xgboost\n"
      ],
      "metadata": {
        "id": "RPUiE7v4uK0w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "\n",
        "# ✅ ตัวแปรที่เลือกไว้\n",
        "selected_features = ['ตำบล', 'อำเภอ', 'ไตรมาส', 'เดือน', 'อาชีพ', 'temp_15d_avg', 'rain_15d_avg']\n",
        "\n",
        "# ✅ เตรียม X, y\n",
        "X = df[selected_features].copy()\n",
        "y = df['cases']\n",
        "\n",
        "# ✅ interaction term\n",
        "X['ฝน_อุณหภูมิ'] = X['temp_15d_avg'] * X['rain_15d_avg']\n",
        "\n",
        "# ✅ แบ่ง train/test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# ✅ Categorical & numeric columns\n",
        "categorical_cols = ['ตำบล', 'อำเภอ', 'ไตรมาส', 'เดือน', 'อาชีพ']\n",
        "numeric_cols = ['temp_15d_avg', 'rain_15d_avg']\n",
        "\n",
        "# ✅ Preprocessing\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)\n",
        "], remainder='passthrough')  # numeric ผ่านตรง\n",
        "\n",
        "# ✅ สร้าง Pipeline\n",
        "xgb_model = xgb.XGBRegressor(objective='reg:squarederror', random_state=42)\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('regressor', xgb_model)\n",
        "])\n",
        "\n",
        "# ✅ Hyperparameter tuning\n",
        "param_dist = {\n",
        "    'regressor__n_estimators': [100, 200, 300, 500],\n",
        "    'regressor__max_depth': [4, 6, 8, 10],\n",
        "    'regressor__learning_rate': [0.03, 0.05, 0.07],\n",
        "    'regressor__subsample': [0.6, 0.7, 0.8],\n",
        "    'regressor__colsample_bytree': [0.6, 0.8, 1.0],\n",
        "    'regressor__gamma': [0, 0.1, 0.3],\n",
        "    'regressor__reg_alpha': [0, 0.01, 0.1],\n",
        "    'regressor__reg_lambda': [1, 1.5, 2]\n",
        "}\n",
        "\n",
        "search = RandomizedSearchCV(\n",
        "    estimator=pipeline,\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=150,\n",
        "    cv=5,\n",
        "    scoring='neg_mean_squared_error',\n",
        "    random_state=42,\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# ✅ เทรน\n",
        "search.fit(X_train, y_train)\n",
        "\n",
        "# ✅ ทำนายและประเมินผล\n",
        "best_model = search.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "\n",
        "print(f\"✅ Best Parameters: {search.best_params_}\")\n",
        "print(f\"✅ XGBoost R2: {r2:.4f}\")\n",
        "print(f\"✅ XGBoost RMSE: {rmse:.4f}\")\n",
        "print(f\"✅ XGBoost MAE: {mae:.4f}\")\n"
      ],
      "metadata": {
        "id": "kWXFE7KIuFC9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "\n",
        "# ✅ ตัวแปรที่เลือกไว้\n",
        "selected_features = ['ตำบล', 'อำเภอ', 'ไตรมาส', 'เดือน', 'อาชีพ', 'temp_15d_avg', 'rain_15d_avg']\n",
        "\n",
        "# ✅ เตรียม X, y\n",
        "X = df[selected_features].copy()\n",
        "y = df['cases']\n",
        "\n",
        "# ✅ interaction term\n",
        "X['ฝน_อุณหภูมิ'] = X['temp_15d_avg'] * X['rain_15d_avg']\n",
        "\n",
        "# ✅ แบ่ง train/test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# ✅ Categorical & numeric columns\n",
        "categorical_cols = ['ตำบล', 'อำเภอ', 'ไตรมาส', 'เดือน', 'อาชีพ']\n",
        "numeric_cols = ['temp_15d_avg', 'rain_15d_avg', 'ฝน_อุณหภูมิ']\n",
        "\n",
        "# ✅ Preprocessing\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)\n",
        "], remainder='passthrough')  # numeric ผ่านตรง\n",
        "\n",
        "# ✅ สร้าง Pipeline\n",
        "xgb_model = xgb.XGBRegressor(objective='reg:squarederror', random_state=42)\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('regressor', xgb_model)\n",
        "])\n",
        "\n",
        "# ✅ Hyperparameter tuning\n",
        "param_dist = {\n",
        "    'regressor__n_estimators': [100, 200, 300, 500],\n",
        "    'regressor__max_depth': [4, 6, 8, 10],\n",
        "    'regressor__learning_rate': [0.03, 0.05, 0.07],\n",
        "    'regressor__subsample': [0.6, 0.7, 0.8],\n",
        "    'regressor__colsample_bytree': [0.6, 0.8, 1.0],\n",
        "    'regressor__gamma': [0, 0.1, 0.3],\n",
        "    'regressor__reg_alpha': [0, 0.01, 0.1],\n",
        "    'regressor__reg_lambda': [1, 1.5, 2]\n",
        "}\n",
        "\n",
        "search = RandomizedSearchCV(\n",
        "    estimator=pipeline,\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=50,\n",
        "    cv=5,\n",
        "    scoring='neg_mean_squared_error',\n",
        "    random_state=42,\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# ✅ เทรน\n",
        "search.fit(X_train, y_train)\n",
        "\n",
        "# ✅ ทำนายและประเมินผล\n",
        "best_model = search.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "\n",
        "print(f\"✅ Best Parameters: {search.best_params_}\")\n",
        "print(f\"✅ XGBoost R2: {r2:.4f}\")\n",
        "print(f\"✅ XGBoost RMSE: {rmse:.4f}\")\n",
        "print(f\"✅ XGBoost MAE: {mae:.4f}\")\n"
      ],
      "metadata": {
        "id": "oIfVm3duwvgF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## deep learning"
      ],
      "metadata": {
        "id": "SRINxDTypY3Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n"
      ],
      "metadata": {
        "id": "APbMHIXofHXb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "import numpy as np\n",
        "\n",
        "# สร้างโมเดลง่าย ๆ\n",
        "model = Sequential([\n",
        "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# ฝึกโมเดล\n",
        "model.fit(X_train, y_train, epochs=50, batch_size=32, verbose=0)\n",
        "\n",
        "# ทำนาย\n",
        "y_pred_dl = model.predict(X_test).flatten()\n",
        "\n",
        "# คำนวณ metric\n",
        "rmse_dl = np.sqrt(mean_squared_error(y_test, y_pred_dl))\n",
        "r2_dl = r2_score(y_test, y_pred_dl)\n",
        "mae_dl = mean_absolute_error(y_test, y_pred_dl)\n",
        "\n",
        "print(f\"Deep Learning R2: {r2_dl:.4f}\")\n",
        "print(f\"Deep Learning RMSE: {rmse_dl:.4f}\")\n",
        "print(f\"Deep Learning MAE: {mae_dl:.4f}\")\n"
      ],
      "metadata": {
        "id": "YoZnC8hdeGdA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4EENKOG5eGgd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mdJNsVkyeGjy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "v8nhEuazpQtA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gzdK4BC6pQxb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# โหลดข้อมูล CSV (เปลี่ยนชื่อไฟล์ตามของคุณ)\n",
        "df = pd.read_csv('df_final_clean.csv')\n",
        "\n",
        "# แปลงคอลัมน์ date เป็น datetime\n",
        "df['date'] = pd.to_datetime(df['date'])\n",
        "\n",
        "# ตั้ง date เป็น index ของ dataframe\n",
        "df = df.set_index('date')\n",
        "\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "id": "pQtN-GIypQ0R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "df['cases'].plot(figsize=(12,6), title='จำนวนเคสตามเวลา')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Nc2AdzMypVKN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = int(len(df) * 0.8)\n",
        "train = df.iloc[:train_size]\n",
        "test = df.iloc[train_size:]\n"
      ],
      "metadata": {
        "id": "KrUbE0q8pX-U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
        "\n",
        "model = SARIMAX(train['cases'], order=(1,1,1), seasonal_order=(1,1,1,12))\n",
        "result = model.fit()\n",
        "\n",
        "print(result.summary())\n"
      ],
      "metadata": {
        "id": "2j2DN4fkpbPm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = result.predict(start=len(train), end=len(train) + len(test) - 1)\n"
      ],
      "metadata": {
        "id": "juziObhqpdBH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "rmse = np.sqrt(mean_squared_error(test['cases'], pred))\n",
        "print(f'RMSE: {rmse:.4f}')\n",
        "\n",
        "plt.figure(figsize=(12,6))\n",
        "plt.plot(train.index, train['cases'], label='Train')\n",
        "plt.plot(test.index, test['cases'], label='Test')\n",
        "plt.plot(pred.index, pred, label='Predicted')\n",
        "plt.legend()\n",
        "plt.title('ผลการทำนายจำนวนเคส')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Mw1imH0ypeN4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iFw8Hnr5qQTU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ysoEAs35qQXB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OOaN7DycqQal"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "K5MJVrI0qQeU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XpgMqGjyvs5M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1Z46XK7Gvs8T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PQuD-U-Bvs_U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ขั้นตอน 1: โหลดและเตรียมข้อมูล"
      ],
      "metadata": {
        "id": "QGNPU9QdvvpS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# โหลดข้อมูลสภาพอากาศจากหลายชีทในไฟล์ rain.xlsx\n",
        "file_path = 'rain.xlsx'\n",
        "xls = pd.ExcelFile(file_path)\n",
        "\n",
        "df_list = []\n",
        "for sheet in xls.sheet_names:\n",
        "    df = pd.read_excel(xls, sheet_name=sheet)\n",
        "    df = df.rename(columns={'ปี': 'year', 'เดือน': 'month', 'วันที่': 'day'})\n",
        "\n",
        "    # แปลงเป็นตัวเลข\n",
        "    df['year'] = pd.to_numeric(df['year'], errors='coerce')\n",
        "    df['month'] = pd.to_numeric(df['month'], errors='coerce')\n",
        "    df['day'] = pd.to_numeric(df['day'], errors='coerce')\n",
        "    df = df.dropna(subset=['year', 'month', 'day'])\n",
        "\n",
        "    # สร้าง datetime column\n",
        "    df['วัน'] = pd.to_datetime(df[['year', 'month', 'day']], errors='coerce')\n",
        "    df = df.dropna(subset=['วัน'])\n",
        "\n",
        "    # แปลงข้อมูลสภาพอากาศให้เป็นตัวเลข\n",
        "    for col in ['อุณหภูมิ', 'ฝน', 'ชื้น']:\n",
        "        if col in df.columns:\n",
        "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "    # กรองเอาเฉพาะแถวที่มีข้อมูลครบ\n",
        "    df = df[df[['อุณหภูมิ', 'ฝน', 'ชื้น']].notna().all(axis=1)]\n",
        "    df_list.append(df)\n",
        "\n",
        "# รวมข้อมูลสภาพอากาศทั้งหมด\n",
        "weather = pd.concat(df_list, ignore_index=True).drop_duplicates().sort_values('วัน').reset_index(drop=True)\n",
        "\n",
        "# บันทึกข้อมูลสภาพอากาศที่ clean แล้ว\n",
        "weather.to_excel('rain_all_years_sorted3.xlsx', index=False)\n",
        "print(\"✅ บันทึก rain_all_years_sorted3.xlsx เรียบร้อยแล้ว\")\n"
      ],
      "metadata": {
        "id": "X-BOXRdcvwn4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ขั้นตอน 2: โหลดและเตรียมข้อมูลผู้ป่วย"
      ],
      "metadata": {
        "id": "guGfkSH3vziC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# โหลดข้อมูลผู้ป่วยจากหลายชีทในไฟล์ DHFcc12.xlsx\n",
        "xls = pd.ExcelFile('DHFcc12.xlsx')\n",
        "df_list = []\n",
        "\n",
        "for sheet in xls.sheet_names:\n",
        "    if sheet == \"Table1\":  # ข้ามชีท Table1\n",
        "        continue\n",
        "\n",
        "    df = pd.read_excel(xls, sheet_name=sheet)\n",
        "    df.columns = df.columns.str.strip()\n",
        "\n",
        "    if 'วันเริ่มป่วย' in df.columns:\n",
        "        df['วันเริ่มป่วย'] = pd.to_datetime(df['วันเริ่มป่วย'], errors='coerce')\n",
        "\n",
        "    for col in ['อายุ(ปี)', 'อายุ(เดือน)']:\n",
        "        if col in df.columns:\n",
        "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "    df = df.dropna(subset=['วันเริ่มป่วย'])\n",
        "    df = df.dropna(how='all')\n",
        "\n",
        "    df_list.append(df)\n",
        "\n",
        "patients = pd.concat(df_list, ignore_index=True).drop_duplicates()\n",
        "print(f\"✅ รวมข้อมูลผู้ป่วยสำเร็จ: {patients.shape[0]} แถว, {patients.shape[1]} คอลัมน์\")\n"
      ],
      "metadata": {
        "id": "Q3idV_YBv0gv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ขั้นตอน 3: คำนวณ rolling average ของสภาพอากาศย้อนหลัง 15 วัน สำหรับแต่ละวันเริ่มป่วย"
      ],
      "metadata": {
        "id": "I8F_5ONJv3ST"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# โหลดข้อมูลสภาพอากาศที่จัดการแล้ว (เพื่อความแน่นอน)\n",
        "weather = pd.read_excel(\"rain_all_years_sorted3.xlsx\")\n",
        "weather['วัน'] = pd.to_datetime(weather['วัน'])\n",
        "\n",
        "# ฟังก์ชันคำนวณ rolling average ย้อนหลัง 15 วัน\n",
        "def get_rolling_avg(date, n_days=15):\n",
        "    start_date = date - pd.Timedelta(days=n_days)\n",
        "    mask = (weather['วัน'] >= start_date) & (weather['วัน'] < date)\n",
        "    subset = weather.loc[mask]\n",
        "    if subset.empty:\n",
        "        return pd.Series([None, None, None])\n",
        "    return pd.Series([\n",
        "        subset['อุณหภูมิ'].mean(),\n",
        "        subset['ฝน'].mean(),\n",
        "        subset['ชื้น'].mean()\n",
        "    ])\n",
        "\n",
        "# คำนวณ rolling average สำหรับผู้ป่วยแต่ละราย\n",
        "patients[['temp_15d_avg', 'rain_15d_avg', 'humid_15d_avg']] = patients['วันเริ่มป่วย'].apply(get_rolling_avg)\n",
        "print(\"✅ คำนวณ rolling average เสร็จ\")\n"
      ],
      "metadata": {
        "id": "VijSe9Uov3mW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ขั้นตอน 4: สร้างฟีเจอร์วันที่ เช่น ปี, เดือน, ไตรมาส, ฤดูกาล"
      ],
      "metadata": {
        "id": "7cfpszmov7-F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "patients['ปี'] = patients['วันเริ่มป่วย'].dt.year\n",
        "patients['เดือน'] = patients['วันเริ่มป่วย'].dt.month\n",
        "patients['ไตรมาส'] = patients['วันเริ่มป่วย'].dt.quarter\n",
        "\n",
        "def assign_season(row):\n",
        "    month = row['เดือน']\n",
        "    day = row['วันเริ่มป่วย'].day\n",
        "    if (month == 2 and day >= 15) or month in [3,4] or (month == 5 and day < 15):\n",
        "        return 'Summer'\n",
        "    elif (month == 5 and day >= 15) or month in [6,7,8,9] or (month == 10 and day < 15):\n",
        "        return 'Rainy'\n",
        "    else:\n",
        "        return 'Winter'\n",
        "\n",
        "patients['ฤดูกาล'] = patients.apply(assign_season, axis=1)\n"
      ],
      "metadata": {
        "id": "ZxILeNCYv9Tp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ขั้นตอน 5: รวมข้อมูลรายวันและคำนวณจำนวนผู้ป่วยรายวัน"
      ],
      "metadata": {
        "id": "4f3zx3P0wAgB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# สร้าง column วันแบบ date (ไม่มีเวลา)\n",
        "patients['date'] = patients['วันเริ่มป่วย'].dt.date\n",
        "\n",
        "# นับจำนวนผู้ป่วยแต่ละวัน (cases)\n",
        "daily_counts = patients.groupby('date').size().reset_index(name='cases')\n",
        "\n",
        "# คำนวณค่าเฉลี่ยและโหมดของตัวแปรอื่น ๆ ต่อวัน\n",
        "daily_weather = patients.groupby('date').agg({\n",
        "    'temp_15d_avg': 'mean',\n",
        "    'rain_15d_avg': 'mean',\n",
        "    'humid_15d_avg': 'mean',\n",
        "    'อายุ(ปี)': 'mean',\n",
        "    'เพศ': lambda x: x.mode()[0] if not x.mode().empty else None,\n",
        "    'อาชีพ': lambda x: x.mode()[0] if not x.mode().empty else None,\n",
        "    'ตำบล': lambda x: x.mode()[0] if not x.mode().empty else None,\n",
        "    'อำเภอ': lambda x: x.mode()[0] if not x.mode().empty else None,\n",
        "    'เดือน': lambda x: x.mode()[0] if not x.mode().empty else None,\n",
        "    'ปี': lambda x: x.mode()[0] if not x.mode().empty else None,\n",
        "    'ไตรมาส': lambda x: x.mode()[0] if not x.mode().empty else None,\n",
        "    'ฤดูกาล': lambda x: x.mode()[0] if not x.mode().empty else None\n",
        "}).reset_index()\n",
        "\n",
        "# รวมข้อมูลผู้ป่วยรายวันกับข้อมูลสภาพอากาศ\n",
        "df_final = pd.merge(daily_counts, daily_weather, on='date', how='left')\n",
        "print(\"✅ รวมข้อมูล df_final สำเร็จ:\", df_final.shape)\n"
      ],
      "metadata": {
        "id": "d8ELTpp6wBce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ขั้นตอน 6: จัดการ missing values และบันทึกข้อมูล"
      ],
      "metadata": {
        "id": "XKRfmM20wEcL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "missing_before = df_final.isnull().sum().sum()\n",
        "print(f\"⚠️ พบ missing values: {missing_before} ช่อง\")\n",
        "\n",
        "df_final_clean = df_final.dropna()\n",
        "print(\"✅ ลบ missing rows แล้ว → ขนาดข้อมูล:\", df_final_clean.shape)\n",
        "\n",
        "# บันทึกไฟล์ clean data\n",
        "df_final_clean.to_csv(\"df_final_clean.csv\", index=False)\n",
        "df_final_clean.to_excel(\"df_final_clean.xlsx\", index=False)\n",
        "print(\"📁 บันทึกไฟล์ df_final_clean.csv และ df_final_clean.xlsx เรียบร้อย\")\n"
      ],
      "metadata": {
        "id": "0c4k-ckFwFNz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ขั้นตอน 7: เปลี่ยนชื่อคอลัมน์เป็นภาษาอังกฤษ เพื่อใช้งานในโมเดล"
      ],
      "metadata": {
        "id": "Cmcu7JMiwJXm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_final_clean = pd.read_excel(\"/content/df_final_clean.xlsx\")"
      ],
      "metadata": {
        "id": "IouK0CFx2H9G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_final_clean.isnull().sum())\n"
      ],
      "metadata": {
        "id": "eSW25gCTOcEg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_final_clean = df_final_clean.drop_duplicates() #ตรวจสอบข้อมูลซ้ำ (Duplicate Records)"
      ],
      "metadata": {
        "id": "i0Xp1RnOOfPW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_final_clean.dtypes) #ตรวจสอบประเภทข้อมูล (Data Types)\n"
      ],
      "metadata": {
        "id": "aypEpMzAOzxI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_clean = df_final_clean.rename(columns={\n",
        "    'เพศ': 'gender',\n",
        "    'อาชีพ': 'occupation',\n",
        "    'ตำบล': 'subdistrict',\n",
        "    'อำเภอ': 'district',\n",
        "    'เดือน': 'month',\n",
        "    'ไตรมาส': 'quarter',\n",
        "    'อายุ(ปี)': 'age',\n",
        "    'ฤดูกาล': 'season',\n",
        "})\n"
      ],
      "metadata": {
        "id": "duEZRDLYwKNP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_clean.head())"
      ],
      "metadata": {
        "id": "Wetw53VbI6Lu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# โหลดข้อมูลจากไฟล์\n",
        "df_final_clean = pd.read_excel(\"/content/df_final_clean.xlsx\")\n",
        "\n",
        "# ตัวอย่างการสร้างกราฟแท่ง (Bar Chart) แสดงการกระจายของ 'cases' ตาม 'season'\n",
        "plt.figure(figsize=(10, 6))\n",
        "df_final_clean.groupby('ฤดูกาล')['cases'].sum().plot(kind='bar', color='skyblue')\n",
        "plt.title('Total Cases by Season')\n",
        "plt.xlabel('Season')\n",
        "plt.ylabel('Total Cases')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()\n",
        "\n",
        "# ตัวอย่างการสร้างกราฟกระจาย (Scatter Plot) แสดงความสัมพันธ์ระหว่าง 'age' และ 'cases'\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(df_final_clean['อายุ(ปี)'], df_final_clean['cases'], color='orange')\n",
        "plt.title('Scatter Plot of Age vs Cases')\n",
        "plt.xlabel('Age')\n",
        "plt.ylabel('Cases')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "3sFktvdklJkm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# แปลงคอลัมน์ 'date' เป็น datetime\n",
        "df_clean['date'] = pd.to_datetime(df_clean['date'], errors='coerce')\n",
        "\n",
        "# กรองข้อมูลในช่วงปี 2017-2024\n",
        "df_clean = df_clean[df_clean['date'].dt.year.between(2017, 2024)]\n",
        "\n",
        "# สร้างคอลัมน์ 'month' และ 'year' เพื่อให้แยกกราฟตามเดือน\n",
        "df_clean['month'] = df_clean['date'].dt.month\n",
        "df_clean['year'] = df_clean['date'].dt.year\n",
        "\n",
        "# คำนวณค่าเฉลี่ยตามปีและเดือน\n",
        "avg_data = df_clean.groupby(['year', 'month']).agg({\n",
        "    'temp_15d_avg': 'mean',\n",
        "    'rain_15d_avg': 'mean',\n",
        "    'humid_15d_avg': 'mean'\n",
        "}).reset_index()\n",
        "\n",
        "# ตั้งค่าการแสดงผล 3 กราฟ (temp_15d_avg, rain_15d_avg, humid_15d_avg) แยกตามเดือน\n",
        "fig, axs = plt.subplots(3, 1, figsize=(12, 18), sharex=True)\n",
        "\n",
        "# แสดงกราฟแค่เดือนที่จำเป็น (ทุกๆ 6 เดือน)\n",
        "months_to_display = [1, 6, 12]\n",
        "avg_data_filtered = avg_data[avg_data['month'].isin(months_to_display)]\n",
        "\n",
        "# กราฟแสดงอุณหภูมิ (Temperature)\n",
        "axs[0].plot(avg_data_filtered['year'].astype(str) + '-' + avg_data_filtered['month'].astype(str), avg_data_filtered['temp_15d_avg'], color='red', label='Temperature')\n",
        "axs[0].set_title('Average Temperature (°C) from 2017 to 2024')\n",
        "axs[0].set_ylabel('Temperature (°C)')\n",
        "axs[0].legend()\n",
        "\n",
        "# กราฟแสดงฝน (Rainfall)\n",
        "axs[1].plot(avg_data_filtered['year'].astype(str) + '-' + avg_data_filtered['month'].astype(str), avg_data_filtered['rain_15d_avg'], color='green', label='Rainfall')\n",
        "axs[1].set_title('Average Rainfall (mm) from 2017 to 2024')\n",
        "axs[1].set_ylabel('Rainfall (mm)')\n",
        "axs[1].legend()\n",
        "\n",
        "# กราฟแสดงความชื้น (Humidity)\n",
        "axs[2].plot(avg_data_filtered['year'].astype(str) + '-' + avg_data_filtered['month'].astype(str), avg_data_filtered['humid_15d_avg'], color='blue', label='Humidity')\n",
        "axs[2].set_title('Average Humidity (%) from 2017 to 2024')\n",
        "axs[2].set_ylabel('Humidity (%)')\n",
        "axs[2].legend()\n",
        "\n",
        "# ตั้งชื่อกราฟ\n",
        "plt.xlabel('Date (Year-Month)')\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "tqN2205pKI_n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# อ่านข้อมูล\n",
        "df = pd.read_csv('df_final_clean.csv')  # ใส่ path ของไฟล์ที่คุณใช้\n",
        "\n",
        "# แปลงคอลัมน์ 'date' เป็น datetime\n",
        "df['date'] = pd.to_datetime(df['date'])\n",
        "\n",
        "# สร้างคอลัมน์ 'year' และ 'season' สำหรับกราฟรายปีและฤดูกาล\n",
        "df['year'] = df['date'].dt.year  # เพิ่มคอลัมน์ 'year' สำหรับการกรุ๊ปข้อมูลรายปี\n",
        "df['season'] = df['date'].dt.month % 12 // 3 + 1  # ฤดูกาล: 1=ฤดูร้อน, 2=ฤดูฝน, 3=ฤดูหนาว\n",
        "\n",
        "# คำนวณค่าเฉลี่ยประจำปี\n",
        "df_yearly = df.groupby('year').agg({\n",
        "    'humid_15d_avg': 'mean',\n",
        "    'rain_15d_avg': 'mean',\n",
        "    'temp_15d_avg': 'mean'\n",
        "}).reset_index()\n",
        "\n",
        "# สร้างกราฟ\n",
        "fig, ax = plt.subplots(3, 1, figsize=(10, 12))\n",
        "\n",
        "# กราฟแสดงอุณหภูมิ\n",
        "ax[0].plot(df_yearly['year'], df_yearly['temp_15d_avg'], label='Temperature', color='red')\n",
        "ax[0].set_title('Average Temperature from 2017 to 2024')\n",
        "ax[0].set_xlabel('Year')\n",
        "ax[0].set_ylabel('Temperature (°C)')\n",
        "\n",
        "# กราฟแสดงฝน\n",
        "ax[1].plot(df_yearly['year'], df_yearly['rain_15d_avg'], label='Rain', color='blue')\n",
        "ax[1].set_title('Average Rainfall from 2017 to 2024')\n",
        "ax[1].set_xlabel('Year')\n",
        "ax[1].set_ylabel('Rainfall (mm)')\n",
        "\n",
        "# กราฟแสดงความชื้น\n",
        "ax[2].plot(df_yearly['year'], df_yearly['humid_15d_avg'], label='Humidity', color='green')\n",
        "ax[2].set_title('Average Humidity from 2017 to 2024')\n",
        "ax[2].set_xlabel('Year')\n",
        "ax[2].set_ylabel('Humidity (%)')\n",
        "\n",
        "# แสดงกราฟ\n",
        "plt.tight_layout()\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "bysb4fgVLAbB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.columns)\n"
      ],
      "metadata": {
        "id": "qab8woG2LRC9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import font_manager\n",
        "\n",
        "# กำหนดฟอนต์ที่ใช้\n",
        "font_path = \"/content/THSarabunNew.ttf\"  # แก้ไขให้ตรงกับตำแหน่งฟอนต์ที่ติดตั้ง\n",
        "font_prop = font_manager.FontProperties(fname=font_path)\n",
        "\n",
        "# คำนวณจำนวนผู้ป่วยทั้งหมดในแต่ละตำบล\n",
        "top_subdistricts = df_clean.groupby('subdistrict')['cases'].sum().sort_values(ascending=False).head(20)\n",
        "\n",
        "# สร้างกราฟ\n",
        "plt.figure(figsize=(12, 8))\n",
        "top_subdistricts.plot(kind='barh', color='lightblue')\n",
        "\n",
        "# ตั้งชื่อกราฟและแกน\n",
        "plt.xlabel('Total Cases', fontproperties=font_prop)\n",
        "plt.ylabel('Subdistrict', fontproperties=font_prop)\n",
        "plt.title('Top 20 Subdistricts by Total Cases', fontproperties=font_prop)\n",
        "\n",
        "# หมุนชื่อให้สามารถอ่านได้ง่ายขึ้น\n",
        "plt.xticks(rotation=45, fontproperties=font_prop)\n",
        "plt.yticks(fontproperties=font_prop)\n",
        "\n",
        "# เพิ่มข้อความแสดงจำนวนผู้ป่วย\n",
        "for index, value in enumerate(top_subdistricts):\n",
        "    plt.text(value, index, str(value), fontproperties=font_prop)  # แสดงค่าในแต่ละตำแหน่งของบาร์\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "3y43STz2le0U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import font_manager\n",
        "\n",
        "# กำหนดฟอนต์ที่ใช้\n",
        "font_path = \"/content/THSarabunNew.ttf\"  # แก้ไขให้ตรงกับตำแหน่งฟอนต์ที่ติดตั้ง\n",
        "font_prop = font_manager.FontProperties(fname=font_path)\n",
        "\n",
        "# คำนวณจำนวนผู้ป่วยทั้งหมดในแต่ละตำบล\n",
        "top_subdistricts = df_clean.groupby('subdistrict')['cases'].sum().sort_values(ascending=True).head(20)  # เลือก 20 ตำบลที่มีจำนวนผู้ป่วยน้อยที่สุด\n",
        "\n",
        "# สร้างกราฟ\n",
        "plt.figure(figsize=(12, 8))\n",
        "top_subdistricts.plot(kind='barh', color='lightblue')\n",
        "\n",
        "# ตั้งชื่อกราฟและแกน\n",
        "plt.xlabel('Total Cases', fontproperties=font_prop)\n",
        "plt.ylabel('Subdistrict', fontproperties=font_prop)\n",
        "plt.title('Top 20 Subdistricts by Total Cases (Lowest)', fontproperties=font_prop)\n",
        "\n",
        "# หมุนชื่อให้สามารถอ่านได้ง่ายขึ้น\n",
        "plt.xticks(rotation=45, fontproperties=font_prop)\n",
        "plt.yticks(fontproperties=font_prop)\n",
        "\n",
        "# เพิ่มข้อความแสดงจำนวนผู้ป่วย\n",
        "for index, value in enumerate(top_subdistricts):\n",
        "    plt.text(value, index, str(value), fontproperties=font_prop)  # แสดงค่าในแต่ละตำแหน่งของบาร์\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "9ZRjXSqsCi__"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import font_manager\n",
        "\n",
        "# กำหนดฟอนต์ที่ใช้\n",
        "font_path = \"/content/THSarabunNew.ttf\"  # แก้ไขให้ตรงกับตำแหน่งฟอนต์ที่ติดตั้ง\n",
        "font_prop = font_manager.FontProperties(fname=font_path)\n",
        "\n",
        "# คำนวณจำนวนผู้ป่วยทั้งหมดในแต่ละอาชีพ\n",
        "top_occupation = df_clean.groupby('occupation')['cases'].sum().sort_values(ascending=False).head(20)\n",
        "\n",
        "# สร้างกราฟ\n",
        "plt.figure(figsize=(12, 10))  # เพิ่มขนาดกราฟ\n",
        "top_occupation.plot(kind='barh', color='lightcoral')  # ใช้ top_occupation แทน top_subdistricts\n",
        "\n",
        "# ตั้งชื่อกราฟและแกน\n",
        "plt.xlabel('Total Cases', fontproperties=font_prop)\n",
        "plt.ylabel('Occupation', fontproperties=font_prop)  # เปลี่ยนชื่อแกน y\n",
        "plt.title('Top 20 Occupation by Total Cases', fontproperties=font_prop)  # เปลี่ยนชื่อกราฟ\n",
        "\n",
        "# หมุนชื่อให้สามารถอ่านได้ง่ายขึ้น\n",
        "plt.xticks(rotation=45, fontproperties=font_prop)\n",
        "plt.yticks(fontproperties=font_prop)\n",
        "\n",
        "# เพิ่มข้อความแสดงจำนวนผู้ป่วย\n",
        "for index, value in enumerate(top_occupation):  # ใช้ top_occupation แทน top_subdistricts\n",
        "    plt.text(value, index, str(value), fontproperties=font_prop)  # แสดงค่าในแต่ละตำแหน่งของบาร์\n",
        "\n",
        "plt.tight_layout()  # จัดการกับขนาดของกราฟให้สมบูรณ์\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "UFMh7gRryMww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ขั้นตอน 8: วิเคราะห์เชิงเดี่ยว (Univariate Analysis)"
      ],
      "metadata": {
        "id": "REbDjrN3wNOG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ตรวจสอบชื่อคอลัมน์อีกครั้ง\n",
        "print(df_final_clean.columns)\n"
      ],
      "metadata": {
        "id": "72man_fQQ5hr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import scipy.stats as stats\n",
        "from scipy.stats import spearmanr, pointbiserialr, kruskal\n",
        "\n",
        "# เลือกตัวแปรที่ใช้\n",
        "target = 'cases'\n",
        "numeric_vars = ['temp_15d_avg', 'rain_15d_avg', 'humid_15d_avg', 'อายุ(ปี)']  # รวม 'อายุ(ปี)'\n",
        "binary_cats = ['เพศ']\n",
        "multi_cats = ['อาชีพ', 'ตำบล', 'อำเภอ', 'เดือน', 'ปี', 'ไตรมาส', 'ฤดูกาล']  # รวมตัวแปร 'เดือน', 'ปี', 'ไตรมาส', 'ฤดูกาล'\n",
        "\n",
        "# แปลงเพศเป็นตัวเลข (ชาย=0, หญิง=1)\n",
        "if 'เพศ' in df_final_clean.columns:\n",
        "    df_final_clean['gender_code'] = df_final_clean['เพศ'].map({'ชาย': 0, 'หญิง': 1})\n",
        "\n",
        "# ลบ missing values ที่จำเป็นสำหรับตัวแปรที่ใช้ในการคำนวณ\n",
        "df_final_clean = df_final_clean.dropna(subset=['temp_15d_avg', 'rain_15d_avg', 'humid_15d_avg', 'gender_code', target])\n",
        "\n",
        "# คำนวณค่า p-value\n",
        "results = []\n",
        "\n",
        "# 1) Spearman correlation กับตัวแปรเชิงปริมาณ\n",
        "for var in numeric_vars:\n",
        "    corr, p = spearmanr(df_final_clean[var], df_final_clean[target])\n",
        "    results.append({\n",
        "        'Variable': var,\n",
        "        'Test': 'Spearman Correlation',\n",
        "        'Stat': round(corr, 3),\n",
        "        'P-Value': round(p, 4)\n",
        "    })\n",
        "\n",
        "# 2) Point-Biserial correlation กับตัวแปรไบนารี\n",
        "for var in binary_cats:\n",
        "    encoded_var = var + '_code'  # ชื่อคอลัมน์ที่แปลงจากเพศ\n",
        "    if encoded_var in df_final_clean.columns and df_final_clean[encoded_var].nunique() == 2:\n",
        "        corr, p = pointbiserialr(df_final_clean[encoded_var], df_final_clean[target])\n",
        "        results.append({\n",
        "            'Variable': var,\n",
        "            'Test': 'Point-Biserial',\n",
        "            'Stat': round(corr, 3),\n",
        "            'P-Value': round(p, 4)\n",
        "        })\n",
        "\n",
        "# 3) Kruskal-Wallis test กับตัวแปรหลายกลุ่ม\n",
        "for var in multi_cats:\n",
        "    df_non_null = df_final_clean.dropna(subset=[var])\n",
        "    groups = [group[target].dropna() for name, group in df_non_null.groupby(var)]\n",
        "    if len(groups) > 1:\n",
        "        h_stat, p = kruskal(*groups)\n",
        "        results.append({\n",
        "            'Variable': var,\n",
        "            'Test': 'Kruskal-Wallis',\n",
        "            'Stat': round(h_stat, 3),\n",
        "            'P-Value': round(p, 4)\n",
        "        })\n",
        "\n",
        "# แสดงผล\n",
        "results_df = pd.DataFrame(results).sort_values('P-Value')\n",
        "print(\"\\n📊 ผลวิเคราะห์เชิงเดี่ยว (เรียงตาม p-value):\")\n",
        "print(results_df)\n"
      ],
      "metadata": {
        "id": "BticRF0EwOKf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import scipy.stats as stats\n",
        "from scipy.stats import spearmanr, pointbiserialr, kruskal\n",
        "\n",
        "# เลือกตัวแปรที่ใช้\n",
        "target = 'cases'\n",
        "numeric_vars = ['temp_15d_avg', 'rain_15d_avg', 'humid_15d_avg', 'อายุ(ปี)']  # รวม 'อายุ(ปี)'\n",
        "binary_cats = ['เพศ']\n",
        "multi_cats = ['อาชีพ', 'ตำบล', 'อำเภอ', 'เดือน', 'ปี', 'ไตรมาส', 'ฤดูกาล']  # รวมตัวแปร 'เดือน', 'ปี', 'ไตรมาส', 'ฤดูกาล'\n",
        "\n",
        "# แปลงเพศเป็นตัวเลข (ชาย=0, หญิง=1)\n",
        "if 'เพศ' in df_final_clean.columns:\n",
        "    df_final_clean['gender_code'] = df_final_clean['เพศ'].map({'ชาย': 0, 'หญิง': 1})\n",
        "\n",
        "# ลบ missing values ที่จำเป็นสำหรับตัวแปรที่ใช้ในการคำนวณ\n",
        "df_final_clean = df_final_clean.dropna(subset=['temp_15d_avg', 'rain_15d_avg', 'humid_15d_avg', 'gender_code', target])\n",
        "\n",
        "# คำนวณค่า p-value\n",
        "results = []\n",
        "\n",
        "# 1) Spearman correlation กับตัวแปรเชิงปริมาณ\n",
        "for var in numeric_vars:\n",
        "    corr, p = spearmanr(df_final_clean[var], df_final_clean[target])\n",
        "    results.append({\n",
        "        'Variable': var,\n",
        "        'Test': 'Spearman Correlation',\n",
        "        'Stat': round(corr, 3),\n",
        "        'P-Value': round(p, 4)\n",
        "    })\n",
        "\n",
        "# 2) Point-Biserial correlation กับตัวแปรไบนารี\n",
        "for var in binary_cats:\n",
        "    encoded_var = var + '_code'  # ชื่อคอลัมน์ที่แปลงจากเพศ\n",
        "    if encoded_var in df_final_clean.columns and df_final_clean[encoded_var].nunique() == 2:\n",
        "        corr, p = pointbiserialr(df_final_clean[encoded_var], df_final_clean[target])\n",
        "        results.append({\n",
        "            'Variable': var,\n",
        "            'Test': 'Point-Biserial',\n",
        "            'Stat': round(corr, 3),\n",
        "            'P-Value': round(p, 4)\n",
        "        })\n",
        "\n",
        "# 3) Kruskal-Wallis test กับตัวแปรหลายกลุ่ม\n",
        "for var in multi_cats:\n",
        "    df_non_null = df_final_clean.dropna(subset=[var])\n",
        "    groups = [group[target].dropna() for name, group in df_non_null.groupby(var)]\n",
        "    if len(groups) > 1:\n",
        "        h_stat, p = kruskal(*groups)\n",
        "        results.append({\n",
        "            'Variable': var,\n",
        "            'Test': 'Kruskal-Wallis',\n",
        "            'Stat': round(h_stat, 3),\n",
        "            'P-Value': round(p, 4)\n",
        "        })\n",
        "\n",
        "# แปลงผลลัพธ์เป็น DataFrame\n",
        "results_df = pd.DataFrame(results).sort_values('P-Value')\n",
        "\n",
        "# กรองเฉพาะตัวแปรที่มี p-value < 0.05\n",
        "significant_results_df = results_df[results_df['P-Value'] < 0.05]\n",
        "\n",
        "# แสดงผล\n",
        "print(\"\\n📊 ผลวิเคราะห์เชิงเดี่ยว (ตัวแปรที่มี p-value < 0.05):\")\n",
        "print(significant_results_df)\n"
      ],
      "metadata": {
        "id": "Tjas_15qMqdd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ขั้นตอน 9: วิเคราะห์เชิงพหุด้วย Negative Binomial Regression"
      ],
      "metadata": {
        "id": "snd6z7VFwSNs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_final_clean.columns)  # ตรวจสอบคอลัมน์ทั้งหมดใน DataFrame\n"
      ],
      "metadata": {
        "id": "LgP1JD5oa6oY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_final_clean.rename(columns={\n",
        "    'date': 'date',\n",
        "    'cases': 'cases',\n",
        "    'temp_15d_avg': 'temp_15d_avg',\n",
        "    'rain_15d_avg': 'rain_15d_avg',\n",
        "    'humid_15d_avg': 'humid_15d_avg',\n",
        "    'อายุ(ปี)': 'age',\n",
        "    'เพศ': 'gender',\n",
        "    'อาชีพ': 'occupation',\n",
        "    'ตำบล': 'subdistrict',\n",
        "    'อำเภอ': 'district',\n",
        "    'เดือน': 'month',\n",
        "    'ปี': 'year',\n",
        "    'ไตรมาส': 'quarter',\n",
        "    'ฤดูกาล': 'season',\n",
        "    'gender_code': 'gender_code'\n",
        "}, inplace=True)\n"
      ],
      "metadata": {
        "id": "vnZa-ue9Vbrp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm  # นำเข้า statsmodels\n"
      ],
      "metadata": {
        "id": "7m6FfUuR2qR6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# แปลงคอลัมน์ที่เป็น categorical ให้เป็น dtype 'category' (ตัวแปรหมวดหมู่)\n",
        "df_final_clean['occupation'] = df_final_clean['occupation'].astype('category')\n",
        "df_final_clean['subdistrict'] = df_final_clean['subdistrict'].astype('category')\n",
        "df_final_clean['district'] = df_final_clean['district'].astype('category')\n",
        "df_final_clean['season'] = df_final_clean['season'].astype('category')\n",
        "df_final_clean['quarter'] = df_final_clean['quarter'].astype('category')\n",
        "\n",
        "# ตรวจสอบข้อมูลใหม่\n",
        "print(df_final_clean.dtypes)\n"
      ],
      "metadata": {
        "id": "W0IjCB5OwTBZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ลบคอลัมน์ season ที่ซ้ำ\n",
        "df_final_clean = df_final_clean.loc[:, ~df_final_clean.columns.duplicated()]\n",
        "\n",
        "# สร้างโมเดล Negative Binomial\n",
        "nb_model = smf.glm(\n",
        "    formula=formula,\n",
        "    data=df_final_clean,\n",
        "    family=sm.families.NegativeBinomial()  # ใช้ sm.families.NegativeBinomial()\n",
        ").fit()\n",
        "\n",
        "# แสดงผลลัพธ์ของโมเดล\n",
        "print(nb_model.summary())\n"
      ],
      "metadata": {
        "id": "qWCfTn4MXV0c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# สรุปเฉพาะตัวแปรที่มีนัยสำคัญ p-value < 0.05\n",
        "summary_df = nb_model.summary2().tables[1]\n",
        "significant_vars = summary_df[summary_df['P>|z|'] < 0.05]\n",
        "\n",
        "print(\"\\n📌 ตัวแปรที่มีนัยสำคัญ (p-value < 0.05):\")\n",
        "print(significant_vars[['Coef.', 'Std.Err.', 'z', 'P>|z|']])\n"
      ],
      "metadata": {
        "id": "3W3DbpleXepd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ตรวจสอบ overdispersion\n",
        "mean_cases = df_final_clean['cases'].mean()\n",
        "var_cases = df_final_clean['cases'].var()\n",
        "\n",
        "print(f\"\\nMean of cases: {mean_cases:.4f}\")\n",
        "print(f\"Variance of cases: {var_cases:.4f}\")\n",
        "\n",
        "# ตรวจสอบว่าเกิด overdispersion หรือไม่\n",
        "if var_cases > mean_cases:\n",
        "    print(\"📈 มี overdispersion → เหมาะกับ Negative Binomial\")\n",
        "else:\n",
        "    print(\"📉 ไม่มี overdispersion → อาจไม่เหมาะกับ Negative Binomial\")\n"
      ],
      "metadata": {
        "id": "FeM2HKy2XiST"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# การปรับข้อมูลให้เป็นมาตรฐาน (Standardization)\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# ทำการ normalize ข้อมูลที่ใช้ในการพยากรณ์\n",
        "df_final_clean[['temp_15d_avg', 'rain_15d_avg', 'humid_15d_avg']] = scaler.fit_transform(\n",
        "    df_final_clean[['temp_15d_avg', 'rain_15d_avg', 'humid_15d_avg']])\n",
        "\n",
        "# สร้างโมเดล Negative Binomial ใหม่\n",
        "nb_model = smf.glm(\n",
        "    formula=formula,\n",
        "    data=df_final_clean,\n",
        "    family=sm.families.NegativeBinomial()\n",
        ").fit()\n",
        "\n",
        "# ผลลัพธ์ใหม่\n",
        "predictions = nb_model.predict(df_final_clean)\n"
      ],
      "metadata": {
        "id": "F008IJYuXkET"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use rolling average for smoothing\n",
        "predictions_smooth = predictions.rolling(window=10).mean()\n",
        "actual_cases_smooth = df_final_clean['cases'].rolling(window=10).mean()\n",
        "\n",
        "# กราฟใหม่\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(predictions_smooth, label='Predicted Cases', color='blue')\n",
        "plt.plot(actual_cases_smooth, label='Actual Cases', color='red', alpha=0.6)\n",
        "plt.title(\"Smoothed Predicted vs Actual Cases\")\n",
        "plt.xlabel(\"Index\")\n",
        "plt.ylabel(\"Number of Cases\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Y79Yi9NEXnjz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "32G8JFyu7JJX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# แบ่งข้อมูล\n",
        "X = df_final_clean_encoded\n",
        "y = df_final_clean['cases']\n",
        "\n",
        "# แบ่งข้อมูลเป็นชุดฝึกและทดสอบ\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# สร้างโมเดล XGBoost\n",
        "model = xgb.XGBRegressor(objective='reg:squarederror', eval_metric='rmse')\n",
        "\n",
        "# ฝึกโมเดล\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# ทำนายค่าบนชุดทดสอบ\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# คำนวณค่า MSE (Mean Squared Error)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)  # คำนวณค่ารากที่สองของ MSE\n",
        "print(f\"RMSE: {rmse}\")\n",
        "\n",
        "# คำนวณค่า R² (Coefficient of Determination)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print(f\"R²: {r2}\")\n",
        "\n",
        "# กราฟเปรียบเทียบผลทำนายและค่าจริง\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(y_test.values, label='Actual Cases', color='red')\n",
        "plt.plot(y_pred, label='Predicted Cases', color='blue')\n",
        "plt.title('Predicted vs Actual Cases')\n",
        "plt.xlabel('Index')\n",
        "plt.ylabel('Number of Cases')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# แสดง Feature Importance\n",
        "xgb.plot_importance(model, importance_type='weight', max_num_features=10)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "WztZYJfKYNRf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# เลือกเฉพาะตัวแปรที่มีนัยสำคัญ\n",
        "significant_columns = ['month', 'rain_15d_avg', 'humid_15d_avg', 'subdistrict']\n",
        "\n",
        "# แปลง categorical variables ให้เป็นตัวเลข\n",
        "df_final_clean_encoded = df_final_clean[significant_columns].copy()\n",
        "\n",
        "# ใช้ LabelEncoder สำหรับแปลงตัวแปรเชิงหมวดหมู่ให้เป็นตัวเลข\n",
        "label_encoder = LabelEncoder()\n",
        "df_final_clean_encoded['subdistrict'] = label_encoder.fit_transform(df_final_clean_encoded['subdistrict'])\n",
        "\n",
        "# สร้าง X และ y\n",
        "X = df_final_clean_encoded\n",
        "y = df_final_clean['cases']\n",
        "\n",
        "# แบ่งข้อมูลเป็นชุดฝึกและทดสอบ\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# สร้างโมเดล XGBoost และปรับพารามิเตอร์\n",
        "model = xgb.XGBRegressor(\n",
        "    objective='reg:squarederror',\n",
        "    eval_metric='rmse',\n",
        "    max_depth=5,        # ลดความลึกของต้นไม้\n",
        "    learning_rate=0.05,  # ลดค่าความเร็วในการเรียนรู้\n",
        "    n_estimators=500,   # เพิ่มจำนวนต้นไม้\n",
        "    colsample_bytree=0.8,  # ตัวแปรที่ใช้ในการแบ่งแต่ละต้นไม้\n",
        "    subsample=0.7,         # ขนาดของแต่ละชุดย่อยในการฝึก\n",
        "    gamma=0.1           # การปรับให้โมเดลไม่ฟิตมากเกินไป\n",
        ")\n",
        "\n",
        "# ฝึกโมเดล\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# ทำนายค่าบนชุดทดสอบ\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# คำนวณค่า MSE (Mean Squared Error)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)  # คำนวณค่ารากที่สองของ MSE\n",
        "print(f\"RMSE: {rmse}\")\n",
        "\n",
        "# คำนวณค่า R² (Coefficient of Determination)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print(f\"R²: {r2}\")\n",
        "\n",
        "# กราฟเปรียบเทียบผลทำนายและค่าจริง\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(y_test.values, label='Actual Cases', color='red')\n",
        "plt.plot(y_pred, label='Predicted Cases', color='blue')\n",
        "plt.title('Predicted vs Actual Cases')\n",
        "plt.xlabel('Index')\n",
        "plt.ylabel('Number of Cases')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# คำนวณ Feature Importance\n",
        "xgb.plot_importance(model, importance_type='weight', max_num_features=10, title=\"Feature Importance\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "2cA5jlADcEHP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# เลือกเฉพาะตัวแปรที่มีนัยสำคัญ\n",
        "significant_columns = ['rain_15d_avg', 'humid_15d_avg', 'month', 'subdistrict']\n",
        "\n",
        "# แปลง categorical variables ให้เป็นตัวเลข\n",
        "df_final_clean_encoded = df_final_clean[significant_columns].copy()\n",
        "\n",
        "# ใช้ One-Hot Encoding สำหรับแปลงตัวแปร subdistrict เป็นค่าดิจิตอล\n",
        "df_final_clean_encoded = pd.get_dummies(df_final_clean_encoded, columns=['subdistrict'], drop_first=True)\n",
        "\n",
        "# ใช้ LabelEncoder สำหรับแปลงตัวแปรเดือน\n",
        "label_encoder = LabelEncoder()\n",
        "df_final_clean_encoded['month'] = label_encoder.fit_transform(df_final_clean_encoded['month'])\n",
        "\n",
        "# สร้าง X และ y\n",
        "X = df_final_clean_encoded\n",
        "y = df_final_clean['cases']\n",
        "\n",
        "# แบ่งข้อมูลเป็นชุดฝึกและทดสอบ\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# สร้างโมเดล XGBoost และปรับพารามิเตอร์\n",
        "model = xgb.XGBRegressor(\n",
        "    objective='reg:squarederror',\n",
        "    eval_metric='rmse',\n",
        "    max_depth=5,        # ลดความลึกของต้นไม้\n",
        "    learning_rate=0.05,  # ลดค่าความเร็วในการเรียนรู้\n",
        "    n_estimators=500,   # เพิ่มจำนวนต้นไม้\n",
        "    colsample_bytree=0.8,  # ตัวแปรที่ใช้ในการแบ่งแต่ละต้นไม้\n",
        "    subsample=0.7,         # ขนาดของแต่ละชุดย่อยในการฝึก\n",
        "    gamma=0.1           # การปรับให้โมเดลไม่ฟิตมากเกินไป\n",
        ")\n",
        "\n",
        "# ฝึกโมเดล\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# ทำนายค่าบนชุดทดสอบ\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# คำนวณค่า MSE (Mean Squared Error)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)  # คำนวณค่ารากที่สองของ MSE\n",
        "print(f\"RMSE: {rmse}\")\n",
        "\n",
        "# คำนวณค่า R² (Coefficient of Determination)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print(f\"R²: {r2}\")\n",
        "\n",
        "# กราฟเปรียบเทียบผลทำนายและค่าจริง\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(y_test.values, label='Actual Cases', color='red')\n",
        "plt.plot(y_pred, label='Predicted Cases', color='blue')\n",
        "plt.title('Predicted vs Actual Cases')\n",
        "plt.xlabel('Index')\n",
        "plt.ylabel('Number of Cases')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# คำนวณ Feature Importance\n",
        "xgb.plot_importance(model, importance_type='weight', max_num_features=10, title=\"Feature Importance\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "EhDvcq3mvIg_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# เลือกเฉพาะตัวแปรที่มีนัยสำคัญ\n",
        "significant_columns = ['rain_15d_avg', 'humid_15d_avg', 'month', 'subdistrict']\n",
        "\n",
        "# แปลง categorical variables ให้เป็นตัวเลข\n",
        "df_final_clean_encoded = df_final_clean[significant_columns].copy()\n",
        "\n",
        "# ใช้ One-Hot Encoding สำหรับแปลงตัวแปร subdistrict เป็นค่าดิจิตอล\n",
        "df_final_clean_encoded = pd.get_dummies(df_final_clean_encoded, columns=['subdistrict'], drop_first=True)\n",
        "\n",
        "# ใช้ LabelEncoder สำหรับแปลงตัวแปรเดือน\n",
        "label_encoder = LabelEncoder()\n",
        "df_final_clean_encoded['month'] = label_encoder.fit_transform(df_final_clean_encoded['month'])\n",
        "\n",
        "# สร้าง X และ y\n",
        "X = df_final_clean_encoded\n",
        "y = df_final_clean['cases']\n",
        "\n",
        "# แบ่งข้อมูลเป็นชุดฝึกและทดสอบ\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "#  Scaling สำหรับ Deep Learning\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# XGBoost\n",
        "xgb_model = xgb.XGBRegressor(\n",
        "    objective='reg:squarederror',\n",
        "    eval_metric='rmse',\n",
        "    max_depth=12,  # เพิ่มความลึกของต้นไม้\n",
        "    learning_rate=0.01,  # ลด learning rate\n",
        "    n_estimators=2000,  # เพิ่มจำนวนต้นไม้\n",
        "    colsample_bytree=0.9,  # เลือกคุณสมบัติสำหรับแต่ละต้นไม้\n",
        "    subsample=0.85,  # ขนาดของการสุ่มข้อมูล\n",
        "    alpha=0.2,  # เพิ่มการ regularization\n",
        "    gamma=0.01,  # ความยืดหยุ่นในการป้องกัน overfitting\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "xgb_model.fit(X_train, y_train)\n",
        "y_pred_xgb = xgb_model.predict(X_test)\n",
        "\n",
        "print(\"XGBoost\")\n",
        "print(\"  RMSE:\", np.sqrt(mean_squared_error(y_test, y_pred_xgb)))\n",
        "print(\"  R2  :\", r2_score(y_test, y_pred_xgb))\n",
        "\n",
        "# Random Forest\n",
        "# Random Forest\n",
        "rf_model = RandomForestRegressor(n_estimators=500, max_depth=20, random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "y_pred_rf = rf_model.predict(X_test)\n",
        "\n",
        "print(\"\\nRandom Forest\")\n",
        "print(\"  RMSE:\", np.sqrt(mean_squared_error(y_test, y_pred_rf)))\n",
        "print(\"  R2  :\", r2_score(y_test, y_pred_rf))\n",
        "\n",
        "# Deep Learning\n",
        "dl_model = Sequential([\n",
        "    Dense(128, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "dl_model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "dl_model.fit(X_train_scaled, y_train,\n",
        "             validation_split=0.2,\n",
        "             epochs=50,  # ลดจำนวน epochs ให้เหมาะสม\n",
        "             batch_size=16,\n",
        "             verbose=1,\n",
        "             callbacks=[early_stop])\n",
        "\n",
        "y_pred_dl = dl_model.predict(X_test_scaled).flatten()\n",
        "\n",
        "print(\"\\nDeep Learning\")\n",
        "print(\"  RMSE:\", np.sqrt(mean_squared_error(y_test, y_pred_dl)))\n",
        "print(\"  R2  :\", r2_score(y_test, y_pred_dl))\n"
      ],
      "metadata": {
        "id": "qZWvXpxDOTvd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "YtfDbHJ3ccuo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "L8iyr05bttzV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "jLk1jO00tuXx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# เลือกเฉพาะตัวแปรที่มีนัยสำคัญ\n",
        "significant_columns = ['temp_15d_avg', 'rain_15d_avg', 'humid_15d_avg', 'gender_code', 'occupation',\n",
        "                       'subdistrict', 'district', 'season', 'quarter', 'year']\n",
        "\n",
        "# แปลง categorical variables ให้เป็นตัวเลข\n",
        "df_final_clean_encoded = df_final_clean[significant_columns].copy()\n",
        "\n",
        "# ใช้ LabelEncoder สำหรับแปลงตัวแปรเชิงหมวดหมู่ให้เป็นตัวเลข\n",
        "label_encoder = LabelEncoder()\n",
        "df_final_clean_encoded['occupation'] = label_encoder.fit_transform(df_final_clean_encoded['occupation'])\n",
        "df_final_clean_encoded['subdistrict'] = label_encoder.fit_transform(df_final_clean_encoded['subdistrict'])\n",
        "df_final_clean_encoded['district'] = label_encoder.fit_transform(df_final_clean_encoded['district'])\n",
        "df_final_clean_encoded['season'] = label_encoder.fit_transform(df_final_clean_encoded['season'])\n",
        "df_final_clean_encoded['quarter'] = label_encoder.fit_transform(df_final_clean_encoded['quarter'])\n",
        "df_final_clean_encoded['year'] = label_encoder.fit_transform(df_final_clean_encoded['year'])\n",
        "\n",
        "# สร้าง X และ y\n",
        "X = df_final_clean_encoded\n",
        "y = df_final_clean['cases']\n",
        "\n",
        "# แบ่งข้อมูลเป็นชุดฝึกและทดสอบ\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# สร้างโมเดล Random Forest\n",
        "rf_model = RandomForestRegressor(n_estimators=200,  max_depth=10, random_state=42)\n",
        "\n",
        "# ฝึกโมเดล\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# ทำนายค่าบนชุดทดสอบ\n",
        "y_pred = rf_model.predict(X_test)\n",
        "\n",
        "# คำนวณค่า MSE (Mean Squared Error)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)  # คำนวณค่ารากที่สองของ MSE\n",
        "print(f\"RMSE: {rmse}\")\n",
        "\n",
        "# คำนวณค่า R² (Coefficient of Determination)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print(f\"R²: {r2}\")\n",
        "\n",
        "# กราฟเปรียบเทียบผลทำนายและค่าจริง\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(y_test.values, label='Actual Cases', color='red')\n",
        "plt.plot(y_pred, label='Predicted Cases', color='blue')\n",
        "plt.title('Predicted vs Actual Cases')\n",
        "plt.xlabel('Index')\n",
        "plt.ylabel('Number of Cases')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Plot feature importance\n",
        "importances = rf_model.feature_importances_\n",
        "indices = np.argsort(importances)[::-1]\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.title('Feature Importance')\n",
        "plt.barh(range(X_train.shape[1]), importances[indices], align='center')\n",
        "plt.yticks(range(X_train.shape[1]), [X_train.columns[i] for i in indices])\n",
        "plt.xlabel('Importance score')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "BcjAa3uQcdID"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Pvhi7lsC34k8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# เลือกเฉพาะตัวแปรที่มีนัยสำคัญ\n",
        "significant_columns = ['rain_15d_avg', 'month', 'subdistrict', 'humid_15d_avg']\n",
        "\n",
        "# แปลง categorical variables ให้เป็นตัวเลข\n",
        "df_final_clean_encoded = df_final_clean[significant_columns].copy()\n",
        "\n",
        "# ใช้ LabelEncoder สำหรับแปลงตัวแปรเชิงหมวดหมู่ให้เป็นตัวเลข\n",
        "label_encoder = LabelEncoder()\n",
        "df_final_clean_encoded['subdistrict'] = label_encoder.fit_transform(df_final_clean_encoded['subdistrict'])\n",
        "\n",
        "# สร้าง X และ y\n",
        "X = df_final_clean_encoded\n",
        "y = df_final_clean['cases']\n",
        "\n",
        "# แบ่งข้อมูลเป็นชุดฝึกและทดสอบ\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# สร้างโมเดล Random Forest\n",
        "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "\n",
        "# ฝึกโมเดล\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# ทำนายค่าบนชุดทดสอบ\n",
        "y_pred = rf_model.predict(X_test)\n",
        "\n",
        "# คำนวณค่า MSE (Mean Squared Error)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)  # คำนวณค่ารากที่สองของ MSE\n",
        "print(f\"RMSE: {rmse}\")\n",
        "\n",
        "# คำนวณค่า R² (Coefficient of Determination)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print(f\"R²: {r2}\")\n",
        "\n",
        "# กราฟเปรียบเทียบผลทำนายและค่าจริง\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(y_test.values, label='Actual Cases', color='red')\n",
        "plt.plot(y_pred, label='Predicted Cases', color='blue')\n",
        "plt.title('Predicted vs Actual Cases')\n",
        "plt.xlabel('Index')\n",
        "plt.ylabel('Number of Cases')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Plot feature importance\n",
        "importances = rf_model.feature_importances_\n",
        "indices = np.argsort(importances)[::-1]\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.title('Feature Importance')\n",
        "plt.barh(range(X_train.shape[1]), importances[indices], align='center')\n",
        "plt.yticks(range(X_train.shape[1]), [X_train.columns[i] for i in indices])\n",
        "plt.xlabel('Importance score')\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "09GT5BsHc7KP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "qlBODmw_0Led"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# เลือกเฉพาะตัวแปรที่มีนัยสำคัญ\n",
        "significant_columns = ['rain_15d_avg', 'month', 'subdistrict', 'humid_15d_avg']\n",
        "\n",
        "# แปลง categorical variables ให้เป็นตัวเลข\n",
        "df_final_clean_encoded = df_final_clean[significant_columns].copy()\n",
        "\n",
        "# ใช้ LabelEncoder สำหรับแปลงตัวแปรเชิงหมวดหมู่ให้เป็นตัวเลข\n",
        "label_encoder = LabelEncoder()\n",
        "df_final_clean_encoded['subdistrict'] = label_encoder.fit_transform(df_final_clean_encoded['subdistrict'])\n",
        "\n",
        "# สร้าง X และ y\n",
        "X = df_final_clean_encoded\n",
        "y = df_final_clean['cases']\n",
        "\n",
        "# แบ่งข้อมูลเป็นชุดฝึกและทดสอบ\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# สร้างโมเดล Gradient Boosting\n",
        "gb_model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=5)\n",
        "\n",
        "# ฝึกโมเดล\n",
        "gb_model.fit(X_train, y_train)\n",
        "\n",
        "# ทำนายค่าบนชุดทดสอบ\n",
        "y_pred = gb_model.predict(X_test)\n",
        "\n",
        "# คำนวณค่า MSE (Mean Squared Error)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)  # คำนวณค่ารากที่สองของ MSE\n",
        "print(f\"RMSE: {rmse}\")\n",
        "\n",
        "# คำนวณค่า R² (Coefficient of Determination)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print(f\"R²: {r2}\")\n",
        "\n",
        "# กราฟเปรียบเทียบผลทำนายและค่าจริง\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(y_test.values, label='Actual Cases', color='red')\n",
        "plt.plot(y_pred, label='Predicted Cases', color='blue')\n",
        "plt.title('Predicted vs Actual Cases')\n",
        "plt.xlabel('Index')\n",
        "plt.ylabel('Number of Cases')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "uyL1lRAL0LrT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "M-U2lR3R0MAz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ZRwVf6qScdiE"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6pTg5u-43Bv0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BGcDjCh53B5L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qx2JKdXY3B9T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MaLiEbFF3CBd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IdXr-0rW3CFa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SQ_ghpQu3CLb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-3-Ah8Dl3CPb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "\n",
        "# ✅ เลือกตัวแปรที่ใช้\n",
        "X = df_clean.drop(columns=['cases', 'date'])  # ลบ target และวันที่ทิ้ง\n",
        "y = df_clean['cases']\n",
        "\n",
        "# ✅ One-hot encoding\n",
        "X_encoded = pd.get_dummies(X, drop_first=True)\n",
        "\n",
        "# ✅ แบ่ง train/test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# ✅ Scaling (ถ้าจำเป็น, สามารถใช้ได้เมื่อข้อมูลมีขนาดหรือสเกลต่างกัน)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# ข้อมูลพร้อมสำหรับการฝึกโมเดล Machine Learning ต่อไป\n"
      ],
      "metadata": {
        "id": "F-l5yBTJ7Jmi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# สร้างโมเดล Random Forest\n",
        "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "\n",
        "# ฝึกโมเดล\n",
        "rf.fit(X_train_scaled, y_train)\n",
        "\n",
        "# ทำนายผล\n",
        "y_pred_rf = rf.predict(X_test_scaled)\n",
        "\n",
        "# ประเมินผล\n",
        "print(\"📊 ผลการประเมิน Random Forest:\")\n",
        "print(f\"RMSE: {np.sqrt(mean_squared_error(y_test, y_pred_rf)):.4f}\")\n",
        "print(f\"MAE : {mean_absolute_error(y_test, y_pred_rf):.4f}\")\n",
        "print(f\"R²  : {r2_score(y_test, y_pred_rf):.4f}\")\n"
      ],
      "metadata": {
        "id": "UWXlcKdJ7Q86"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "นัย\n",
        "# New Section"
      ],
      "metadata": {
        "id": "eYYWfb_JGHFk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "\n",
        "X = df_clean.drop(columns=['cases', 'date'])\n",
        "y = df_clean['cases']\n",
        "\n",
        "X_encoded = pd.get_dummies(X, drop_first=True)\n",
        "\n",
        "# แบ่งข้อมูล\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "HBCsVhjP745p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBRegressor\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.metrics import make_scorer, r2_score\n",
        "import numpy as np\n",
        "from scipy.stats import uniform, randint\n",
        "\n",
        "# โมเดลพื้นฐาน\n",
        "xgb = XGBRegressor(random_state=42)\n",
        "\n",
        "# ช่วงค่าพารามิเตอร์ที่สุ่มเลือก\n",
        "param_dist = {\n",
        "    'n_estimators': randint(100, 600),\n",
        "    'learning_rate': uniform(0.01, 0.2),\n",
        "    'max_depth': randint(3, 10),\n",
        "    'subsample': uniform(0.6, 0.4),\n",
        "    'colsample_bytree': uniform(0.6, 0.4),\n",
        "    'reg_alpha': uniform(0, 1),\n",
        "    'reg_lambda': uniform(0.5, 2)\n",
        "}\n",
        "\n",
        "# ใช้ r2_score เป็น metric\n",
        "r2_scorer = make_scorer(r2_score)\n",
        "\n",
        "# สุ่มเลือก 50 ชุดพารามิเตอร์จาก param_dist\n",
        "random_search = RandomizedSearchCV(\n",
        "    estimator=xgb,\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=50,\n",
        "    scoring=r2_scorer,\n",
        "    cv=3,\n",
        "    verbose=2,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# รันค้นหาค่าที่ดีที่สุด\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "# แสดงผล\n",
        "print(\"Best parameters found: \", random_search.best_params_)\n",
        "\n",
        "print(f\"Best R2 score (CV): {random_search.best_score_:.4f}\")\n",
        "\n",
        "# ทดสอบกับ test set\n",
        "best_xgb = random_search.best_estimator_\n",
        "y_pred = best_xgb.predict(X_test)\n",
        "\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "\n",
        "print(f\"Test RMSE: {np.sqrt(mean_squared_error(y_test, y_pred)):.4f}\")\n",
        "print(f\"Test MAE : {mean_absolute_error(y_test, y_pred):.4f}\")\n",
        "print(f\"Test R2  : {r2_score(y_test, y_pred):.4f}\")\n"
      ],
      "metadata": {
        "id": "zm6krMF276_3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBRegressor\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.metrics import make_scorer, r2_score\n",
        "import numpy as np\n",
        "from scipy.stats import uniform, randint\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "\n",
        "# โมเดล XGBoost\n",
        "xgb = XGBRegressor(random_state=42)\n",
        "\n",
        "# ช่วงค่าพารามิเตอร์ที่สุ่มเลือก\n",
        "param_dist = {\n",
        "    'n_estimators': randint(100, 1000),  # ลดจำนวน n_estimators\n",
        "    'learning_rate': uniform(0.01, 0.1),\n",
        "    'max_depth': randint(3, 10),\n",
        "    'subsample': uniform(0.6, 0.4),\n",
        "    'colsample_bytree': uniform(0.6, 0.4),\n",
        "    'reg_alpha': uniform(0, 1),\n",
        "    'reg_lambda': uniform(0.5, 2)\n",
        "}\n",
        "\n",
        "# ใช้ r2_score เป็น metric\n",
        "r2_scorer = make_scorer(r2_score)\n",
        "\n",
        "# สุ่มเลือก 50 ชุดพารามิเตอร์จาก param_dist\n",
        "random_search = RandomizedSearchCV(\n",
        "    estimator=xgb,\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=50,  # ลดจำนวนการสุ่มพารามิเตอร์\n",
        "    scoring=r2_scorer,\n",
        "    cv=5,  # ลด cross-validation เป็น 5-fold\n",
        "    verbose=2,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# รันค้นหาค่าที่ดีที่สุด\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "# แสดงผลพารามิเตอร์ที่ดีที่สุด\n",
        "print(\"Best parameters found: \", random_search.best_params_)\n",
        "print(f\"Best R² score (CV): {random_search.best_score_:.4f}\")\n",
        "\n",
        "# ทดสอบกับ test set\n",
        "best_xgb = random_search.best_estimator_\n",
        "y_pred = best_xgb.predict(X_test)\n",
        "\n",
        "# ประเมินผล\n",
        "print(f\"Test RMSE: {np.sqrt(mean_squared_error(y_test, y_pred)):.4f}\")\n",
        "print(f\"Test MAE: {mean_absolute_error(y_test, y_pred):.4f}\")\n",
        "print(f\"Test R²: {r2_score(y_test, y_pred):.4f}\")\n"
      ],
      "metadata": {
        "id": "jH3Oam-BRNSA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_encoded_selected.columns)"
      ],
      "metadata": {
        "id": "wQsADwC-at-P"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}